#!/usr/bin/env python3
"""
åŠ¨æ€å®å­¦ä¹ å™¨ (Dynamic Macro Learner)

å½“ Tree-sitter è§£æå¤±è´¥æ—¶ï¼Œè‡ªåŠ¨å­¦ä¹ æ–°çš„å®å®šä¹‰ã€‚
å­¦ä¹ åˆ°çš„å®å¯ä»¥è·¨é¡¹ç›®å¤ç”¨ï¼Œå¹¶æŒä¹…åŒ–ä¿å­˜ã€‚

å®ç°æ€è·¯:
1. å½“ Tree-sitter è§£ææŠ¥é”™æ—¶ï¼Œåˆ†ææŠ¥é”™è¡Œçš„ C æºç 
2. è‡ªåŠ¨æå–å¹²æ‰°è§£æçš„å®
3. åŠ¨æ€æ·»åŠ åˆ°å®å±•å¼€å­—å…¸ä¸­
4. ä¿å­˜åˆ°æ–‡ä»¶ï¼Œä¾›åç»­é¡¹ç›®å¤ç”¨
"""

import re
import json
import logging
import os
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Set
from dataclasses import dataclass, field

logger = logging.getLogger(__name__)

# =========================================================================
# å†…ç½®å®å®šä¹‰ (OpenHarmony/LiteOS ç³»ç»Ÿå®)
# =========================================================================

# åŸºç¡€ç³»ç»Ÿå®
BUILTIN_MACRO_EXPANSIONS = {
    # LiteOS/OpenHarmony å­˜å‚¨ç±»è¯´æ˜ç¬¦
    'STATIC': 'static',
    'INLINE': 'inline',
    'LITE_OS_SEC_TEXT': '',
    'LITE_OS_SEC_TEXT_INIT': '',
    'LITE_OS_SEC_TEXT_MINOR': '',
    'LITE_OS_SEC_DATA': '',
    'LITE_OS_SEC_DATA_INIT': '',
    'LITE_OS_SEC_DATA_VEC': '',
    'LITE_OS_SEC_BSS': '',
    'LITE_OS_SEC_BSS_INIT': '',
    'LITE_OS_SEC_BSS_MINOR': '',
    'LITE_OS_SEC_RODATA': '',
    'LITE_OS_SEC_ITCM': '',
    'LITE_OS_SEC_DTCM': '',
    'LITE_OS_SECTION': '',
    
    # HDF é©±åŠ¨æ¡†æ¶å®
    'HDF_STATIC': 'static',
    'HDF_INIT': '',
    'HDF_LOG_TAG': '',
    
    # OHOS API å®
    'OHOS_API': '',
    'OHOS_INIT': '',
    
    # åŸºæœ¬ç±»å‹å® (LiteOS é£æ ¼)
    'VOID': 'void',
    'CHAR': 'char',
    'BOOL': '_Bool',
    'INT8': 'signed char',
    'UINT8': 'unsigned char',
    'INT16': 'short',
    'UINT16': 'unsigned short',
    'INT32': 'int',
    'UINT32': 'unsigned int',
    'INT64': 'long long',
    'UINT64': 'unsigned long long',
    'FLOAT': 'float',
    'DOUBLE': 'double',
    'UINTPTR': 'uintptr_t',
    'INTPTR': 'intptr_t',
    'AARCHPTR': 'uintptr_t',
    'size_t': 'unsigned long',
    'ssize_t': 'long',
    
    # DSoftBus å®
    'SOFTBUS_DPRINTF_ATTR': '',
    'SOFTBUS_API': '',
    'NO_SANITIZE': '',
    
    # é€šç”¨ç¼–è¯‘å™¨å±æ€§å® (ç®€åŒ–å¤„ç†)
    '__unused': '',
    '__weak': '',
    '__aligned': '',
    '__section': '',
    '__always_inline': 'inline',
    '__noinline': '',
    '__packed': '',
    '__deprecated': '',
    '__printf': '',
}

# =========================================================================
# å®æ¨¡å¼è¯†åˆ«å™¨
# =========================================================================

@dataclass
class LearnedMacro:
    """å­¦ä¹ åˆ°çš„å®ä¿¡æ¯"""
    name: str
    expansion: str
    source: str = "auto-learned"  # æ¥æºï¼šauto-learned, builtin, user-defined
    confidence: float = 0.8
    context: str = ""  # å‘ç°è¯¥å®çš„ä¸Šä¸‹æ–‡
    
    # è¯Šæ–­ä¿¡æ¯ - è®°å½•å®çš„æ¥æºå’Œä¸ºä»€ä¹ˆä½¿ç”¨è¿™ä¸ªå±•å¼€å€¼
    is_placeholder: bool = False              # å±•å¼€å€¼æ˜¯å¦æ˜¯çŒœæµ‹çš„ï¼ˆè€ŒéçœŸå®å®šä¹‰ï¼‰
    c_source_file: str = ""                   # åŸå§‹å®å®šä¹‰çš„æ–‡ä»¶ä½ç½®
    c_source_line: int = 0                    # åŸå§‹å®å®šä¹‰çš„è¡Œå·
    original_definition: str = ""             # åŸå§‹å®å®šä¹‰å†…å®¹
    failure_reason: str = ""                  # å¦‚æœæ˜¯å ä½ç¬¦ï¼Œä¸ºä»€ä¹ˆæ— æ³•è·å–çœŸå®å±•å¼€
    diagnostic_notes: List[str] = field(default_factory=list)  # è¯Šæ–­å¤‡æ³¨

@dataclass
class MacroLearningResult:
    """å­¦ä¹ ç»“æœ"""
    learned: List[LearnedMacro]
    source_modified: str
    success: bool


class MacroLearner:
    """
    åŠ¨æ€å®å­¦ä¹ å™¨
    
    ç‰¹æ€§:
    - ä»è§£æé”™è¯¯ä¸­è‡ªåŠ¨å­¦ä¹ æ–°å®
    - æ”¯æŒå¤šç§å®æ¨¡å¼è¯†åˆ«
    - æŒä¹…åŒ–ä¿å­˜å­¦ä¹ ç»“æœ
    - è·¨é¡¹ç›®å…±äº«çŸ¥è¯†
    """
    
    def __init__(
        self, 
        storage_path: Optional[Path] = None,
        include_builtin: bool = True
    ):
        """
        åˆå§‹åŒ–å®å­¦ä¹ å™¨
        
        Args:
            storage_path: æŒä¹…åŒ–å­˜å‚¨è·¯å¾„ï¼Œé»˜è®¤ä¸ºé¡¹ç›® .cache ç›®å½•
            include_builtin: æ˜¯å¦åŒ…å«å†…ç½®å®
        """
        # é»˜è®¤å­˜å‚¨åˆ°é¡¹ç›®çš„ .cache/learned_data ç›®å½•ï¼ˆæ›´å®‰å…¨ï¼Œä¸ä¼šè¢«æ„å¤–åˆ é™¤ï¼‰
        if storage_path is None:
            cache_root_env = os.environ.get("C2R_CACHE_ROOT", "").strip()
            if cache_root_env:
                cache_dir = Path(cache_root_env).expanduser().resolve() / "learned_data"
            else:
                # å°è¯•æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
                project_root = Path(__file__).parent
                cache_dir = project_root / ".cache" / "learned_data"
            cache_dir.mkdir(parents=True, exist_ok=True)
            self.storage_path = cache_dir / "learned_macros.json"
        else:
            self.storage_path = storage_path
            
        self.macros: Dict[str, LearnedMacro] = {}
        
        # åŠ è½½å†…ç½®å®
        if include_builtin:
            for name, expansion in BUILTIN_MACRO_EXPANSIONS.items():
                self.macros[name] = LearnedMacro(
                    name=name, 
                    expansion=expansion, 
                    source="builtin"
                )
        
        # åŠ è½½æŒä¹…åŒ–çš„å­¦ä¹ ç»“æœ
        self._load_from_storage()
    
    def _load_from_storage(self):
        """ä»æ–‡ä»¶åŠ è½½å·²å­¦ä¹ çš„å®ï¼ˆåŒ…å«è¯Šæ–­ä¿¡æ¯ï¼‰"""
        if not self.storage_path.exists():
            return
        
        try:
            with open(self.storage_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            for entry in data.get("macros", []):
                name = entry.get("name")
                if name and name not in self.macros:  # ä¸è¦†ç›–å†…ç½®å®
                    self.macros[name] = LearnedMacro(
                        name=name,
                        expansion=entry.get("expansion", ""),
                        source=entry.get("source", "loaded"),
                        confidence=entry.get("confidence", 0.5),
                        context=entry.get("context", ""),
                        # è¯Šæ–­ä¿¡æ¯
                        is_placeholder=entry.get("is_placeholder", False),
                        c_source_file=entry.get("c_source_file", ""),
                        c_source_line=entry.get("c_source_line", 0),
                        original_definition=entry.get("original_definition", ""),
                        failure_reason=entry.get("failure_reason", ""),
                        diagnostic_notes=entry.get("diagnostic_notes", [])
                    )
            
            # ç»Ÿè®¡å ä½ç¬¦æ•°é‡
            placeholder_count = sum(1 for m in self.macros.values() if m.is_placeholder and m.source != "builtin")
            logger.info(f"ä» {self.storage_path} åŠ è½½äº† {len(data.get('macros', []))} ä¸ªå·²å­¦ä¹ çš„å® (å…¶ä¸­ {placeholder_count} ä¸ªæ˜¯å ä½ç¬¦)")
        except Exception as e:
            logger.warning(f"åŠ è½½å·²å­¦ä¹ çš„å®å¤±è´¥: {e}")
    
    def save_to_storage(self):
        """ä¿å­˜å­¦ä¹ ç»“æœåˆ°æ–‡ä»¶ï¼ˆåŒ…å«è¯Šæ–­ä¿¡æ¯ï¼‰"""
        try:
            self.storage_path.parent.mkdir(parents=True, exist_ok=True)
            
            # åªä¿å­˜éå†…ç½®å®
            learned_macros = [
                {
                    "name": m.name,
                    "expansion": m.expansion,
                    "source": m.source,
                    "confidence": m.confidence,
                    "context": m.context,
                    # è¯Šæ–­ä¿¡æ¯
                    "is_placeholder": m.is_placeholder,
                    "c_source_file": m.c_source_file,
                    "c_source_line": m.c_source_line,
                    "original_definition": m.original_definition[:500] if m.original_definition else "",
                    "failure_reason": m.failure_reason,
                    "diagnostic_notes": m.diagnostic_notes
                }
                for m in self.macros.values()
                if m.source != "builtin"
            ]
            
            # åˆ†ç±»ç»Ÿè®¡
            placeholder_count = sum(1 for m in learned_macros if m.get("is_placeholder", False))
            real_count = len(learned_macros) - placeholder_count
            
            data = {
                "version": "2.0",
                "statistics": {
                    "total": len(learned_macros),
                    "real_expansions": real_count,
                    "placeholders": placeholder_count
                },
                "macros": learned_macros
            }
            
            with open(self.storage_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"å·²ä¿å­˜ {len(learned_macros)} ä¸ªå­¦ä¹ çš„å®åˆ° {self.storage_path} (çœŸå®: {real_count}, å ä½ç¬¦: {placeholder_count})")
        except Exception as e:
            logger.warning(f"ä¿å­˜å­¦ä¹ çš„å®å¤±è´¥: {e}")
    
    def get_expansion(self, macro_name: str) -> Optional[str]:
        """è·å–å®çš„å±•å¼€å€¼"""
        macro = self.macros.get(macro_name)
        return macro.expansion if macro else None
    
    def add_macro(
        self, 
        name: str, 
        expansion: str, 
        source: str = "auto-learned",
        confidence: float = 0.8,
        context: str = "",
        # è¯Šæ–­ä¿¡æ¯å‚æ•°
        is_placeholder: bool = False,
        c_source_file: str = "",
        c_source_line: int = 0,
        original_definition: str = "",
        failure_reason: str = "",
        diagnostic_notes: List[str] = None
    ):
        """
        æ·»åŠ æ–°å®
        
        Args:
            name: å®åç§°
            expansion: å±•å¼€åçš„å€¼
            source: æ¥æº
            confidence: ç½®ä¿¡åº¦
            context: ä¸Šä¸‹æ–‡
            is_placeholder: å±•å¼€å€¼æ˜¯å¦æ˜¯çŒœæµ‹çš„
            c_source_file: åŸå§‹å®šä¹‰æ–‡ä»¶
            c_source_line: åŸå§‹å®šä¹‰è¡Œå·
            original_definition: åŸå§‹å®å®šä¹‰
            failure_reason: å¤±è´¥åŸå› 
            diagnostic_notes: è¯Šæ–­å¤‡æ³¨
        """
        if name in self.macros and self.macros[name].source == "builtin":
            # ä¸è¦†ç›–å†…ç½®å®
            return
        
        self.macros[name] = LearnedMacro(
            name=name,
            expansion=expansion,
            source=source,
            confidence=confidence,
            context=context,
            is_placeholder=is_placeholder,
            c_source_file=c_source_file,
            c_source_line=c_source_line,
            original_definition=original_definition,
            failure_reason=failure_reason,
            diagnostic_notes=diagnostic_notes or []
        )
        
        # æ—¥å¿—è¾“å‡º
        if is_placeholder:
            logger.warning(f"âš ï¸ å­¦ä¹ å ä½ç¬¦å®: {name} -> {expansion} (åŸå› : {failure_reason})")
        else:
            logger.info(f"âœ“ å­¦ä¹ å®: {name} -> {expansion}")
    
    def expand_all(self, source_code: str) -> str:
        """
        å±•å¼€æºä»£ç ä¸­çš„æ‰€æœ‰å·²çŸ¥å®
        
        Args:
            source_code: æºä»£ç 
        
        Returns:
            å±•å¼€åçš„æºä»£ç 
        """
        result = source_code
        
        # æŒ‰å®åé•¿åº¦é™åºæ’åºï¼Œé¿å…çŸ­å®åè¢«å…ˆæ›¿æ¢å¯¼è‡´é—®é¢˜
        sorted_macros = sorted(
            self.macros.items(), 
            key=lambda x: len(x[0]), 
            reverse=True
        )
        
        for name, macro in sorted_macros:
            if macro.expansion is not None:
                pattern = rf'\b{re.escape(name)}\b'
                result = re.sub(pattern, macro.expansion, result)
        
        return result
    
    def learn_from_error_line(
        self, 
        source_code: str, 
        error_line: int,
        save: bool = True
    ) -> List[LearnedMacro]:
        """
        ä»è§£æé”™è¯¯è¡Œå­¦ä¹ æ–°å®
        
        Args:
            source_code: æºä»£ç 
            error_line: é”™è¯¯è¡Œå· (1-based)
            save: æ˜¯å¦ç«‹å³ä¿å­˜
        
        Returns:
            å­¦ä¹ åˆ°çš„å®åˆ—è¡¨
        """
        lines = source_code.split('\n')
        if error_line < 1 or error_line > len(lines):
            return []
        
        line = lines[error_line - 1].strip()
        learned = []
        
        # =========================================================================
        # æ¨¡å¼1: å­˜å‚¨ç±»è¯´æ˜ç¬¦å® (å¦‚ STATIC void func())
        # =========================================================================
        storage_class_pattern = re.match(
            r'^([A-Z][A-Z0-9_]*)\s+((?:unsigned\s+|signed\s+)?'
            r'(?:int|long|short|char|void|float|double|_Bool|\w+_t))\s+(\w+)\s*\(',
            line
        )
        if storage_class_pattern:
            potential_macro = storage_class_pattern.group(1)
            # å·²çŸ¥çš„å­˜å‚¨ç±»è¯´æ˜ç¬¦å®
            if potential_macro not in self.macros:
                if 'STATIC' in potential_macro:
                    expansion = 'static'
                elif 'INLINE' in potential_macro:
                    expansion = 'inline'
                elif 'EXTERN' in potential_macro:
                    expansion = 'extern'
                else:
                    expansion = ''  # é»˜è®¤å±•å¼€ä¸ºç©ºï¼ˆå¦‚æ®µå±æ€§ï¼‰
                
                self.add_macro(potential_macro, expansion, context=line[:100])
                learned.append(self.macros[potential_macro])
        
        # =========================================================================
        # æ¨¡å¼2: ç±»å‹å® (å¦‚ UINT32 func_name())
        # =========================================================================
        type_macro_pattern = re.match(
            r'^(?:static\s+|inline\s+|extern\s+)*([A-Z][A-Z0-9_]*)\s+(\w+)\s*\(',
            line
        )
        if type_macro_pattern and type_macro_pattern.group(1) not in self.macros:
            potential_type = type_macro_pattern.group(1)
            
            # å·²çŸ¥çš„ç±»å‹å®æ˜ å°„
            known_types = {
                'VOID': 'void', 'CHAR': 'char', 'BOOL': '_Bool',
                'INT8': 'signed char', 'UINT8': 'unsigned char',
                'INT16': 'short', 'UINT16': 'unsigned short',
                'INT32': 'int', 'UINT32': 'unsigned int',
                'INT64': 'long long', 'UINT64': 'unsigned long long',
                'FLOAT': 'float', 'DOUBLE': 'double',
                'SIZE_T': 'unsigned long', 'SSIZE_T': 'long',
            }
            
            if potential_type in known_types:
                expansion = known_types[potential_type]
            else:
                # æ¨æ–­ï¼šä»¥ U å¼€å¤´çš„å…¨å¤§å†™æ ‡è¯†ç¬¦å¯èƒ½æ˜¯æ— ç¬¦å·æ•´æ•°
                if potential_type.startswith('U') and potential_type[1:].isalpha():
                    expansion = 'unsigned int'
                else:
                    expansion = 'int'  # é»˜è®¤å‡è®¾ä¸º int
            
            self.add_macro(potential_type, expansion, context=line[:100])
            learned.append(self.macros[potential_type])
        
        # =========================================================================
        # æ¨¡å¼3: å‚æ•°åˆ—è¡¨ä¸­çš„å® (å¦‚ func(UINT32 arg))
        # =========================================================================
        param_macro_pattern = re.findall(r'\(.*?([A-Z][A-Z0-9_]*)\s+\w+', line)
        for param_type in param_macro_pattern:
            if param_type not in self.macros:
                # åŒä¸Šï¼Œæ¨æ–­ç±»å‹
                known_types = {
                    'VOID': 'void', 'CHAR': 'char', 'BOOL': '_Bool',
                    'INT8': 'signed char', 'UINT8': 'unsigned char',
                    'INT16': 'short', 'UINT16': 'unsigned short',
                    'INT32': 'int', 'UINT32': 'unsigned int',
                    'INT64': 'long long', 'UINT64': 'unsigned long long',
                }
                
                if param_type in known_types:
                    expansion = known_types[param_type]
                else:
                    expansion = 'int'
                
                self.add_macro(param_type, expansion, context=line[:100])
                learned.append(self.macros[param_type])
        
        if save and learned:
            self.save_to_storage()
        
        return learned
    
    def learn_from_parse_errors(
        self, 
        source_code: str, 
        error_locations: List[Tuple[int, int]],
        max_learn: int = 10
    ) -> MacroLearningResult:
        """
        ä»å¤šä¸ªè§£æé”™è¯¯ä½ç½®å­¦ä¹ å®
        
        Args:
            source_code: æºä»£ç 
            error_locations: é”™è¯¯ä½ç½®åˆ—è¡¨ [(line, col), ...]
            max_learn: æœ€å¤§å­¦ä¹ æ•°é‡
        
        Returns:
            å­¦ä¹ ç»“æœ
        """
        all_learned = []
        
        # å»é‡é”™è¯¯è¡Œ
        error_lines = set(loc[0] for loc in error_locations[:max_learn])
        
        for line_num in sorted(error_lines):
            learned = self.learn_from_error_line(source_code, line_num, save=False)
            all_learned.extend(learned)
        
        # åº”ç”¨å­¦ä¹ åˆ°çš„å®å±•å¼€
        modified_source = self.expand_all(source_code)
        
        # ä¿å­˜
        if all_learned:
            self.save_to_storage()
        
        return MacroLearningResult(
            learned=all_learned,
            source_modified=modified_source,
            success=len(all_learned) > 0
        )
    
    def get_gcc_define_args(self) -> List[str]:
        """
        ç”Ÿæˆ GCC é¢„å¤„ç†å™¨çš„ -D å‚æ•°
        
        Returns:
            å‚æ•°åˆ—è¡¨ ['-DSTATIC=static', '-DUINT32=unsigned int', ...]
        """
        args = []
        for name, macro in self.macros.items():
            if macro.expansion:
                args.append(f'-D{name}={macro.expansion}')
            else:
                args.append(f'-D{name}=')
        return args
    
    def get_macro_count(self) -> Dict[str, int]:
        """è·å–å®ç»Ÿè®¡ä¿¡æ¯"""
        counts = {"builtin": 0, "auto-learned": 0, "loaded": 0, "user-defined": 0}
        for macro in self.macros.values():
            source = macro.source if macro.source in counts else "other"
            counts[source] = counts.get(source, 0) + 1
        return counts
    
    def get_placeholder_macros(self) -> List[LearnedMacro]:
        """è·å–æ‰€æœ‰å ä½ç¬¦å®ï¼ˆéœ€è¦äººå·¥å®¡æŸ¥ï¼‰"""
        return [m for m in self.macros.values() if m.is_placeholder and m.source != "builtin"]
    
    def get_statistics(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯ï¼ˆåŒ…å«è¯Šæ–­ä¿¡æ¯ï¼‰"""
        learned_macros = [m for m in self.macros.values() if m.source != "builtin"]
        placeholder_macros = [m for m in learned_macros if m.is_placeholder]
        
        return {
            "builtin_count": sum(1 for m in self.macros.values() if m.source == "builtin"),
            "learned_count": len(learned_macros),
            "learned_real": len(learned_macros) - len(placeholder_macros),
            "learned_placeholder": len(placeholder_macros),
            "storage_path": str(self.storage_path)
        }
    
    def generate_diagnostic_report(self, output_path: Optional[Path] = None) -> str:
        """
        ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
        
        æ˜¾ç¤ºæ‰€æœ‰å ä½ç¬¦å®åŠå…¶å¤±è´¥åŸå› 
        
        Args:
            output_path: å¯é€‰ï¼Œä¿å­˜æŠ¥å‘Šçš„è·¯å¾„
            
        Returns:
            æ ¼å¼åŒ–çš„æŠ¥å‘Šæ–‡æœ¬
        """
        from datetime import datetime
        
        lines = [
            "=" * 70,
            "å®å­¦ä¹ å™¨è¯Šæ–­æŠ¥å‘Š",
            f"ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}",
            f"å­˜å‚¨è·¯å¾„: {self.storage_path}",
            "=" * 70,
            "",
        ]
        
        stats = self.get_statistics()
        lines.append("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
        lines.append(f"  å†…ç½®å®: {stats['builtin_count']}")
        lines.append(f"  å­¦ä¹ å®: {stats['learned_count']} (çœŸå®å±•å¼€: {stats['learned_real']}, å ä½ç¬¦: {stats['learned_placeholder']})")
        lines.append("")
        
        placeholder_macros = self.get_placeholder_macros()
        
        if placeholder_macros:
            lines.append("-" * 70)
            lines.append(f"âš ï¸ éœ€è¦å®¡æŸ¥çš„å® ({len(placeholder_macros)} ä¸ª)")
            lines.append("-" * 70)
            
            for m in placeholder_macros:
                lines.append(f"\n[å®] {m.name}")
                lines.append(f"  å½“å‰å±•å¼€: {m.expansion}")
                lines.append(f"  å¤±è´¥åŸå› : {m.failure_reason}")
                if m.c_source_file:
                    lines.append(f"  C æºç ä½ç½®: {m.c_source_file}:{m.c_source_line}")
                if m.original_definition:
                    lines.append(f"  åŸå§‹å®šä¹‰: {m.original_definition[:100]}...")
                if m.context:
                    lines.append(f"  ä¸Šä¸‹æ–‡: {m.context[:80]}...")
                if m.diagnostic_notes:
                    lines.append("  è¯Šæ–­å¤‡æ³¨:")
                    for note in m.diagnostic_notes:
                        lines.append(f"    - {note}")
        else:
            lines.append("âœ… æ‰€æœ‰å­¦ä¹ çš„å®éƒ½æœ‰çœŸå®å±•å¼€å€¼ï¼Œæ— éœ€å®¡æŸ¥")
        
        report = '\n'.join(lines)
        
        if output_path:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report)
            logger.info(f"å®è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        
        return report


# =========================================================================
# å…¨å±€å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
# =========================================================================

_global_learner: Optional[MacroLearner] = None

def get_global_macro_learner() -> MacroLearner:
    """è·å–å…¨å±€å®å­¦ä¹ å™¨å®ä¾‹"""
    global _global_learner
    if _global_learner is None:
        _global_learner = MacroLearner()
    return _global_learner


def expand_macros(source_code: str) -> str:
    """å¿«é€Ÿå±•å¼€å®çš„ä¾¿æ·å‡½æ•°"""
    return get_global_macro_learner().expand_all(source_code)


def get_gcc_macro_args() -> List[str]:
    """è·å– GCC -D å‚æ•°çš„ä¾¿æ·å‡½æ•°"""
    return get_global_macro_learner().get_gcc_define_args()


# =========================================================================
# æµ‹è¯•
# =========================================================================

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # åˆ›å»ºå­¦ä¹ å™¨
    learner = MacroLearner()
    
    # æµ‹è¯•ä»£ç 
    test_code = """
STATIC UINT32 GetFatBlockNums(INT32 diskId, UINT64* fatBlocks)
{
    // implementation
}

VOID OsMain(VOID)
{
    UINT32 ret;
    ret = SOFTBUS_OK;
}
"""
    
    # å±•å¼€å®
    expanded = learner.expand_all(test_code)
    print("=== Original ===")
    print(test_code)
    print("\n=== Expanded ===")
    print(expanded)
    
    # è·å– GCC å‚æ•°
    gcc_args = learner.get_gcc_define_args()
    print(f"\n=== GCC Args ({len(gcc_args)} total) ===")
    print(' '.join(gcc_args[:10]))
    print("...")
    
    # ç»Ÿè®¡
    counts = learner.get_macro_count()
    print(f"\n=== Statistics ===")
    for source, count in counts.items():
        print(f"  {source}: {count}")












