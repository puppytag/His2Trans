# æ–‡ä»¶å: resort_by_unixcoder.py (å·²ä¿®æ”¹)
# ä½œç”¨: (RAG æ­¥éª¤ 2) åŠ è½½ jina-reranker-v3ï¼Œé‡æ’ BM25 çš„ Top-100 ç»“æœã€‚
# ä¼˜åŒ–: æ”¯æŒå¤šé¡¹ç›®å¹¶è¡Œå¤„ç†
# ç­–ç•¥: 
#   - æ¯ä¸ªé¡¹ç›®ä½¿ç”¨ä¸€ä¸ªGPUï¼ˆé€šè¿‡é¡¹ç›®åhashåˆ†é…ï¼‰
#   - å…è®¸å¤šä¸ªé¡¹ç›®åŒæ—¶è¿è¡Œï¼ˆæœ€å¤š4ä¸ªï¼Œå¦‚æœæœ‰4ä¸ªGPUï¼‰
#   - æ¯ä¸ªGPUä½¿ç”¨ç‹¬ç«‹çš„æ–‡ä»¶é”ï¼Œé¿å…å†²çª
#   - å•ä¸ªé¡¹ç›®å†…å¯ä»¥ä½¿ç”¨å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†æ–‡ä»¶ï¼ˆæé«˜GPUåˆ©ç”¨ç‡ï¼‰

import os
import sys
import re
import json
import time
import fcntl
import torch
from transformers import AutoModel
from tqdm import tqdm
from multiprocessing import Process, Queue, Manager, set_start_method, get_start_method
from pathlib import Path

# --- é…ç½® ---
from workspace_config import (
    RAG_ELASTIC_SEARCH_RESULTS, RAG_RERANKED_RESULTS,
    get_elastic_search_path, get_reranked_path
)
from project_config import PROJECT_NAME

# ä½¿ç”¨æ–°çš„å·¥ä½œç©ºé—´è·¯å¾„
RAG_PATH = get_elastic_search_path(PROJECT_NAME)  # BM25 ç»“æœçš„è¾“å…¥ç›®å½•
OUTPUT_PATH = get_reranked_path(PROJECT_NAME)  # é‡æ’ç»“æœçš„è¾“å‡ºç›®å½•
def _get_env_int(name: str, default: int) -> int:
    raw = (os.environ.get(name) or "").strip()
    if not raw:
        return default
    try:
        v = int(raw)
        return v if v > 0 else default
    except Exception:
        return default

# æœ€ç»ˆä¿ç•™çš„èŒƒä¾‹æ•°é‡ï¼ˆé»˜è®¤ 10ï¼›å¯é€šè¿‡ C2R_RAG_TOPK è¦†ç›–ï¼Œç”¨äº RQ3.2 top-k æ•æ„Ÿæ€§å®éªŒï¼‰
TOP_K = _get_env_int("C2R_RAG_TOPK", 10)

# Jina-reranker åŠ è½½è®¾ç½®
DEFAULT_MODEL_ID = "jinaai/jina-reranker-v3"
SCRIPT_DIR = Path(__file__).parent.resolve()
MY_CACHE_PATH = str(SCRIPT_DIR / "data" / "my-huggingface")
os.environ["HF_HOME"] = MY_CACHE_PATH
os.environ["TRANSFORMERS_CACHE"] = MY_CACHE_PATH
os.environ["HF_HUB_CACHE"] = str(Path(MY_CACHE_PATH) / "hub")

# ç”±å¤–éƒ¨é˜Ÿåˆ—è°ƒåº¦å™¨åˆ†é… GPUï¼ˆrun_jina_reranker_queued.pyï¼‰ï¼›æ­¤æ—¶æœ¬è„šæœ¬ä¸åº”å†åšâ€œè·¨é¡¹ç›®çš„å…¨å±€ GPU æ§½ä½/è°ƒåº¦â€
EXTERNAL_GPU_SCHEDULER = os.environ.get("C2R_JINA_EXTERNAL_SCHEDULER", "").lower() in ("1", "true", "yes")


def _detect_local_snapshot():
    """è‡ªåŠ¨æ¢æµ‹ data/my-huggingface ä¸‹çš„æœ¬åœ° reranker æ¨¡å‹"""
    base = Path(os.environ.get(
        "JINA_RERANKER_CACHE_DIR",
        SCRIPT_DIR / "data" / "my-huggingface" / "models--jinaai--jina-reranker-v3"
    )).expanduser()
    snapshot_root = base / "snapshots"
    if not snapshot_root.exists():
        return None
    for candidate in sorted(snapshot_root.iterdir()):
        if candidate.is_dir() and (candidate / "config.json").exists():
            return candidate
    return None


def _resolve_model_path():
    """
    è·å–åº”è¯¥åŠ è½½çš„æ¨¡å‹è·¯å¾„ï¼š
    1. ä¼˜å…ˆä½¿ç”¨ JINA_RERANKER_LOCAL_DIR æŒ‡å®šçš„æœ¬åœ°ç›®å½•ï¼›
    2. å…¶æ¬¡ä½¿ç”¨ JINA_RERANKER_MODELï¼ˆè‹¥å…¶æŒ‡å‘æœ¬åœ°è·¯å¾„ï¼‰ï¼›
    3. å†æ¬¡å°è¯•è‡ªåŠ¨æ¢æµ‹ data/my-huggingface/snapshotsï¼›
    4. æœ€åå›é€€åˆ° huggingface idï¼ˆå¯é€šè¿‡ JINA_RERANKER_MODEL è¦†ç›–ï¼‰ã€‚
    """
    env_local = os.environ.get("JINA_RERANKER_LOCAL_DIR")
    env_model = os.environ.get("JINA_RERANKER_MODEL")

    for candidate in [env_local, env_model]:
        if candidate:
            candidate_path = Path(candidate).expanduser()
            if candidate_path.exists():
                return str(candidate_path), True

    detected = _detect_local_snapshot()
    if detected:
        return str(detected), True

    return env_model or DEFAULT_MODEL_ID, False


MODEL_NAME, MODEL_IS_LOCAL = _resolve_model_path()
# å¯é€šè¿‡ JINA_RERANKER_LOCAL_ONLY=0 å…è®¸å›é€€ç½‘ç»œ
LOCAL_ONLY = os.environ.get(
    "JINA_RERANKER_LOCAL_ONLY",
    "1" if MODEL_IS_LOCAL else "0"
).lower() not in ("0", "false", "no")

# å¤š GPU é…ç½®
NUM_GPUS = torch.cuda.device_count() if torch.cuda.is_available() else 1
USE_MULTI_GPU = NUM_GPUS > 1 and torch.cuda.is_available()

# GPU å†…å­˜é˜ˆå€¼é…ç½®ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡è°ƒæ•´ï¼‰
# å¯¹äº 49GB æ˜¾å­˜çš„ GPUï¼ˆå¦‚ RTX 5880 Adaï¼‰ï¼Œæ¯ä¸ª Jina Reranker çº¦éœ€ 6-8GB
# å› æ­¤æ¯ä¸ª GPU å¯ä»¥æ”¯æŒ 4-6 ä¸ªå¹¶è¡Œä»»åŠ¡
MIN_FREE_MEMORY_GB = float(os.environ.get("GPU_MIN_FREE_MEMORY_GB", "6.0"))  # é™ä½åˆ° 6GB
BATCH_SIZE_AUTO = os.environ.get("GPU_BATCH_SIZE_AUTO", "1").lower() in ("1", "true", "yes")

# é»˜è®¤æ¯ä¸ª GPU æœ€å¤§å¹¶è¡Œä»»åŠ¡æ•°
# å¯é€šè¿‡ JINA_MAX_SLOTS_PER_GPU ç¯å¢ƒå˜é‡è¦†ç›–
DEFAULT_MAX_SLOTS_PER_GPU = 3  # æ¯ä¸ª GPU æœ€å¤š 3 ä¸ªå¹¶è¡Œä»»åŠ¡ï¼Œé¿å…æ˜¾å­˜çˆ†ç‚¸

def get_gpu_free_memory(gpu_id: int) -> float:
    """è·å– GPU ç©ºé—²å†…å­˜ï¼ˆGBï¼‰"""
    if not torch.cuda.is_available():
        return 0.0

    # é¦–é€‰ï¼šCUDA runtime çš„ mem_get_infoï¼ˆä¸ä¾èµ– NVMLï¼›ä¸”åœ¨ CUDA_VISIBLE_DEVICES è¢«è®¾ç½®æ—¶è¯­ä¹‰æ­£ç¡®ï¼‰
    try:
        free_bytes, _total_bytes = torch.cuda.mem_get_info(gpu_id)
        return float(free_bytes) / (1024**3)
    except Exception:
        pass

    try:
        import subprocess
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=memory.free', '--format=csv,noheader,nounits', f'--id={gpu_id}'],
            capture_output=True, text=True, timeout=5
        )
        if result.returncode == 0:
            return float(result.stdout.strip()) / 1024  # MB -> GB
    except Exception:
        pass
    
    # å›é€€ï¼šä½¿ç”¨ PyTorch API
    try:
        props = torch.cuda.get_device_properties(gpu_id)
        allocated = torch.cuda.memory_allocated(gpu_id)
        return (props.total_memory - allocated) / (1024**3)
    except Exception:
        return 0.0

def get_gpu_running_tasks(gpu_id: int, max_slots: int = 2) -> int:
    """
    è·å–æŒ‡å®š GPU ä¸Šå½“å‰è¿è¡Œçš„ä»»åŠ¡æ•°ï¼ˆé€šè¿‡æ£€æŸ¥é”æ–‡ä»¶ï¼‰
    
    Args:
        gpu_id: GPU ID
        max_slots: æ¯ä¸ª GPU çš„æœ€å¤§æ§½ä½æ•°
    
    Returns:
        å½“å‰è¿è¡Œçš„ä»»åŠ¡æ•°
    """
    running_count = 0
    for slot_id in range(max_slots):
        lock_file_path = SCRIPT_DIR / f".jina_reranker_gpu{gpu_id}_slot{slot_id}.lock"
        if lock_file_path.exists():
            try:
                # å°è¯•éé˜»å¡è·å–é”
                lock_file = open(lock_file_path, 'r')
                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
                # æˆåŠŸè·å–é”è¯´æ˜æ§½ä½ç©ºé—²
                fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
                lock_file.close()
            except (IOError, OSError):
                # æ— æ³•è·å–é”è¯´æ˜æ§½ä½è¢«å ç”¨
                running_count += 1
            except Exception:
                pass
    return running_count


# GPU è°ƒåº¦é˜ˆå€¼é…ç½®
# å¯¹äº 50GB æ˜¾å­˜çš„ GPUï¼Œå½“ç©ºé—²å†…å­˜ä½äºæ­¤å€¼æ—¶ä¸å†åˆ†é…æ–°ä»»åŠ¡
MIN_FREE_MEMORY_FOR_NEW_TASK = float(os.environ.get("JINA_MIN_FREE_MEMORY_GB", "25.0"))

def get_best_gpu_for_task() -> int:
    """
    é€‰æ‹©æœ€é€‚åˆä»»åŠ¡çš„ GPUï¼ˆç»¼åˆè€ƒè™‘è¿è¡Œä»»åŠ¡æ•°å’Œç©ºé—²å†…å­˜ï¼‰
    
    è°ƒåº¦ç­–ç•¥ï¼š
    1. æ·»åŠ éšæœºå»¶è¿Ÿï¼Œé¿å…æ‰€æœ‰è¿›ç¨‹åŒæ—¶é€‰æ‹©åŒä¸€ GPU
    2. åªé€‰æ‹©ç©ºé—²å†…å­˜ >= 25GB çš„ GPUï¼ˆå¯é€šè¿‡ JINA_MIN_FREE_MEMORY_GB è°ƒæ•´ï¼‰
    3. ä¼˜å…ˆé€‰æ‹©è¿è¡Œä»»åŠ¡æœ€å°‘çš„ GPU
    4. ä»»åŠ¡æ•°ç›¸åŒæ—¶ï¼Œé€‰æ‹©ç©ºé—²å†…å­˜æœ€å¤šçš„ GPU

    Returns:
        GPU IDï¼Œå¦‚æœæ²¡æœ‰å¯ç”¨ GPU åˆ™è¿”å›ç©ºé—²å†…å­˜æœ€å¤šçš„
    """
    import random
    import time
    
    if not torch.cuda.is_available() or NUM_GPUS == 0:
        return 0

    # æ£€æŸ¥æ˜¯å¦é€šè¿‡ç¯å¢ƒå˜é‡æŒ‡å®šäº† GPU
    # æ³¨æ„ï¼šå½“ CUDA_VISIBLE_DEVICES è¢«è®¾ç½®åï¼ŒPyTorch åªèƒ½çœ‹åˆ°æœ‰é™çš„ GPU
    # è¿™äº› GPU çš„ç´¢å¼•ä» 0 å¼€å§‹ï¼Œä¸ç®¡ç‰©ç† GPU ID æ˜¯å¤šå°‘
    # ä¾‹å¦‚ï¼šCUDA_VISIBLE_DEVICES="2" æ„å‘³ç€ç‰©ç† GPU 2 å˜æˆäº† cuda:0
    cuda_visible = os.environ.get("CUDA_VISIBLE_DEVICES")
    if cuda_visible is not None and cuda_visible != "":
        # CUDA_VISIBLE_DEVICES è¢«è®¾ç½®ï¼Œè¿”å› 0ï¼ˆé€»è¾‘ GPU ç´¢å¼•ï¼‰
        return 0
    
    # æ·»åŠ éšæœºå»¶è¿Ÿï¼ˆ0-2ç§’ï¼‰ï¼Œé¿å…å¤šä¸ªè¿›ç¨‹åŒæ—¶å¯åŠ¨æ—¶éƒ½é€‰æ‹©åŒä¸€ GPU
    random_delay = random.uniform(0, 2.0)
    time.sleep(random_delay)

    # æ¯ä¸ª GPU æœ€å¤§æ§½ä½æ•°ï¼ˆä¿å®ˆè®¾ç½®ä¸º 2ï¼‰
    max_slots_per_gpu = int(os.environ.get("JINA_MAX_SLOTS_PER_GPU", "2"))
    
    # æ”¶é›†æ¯ä¸ª GPU çš„çŠ¶æ€
    gpu_status = []
    for gpu_id in range(NUM_GPUS):
        running_tasks = get_gpu_running_tasks(gpu_id, max_slots_per_gpu)
        free_memory = get_gpu_free_memory(gpu_id)
        # åŒæ—¶æ£€æŸ¥æ§½ä½å’Œå†…å­˜é˜ˆå€¼
        has_capacity = (running_tasks < max_slots_per_gpu) and (free_memory >= MIN_FREE_MEMORY_FOR_NEW_TASK)
        gpu_status.append({
            'gpu_id': gpu_id,
            'running_tasks': running_tasks,
            'free_memory': free_memory,
            'has_capacity': has_capacity
        })
    
    # æ‰“å°å½“å‰ GPU çŠ¶æ€ï¼ˆè°ƒè¯•ç”¨ï¼‰
    print(f"[GPU è°ƒåº¦] å½“å‰çŠ¶æ€ (å†…å­˜é˜ˆå€¼: {MIN_FREE_MEMORY_FOR_NEW_TASK}GB):")
    for status in gpu_status:
        slots_info = f"{status['running_tasks']}/{max_slots_per_gpu}"
        mem_info = f"{status['free_memory']:.1f}GB"
        capacity_info = "âœ“å¯ç”¨" if status['has_capacity'] else "âœ—æ»¡è½½"
        print(f"  GPU {status['gpu_id']}: æ§½ä½ {slots_info}, ç©ºé—² {mem_info}, {capacity_info}")
    
    # ä¼˜å…ˆé€‰æ‹©æœ‰å®¹é‡çš„ GPUï¼ˆæ§½ä½ + å†…å­˜éƒ½æ»¡è¶³ï¼‰
    available_gpus = [s for s in gpu_status if s['has_capacity']]
    
    if available_gpus:
        # æŒ‰ (è¿è¡Œä»»åŠ¡æ•°, -ç©ºé—²å†…å­˜) æ’åº
        available_gpus.sort(key=lambda x: (x['running_tasks'], -x['free_memory']))
        
        # å¦‚æœæœ‰å¤šä¸ª GPU ä»»åŠ¡æ•°ç›¸åŒï¼Œéšæœºé€‰æ‹©ä¸€ä¸ªï¼ˆé¿å…çƒ­ç‚¹ï¼‰
        min_tasks = available_gpus[0]['running_tasks']
        candidates = [g for g in available_gpus if g['running_tasks'] == min_tasks]
        
        if len(candidates) > 1:
            best = random.choice(candidates)
            print(f"[GPU è°ƒåº¦] ä» {len(candidates)} ä¸ªå€™é€‰ä¸­éšæœºé€‰æ‹© GPU {best['gpu_id']} (ä»»åŠ¡: {best['running_tasks']}, ç©ºé—²: {best['free_memory']:.1f}GB)")
        else:
            best = candidates[0]
            print(f"[GPU è°ƒåº¦] é€‰æ‹© GPU {best['gpu_id']} (ä»»åŠ¡: {best['running_tasks']}, ç©ºé—²: {best['free_memory']:.1f}GB)")
        return best['gpu_id']
    else:
        # æ‰€æœ‰ GPU éƒ½æ»¡è½½æˆ–å†…å­˜ä¸è¶³ï¼Œé€‰æ‹©ç©ºé—²å†…å­˜æœ€å¤šçš„ï¼ˆç­‰å¾…èµ„æºé‡Šæ”¾ï¼‰
        gpu_status.sort(key=lambda x: -x['free_memory'])
        best = gpu_status[0]
        print(f"[GPU è°ƒåº¦] âš  æ‰€æœ‰ GPU æ»¡è½½ï¼Œé€‰æ‹©å†…å­˜æœ€å¤šçš„ GPU {best['gpu_id']} (ç©ºé—²: {best['free_memory']:.1f}GB)")
        return best['gpu_id']

def get_adaptive_batch_size(gpu_id: int) -> int:
    """
    æ ¹æ® GPU ç©ºé—²å†…å­˜åŠ¨æ€è®¡ç®—æ‰¹é‡å¤§å°
    
    å¯¹äº Jina Reranker v3ï¼š
    - æ¨¡å‹æœ¬èº«çº¦éœ€ 4-5GB æ˜¾å­˜
    - æ¯ä¸ª batch item çº¦éœ€ 0.2-0.3GB æ˜¾å­˜ï¼ˆå–å†³äºæ–‡æœ¬é•¿åº¦ï¼‰
    
    Args:
        gpu_id: GPU ID
        
    Returns:
        å»ºè®®çš„æ‰¹é‡å¤§å°
    """
    if not BATCH_SIZE_AUTO:
        return 16  # é»˜è®¤æ‰¹é‡å¤§å°ï¼ˆæé«˜ï¼‰
    
    free_memory = get_gpu_free_memory(gpu_id)
    
    # ç•™å‡º 5GB ç»™æ¨¡å‹æœ¬èº«ï¼Œå‰©ä½™ç”¨äºæ‰¹é‡å¤„ç†
    available_for_batch = max(0, free_memory - 5.0)
    
    # æ¯ä¸ª batch item çº¦ 0.25GBï¼ˆæ›´æ¿€è¿›çš„ä¼°è®¡ï¼‰
    batch_size = int(available_for_batch / 0.25)
    
    # é™åˆ¶èŒƒå›´ï¼šæœ€å° 4ï¼Œæœ€å¤§ 64
    batch_size = max(4, min(64, batch_size))
    
    return batch_size

# å¤šé¡¹ç›®å¹¶è¡Œé…ç½®ï¼šæ¯ä¸ªé¡¹ç›®ä½¿ç”¨ä¸€ä¸ªGPU
# é€šè¿‡é¡¹ç›®åhashåˆ†é…GPUï¼Œç¡®ä¿ä¸åŒé¡¹ç›®ä½¿ç”¨ä¸åŒGPU
def get_project_gpu_id(project_name: str) -> int:
    """
    æ ¹æ®é¡¹ç›®ååˆ†é…GPU ID

    ä¼˜å…ˆçº§ï¼š
    1. ç¯å¢ƒå˜é‡ CUDA_VISIBLE_DEVICESï¼ˆè®¾ç½®ååªèƒ½çœ‹åˆ° 1 ä¸ª GPUï¼Œç´¢å¼•ä¸º 0ï¼‰
    2. é€‰æ‹©ç©ºé—²å†…å­˜æœ€å¤šçš„ GPU
    3. ä½¿ç”¨é¡¹ç›®å hash åˆ†é…

    Args:
        project_name: é¡¹ç›®åç§°

    Returns:
        åˆ†é…çš„GPU ID (0 åˆ° NUM_GPUS-1)
    """
    if not torch.cuda.is_available() or NUM_GPUS == 0:
        return 0

    # æ£€æŸ¥æ˜¯å¦é€šè¿‡ç¯å¢ƒå˜é‡æŒ‡å®šäº† GPU
    # æ³¨æ„ï¼šè®¾ç½® CUDA_VISIBLE_DEVICES åï¼Œå¯è§çš„ GPU ç´¢å¼•ä» 0 å¼€å§‹
    cuda_visible = os.environ.get("CUDA_VISIBLE_DEVICES")
    if cuda_visible is not None and cuda_visible != "":
        # CUDA_VISIBLE_DEVICES è¢«è®¾ç½®ï¼Œåªèƒ½çœ‹åˆ°æœ‰é™çš„ GPUï¼Œä½¿ç”¨ç´¢å¼• 0
        return 0
    
    # å°è¯•é€‰æ‹©ç©ºé—²å†…å­˜æœ€å¤šçš„ GPU
    best_gpu = get_best_gpu_for_task()
    
    # æ£€æŸ¥è¿™ä¸ª GPU æ˜¯å¦è¢«é”å®šï¼ˆå…¶ä»–é¡¹ç›®åœ¨ç”¨ï¼‰
    lock_file_path = Path(__file__).parent / f".jina_reranker_gpu{best_gpu}.lock"
    if lock_file_path.exists():
        # å°è¯•éé˜»å¡è·å–é”
        try:
            with open(lock_file_path, 'r') as f:
                fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
                fcntl.flock(f.fileno(), fcntl.LOCK_UN)
                # æˆåŠŸè·å–é”ï¼Œè¯´æ˜ GPU ç©ºé—²
                return best_gpu
        except (IOError, OSError):
            # GPU è¢«å ç”¨ï¼Œä½¿ç”¨ hash åˆ†é…
            pass
    else:
        return best_gpu
    
    # å›é€€ï¼šä½¿ç”¨é¡¹ç›®åçš„hashå€¼æ¥åˆ†é…GPU
    import hashlib
    hash_value = int(hashlib.md5(project_name.encode()).hexdigest(), 16)
    gpu_id = hash_value % NUM_GPUS
    return gpu_id

# è·å–å½“å‰é¡¹ç›®åˆ†é…çš„GPU
PROJECT_GPU_ID = get_project_gpu_id(PROJECT_NAME) if PROJECT_NAME else 0

# --- 1. åŠ è½½æ¨¡å‹ ---
def load_model(device_id=0, local_files_only=None, max_retries=3, retry_delay=5):
    """
    åŠ è½½ Jina reranker æ¨¡å‹åˆ°æŒ‡å®šçš„ GPU
    
    Args:
        device_id: GPU è®¾å¤‡ ID (0, 1, 2, 3...)
        local_files_only: æ˜¯å¦åªä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼ˆé¿å…é‡å¤ä¸‹è½½ï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆç”¨äºå¤„ç† OOMï¼‰
        retry_delay: é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
    
    Returns:
        åŠ è½½çš„æ¨¡å‹å’Œè®¾å¤‡
    """
    import time
    import gc
    
    print(f"[DEBUG] load_model å¼€å§‹: device_id={device_id}, local_files_only={local_files_only}, max_retries={max_retries}")
    device = torch.device(f"cuda:{device_id}" if torch.cuda.is_available() else "cpu")
    print(f"[DEBUG] ä½¿ç”¨è®¾å¤‡: {device}")
    if local_files_only is None:
        local_files_only = LOCAL_ONLY
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œå‡å°‘é‡å¤ä¸‹è½½æç¤º
    os.environ["HF_HUB_DISABLE_EXPERIMENTAL_WARNING"] = "1"
    
    last_error = None
    for attempt in range(max_retries):
        try:
            # åœ¨å°è¯•åŠ è½½å‰å…ˆæ¸…ç† GPU å†…å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                gc.collect()
                
                # æ£€æŸ¥ GPU å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆä»…åœ¨é‡è¯•æ—¶æ£€æŸ¥ï¼‰
                if attempt > 0:
                    try:
                        free_memory = torch.cuda.get_device_properties(device_id).total_memory - torch.cuda.memory_allocated(device_id)
                        free_gb = free_memory / (1024**3)
                        if free_gb < 8:  # å¦‚æœå¯ç”¨å†…å­˜å°‘äº 8GBï¼Œç­‰å¾…
                            print(f"[GPU {device_id}] å¯ç”¨å†…å­˜ä¸è¶³ ({free_gb:.1f}GB)ï¼Œç­‰å¾…...")
                            time.sleep(retry_delay)
                            torch.cuda.empty_cache()
                            gc.collect()
                    except Exception:
                        pass
    
            print(f"[DEBUG] å°è¯•åŠ è½½æ¨¡å‹ {MODEL_NAME} (attempt={attempt+1}/{max_retries})")
            model = AutoModel.from_pretrained(
                MODEL_NAME,
                dtype="auto",
                trust_remote_code=True,
                local_files_only=local_files_only,
            )
            print(f"[DEBUG] æ¨¡å‹åŠ è½½æˆåŠŸï¼Œç§»åŠ¨åˆ°è®¾å¤‡ {device}")
            model.to(device)
            model.eval()
            print(f"[DEBUG] æ¨¡å‹å·²å°±ç»ª")
            return model, device
            
        except (torch.cuda.OutOfMemoryError, RuntimeError) as e:
            last_error = e
            error_str = str(e).lower()
            if "out of memory" in error_str or "cuda" in error_str:
                print(f"[GPU {device_id}] åŠ è½½æ¨¡å‹å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): CUDA OOM")
                # æ¸…ç†å†…å­˜
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                gc.collect()
                
                if attempt < max_retries - 1:
                    # æŒ‡æ•°é€€é¿
                    wait_time = retry_delay * (2 ** attempt)
                    print(f"[GPU {device_id}] ç­‰å¾… {wait_time}s åé‡è¯•...")
                    time.sleep(wait_time)
            else:
                raise  # å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡º
    
    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºæœ€åçš„é”™è¯¯
    raise last_error

def preload_model():
    """
    ä¸»è¿›ç¨‹é¢„åŠ è½½æ¨¡å‹ï¼ˆç¡®ä¿æ¨¡å‹å·²ä¸‹è½½åˆ°æœ¬åœ°ç¼“å­˜ï¼‰
    è¿™æ ·å­è¿›ç¨‹å°±å¯ä»¥ä½¿ç”¨ local_files_only=True é¿å…é‡å¤ä¸‹è½½
    
    æ³¨æ„ï¼šé¢„åŠ è½½æ—¶ä½¿ç”¨ CPU è€Œä¸æ˜¯ GPUï¼Œä»¥é¿å…ä¸åç»­ worker è¿›ç¨‹äº‰æŠ¢ GPU å†…å­˜
    """
    print(f"æ­£åœ¨é¢„åŠ è½½ reranker æ¨¡å‹: {MODEL_NAME}")
    if LOCAL_ONLY and not Path(MODEL_NAME).exists():
        print(f"é”™è¯¯: æœªæ‰¾åˆ°æœ¬åœ°æ¨¡å‹ç›®å½• {MODEL_NAME}ï¼Œè¯·æ£€æŸ¥ JINA_RERANKER_LOCAL_DIR/JINA_RERANKER_MODEL è®¾ç½®")
        return False
    
    # æ£€æŸ¥ GPU å†…å­˜æ˜¯å¦å·²è¢«å ç”¨ï¼Œå¦‚æœæ˜¯åˆ™è·³è¿‡é¢„åŠ è½½
    if torch.cuda.is_available():
        try:
            allocated = torch.cuda.memory_allocated(0)
            if allocated > 1e9:  # è¶…è¿‡ 1GB å·²è¢«å ç”¨
                print(f"GPU 0 å·²æœ‰ {allocated / 1e9:.2f}GB å†…å­˜è¢«å ç”¨ï¼Œè·³è¿‡é¢„åŠ è½½ä»¥é¿å… OOM")
                return True  # è¿”å› True è¡¨ç¤ºå¯ä»¥ç»§ç»­ï¼Œworker ä¼šè‡ªå·±åŠ è½½
        except Exception:
            pass
    
    try:
        # ä½¿ç”¨ CPU è¿›è¡Œé¢„åŠ è½½ï¼Œé¿å…å ç”¨ GPU å†…å­˜
        # è¿™æ ·åªæ˜¯ç¡®ä¿æ¨¡å‹æ–‡ä»¶å·²ä¸‹è½½åˆ°æœ¬åœ°ç¼“å­˜
        device = torch.device("cpu")
        print("ä½¿ç”¨ CPU è¿›è¡Œæ¨¡å‹é¢„åŠ è½½ï¼ˆä»…éªŒè¯ç¼“å­˜ï¼Œé¿å…å ç”¨ GPU å†…å­˜ï¼‰...")
        model = AutoModel.from_pretrained(
            MODEL_NAME,
            dtype="auto",
            trust_remote_code=True,
            local_files_only=LOCAL_ONLY,
        )
        model.to(device)
        model.eval()
        del model  # é‡Šæ”¾å†…å­˜
        
        # å¦‚æœæœ‰ CUDAï¼Œæ¸…ç†ç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        import gc
        gc.collect()
        
        print("æ¨¡å‹é¢„åŠ è½½å®Œæˆï¼Œå·²ç¼“å­˜åˆ°æœ¬åœ°")
        return True
    except Exception as e:
        print(f"æ¨¡å‹é¢„åŠ è½½å¤±è´¥: {e}")
        # é¢„åŠ è½½å¤±è´¥ä¸åº”é˜»æ­¢ç¨‹åºç»§ç»­ï¼Œworker å¯èƒ½ä»èƒ½å·¥ä½œ
        return True  # è¿”å› True è®©ç¨‹åºç»§ç»­

# --- 2. é‡æ’é€»è¾‘ ---
# Jina Reranker v3 çš„ token é™åˆ¶æ˜¯ 131072
# ä»£ç çº¦ 3-4 å­—ç¬¦/tokenï¼Œé¢„ç•™ 10% å®‰å…¨è¾¹é™…
JINA_MAX_TOKENS = 131072
JINA_SAFE_MAX_TOKENS = int(JINA_MAX_TOKENS * 0.9)  # çº¦ 118000 tokens
CHARS_PER_TOKEN = 4  # ä»£ç çº¦ 4 å­—ç¬¦/token

# é¢„é˜²æ€§æˆªæ–­é˜ˆå€¼
# æ€»å­—ç¬¦æ•°é™åˆ¶ï¼šçº¦ 118000 tokens * 4 chars/token = 472000 chars
MAX_TOTAL_CHARS = JINA_SAFE_MAX_TOKENS * CHARS_PER_TOKEN

# ç­–ç•¥ï¼šQuery ä¸é™åˆ¶ï¼ŒDocuments æŒ‰ç›¸å…³æ€§é¡ºåºæ·»åŠ ç›´åˆ°è¾¾åˆ°é™åˆ¶
# è¿™æ ·å¯ä»¥ä¿è¯æŸ¥è¯¢å®Œæ•´ï¼ŒåŒæ—¶å°½å¯èƒ½å¤šåœ°åŒ…å«ç›¸å…³æ–‡æ¡£

# Token è¶…é•¿æ—¶çš„å›é€€æˆªæ–­é˜ˆå€¼ï¼ˆæ›´æ¿€è¿›ï¼Œç”¨äºå‡ºé”™åé‡è¯•ï¼‰
FALLBACK_MAX_QUERY_CHARS = 50000   # query å›é€€æˆªæ–­é˜ˆå€¼ï¼ˆé€šå¸¸ä¸ä¼šè§¦å‘ï¼‰
FALLBACK_MAX_DOC_CHARS = 20000     # æ¯ä¸ª document å›é€€æˆªæ–­é˜ˆå€¼

def truncate_text(text: str, max_chars: int) -> str:
    """
    æˆªæ–­è¿‡é•¿çš„æ–‡æœ¬
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        max_chars: æœ€å¤§å­—ç¬¦æ•°
        
    Returns:
        æˆªæ–­åçš„æ–‡æœ¬
    """
    if len(text) <= max_chars:
        return text
    # ä¿ç•™å¼€å¤´éƒ¨åˆ†ï¼ˆå‡½æ•°ç­¾åå’Œä¸»è¦é€»è¾‘é€šå¸¸åœ¨å¼€å¤´ï¼‰
    return text[:max_chars] + "\n... [truncated]"

def truncate_for_rerank(query: str, documents: list, 
                        max_query_chars: int = FALLBACK_MAX_QUERY_CHARS, 
                        max_doc_chars: int = FALLBACK_MAX_DOC_CHARS) -> tuple:
    """
    æˆªæ–­ query å’Œ documentsï¼ˆä»…åœ¨éœ€è¦æ—¶è°ƒç”¨ï¼‰
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬
        documents: æ–‡æ¡£åˆ—è¡¨
        max_query_chars: query æœ€å¤§å­—ç¬¦æ•°
        max_doc_chars: æ¯ä¸ª document æœ€å¤§å­—ç¬¦æ•°
        
    Returns:
        (truncated_query, truncated_documents)
    """
    truncated_query = truncate_text(query, max_query_chars)
    truncated_docs = [truncate_text(doc, max_doc_chars) for doc in documents]
    return truncated_query, truncated_docs

def estimate_tokens(text: str) -> int:
    """ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡"""
    return len(text) // CHARS_PER_TOKEN if text else 0

def preemptive_truncate_for_rerank(query: str, documents: list) -> tuple:
    """
    é¢„é˜²æ€§æˆªæ–­ï¼Œåœ¨è°ƒç”¨ rerank ä¹‹å‰å°±ç¡®ä¿ä¸è¶…è¿‡æ¨¡å‹é™åˆ¶
    
    ç­–ç•¥ï¼š
    1. Query å®Œæ•´ä¿ç•™ï¼ˆä¸åšä»»ä½•é™åˆ¶ï¼Œå› ä¸ºè¿™æ˜¯æˆ‘ä»¬çš„ç›®æ ‡æŸ¥è¯¢å†…å®¹ï¼‰
    2. Documents ä» BM25 ç­›é€‰çš„æœ€ç›¸å…³çš„å¼€å§‹æ·»åŠ 
    3. ä¸€ç›´æ·»åŠ ç›´åˆ°ï¼šæ·»åŠ å®Œæˆ æˆ–è€… æ·»åŠ åä¼šè¶…è¿‡æœ€å¤§ token é™åˆ¶
    
    è¿™æ ·å¯ä»¥ä¿è¯ï¼š
    - æŸ¥è¯¢å‡½æ•°å®Œæ•´æ€§
    - å°½å¯èƒ½å¤šåœ°åŒ…å«ç›¸å…³æ–‡æ¡£ï¼ˆæŒ‰ç›¸å…³æ€§æ’åºï¼‰
    - ä¸è¶…è¿‡æ¨¡å‹é™åˆ¶
    
    Jina Reranker v3 çš„é™åˆ¶æ˜¯ 131072 tokens
    æˆ‘ä»¬é¢„ç•™ 10% å®‰å…¨è¾¹é™…ï¼Œç›®æ ‡æ˜¯ ~118000 tokens
    
    Args:
        query: æŸ¥è¯¢æ–‡æœ¬ï¼ˆå®Œæ•´ä¿ç•™ï¼‰
        documents: æ–‡æ¡£åˆ—è¡¨ï¼ˆæŒ‰ BM25 ç›¸å…³æ€§æ’åºï¼Œç´¢å¼• 0 æœ€ç›¸å…³ï¼‰
        
    Returns:
        (query, selected_documents, original_indices, was_truncated)
        - query: åŸå§‹ queryï¼ˆä¸æˆªæ–­ï¼‰
        - selected_documents: é€‰ä¸­çš„æ–‡æ¡£åˆ—è¡¨
        - original_indices: é€‰ä¸­æ–‡æ¡£åœ¨åŸå§‹åˆ—è¡¨ä¸­çš„ç´¢å¼•
        - was_truncated: æ˜¯å¦è¿›è¡Œäº†æˆªæ–­
    """
    if not documents:
        return query, [], [], False
    
    # Query å®Œæ•´ä¿ç•™ï¼Œä¸åšæˆªæ–­
    query_tokens = estimate_tokens(query)
    
    # è®¡ç®— documents å¯ç”¨çš„ token é¢„ç®—
    remaining_tokens = JINA_SAFE_MAX_TOKENS - query_tokens
    
    if remaining_tokens <= 0:
        # Query æœ¬èº«å°±è¶…è¿‡äº†é™åˆ¶ï¼Œä½†æˆ‘ä»¬ä»ç„¶ä¿ç•™å®Œæ•´ query
        # åªæ·»åŠ ç¬¬ä¸€ä¸ªæ–‡æ¡£ï¼ˆæœ€ç›¸å…³çš„ï¼‰å¹¶æˆªæ–­
        print(f"  âš  Query è¿‡é•¿ (~{query_tokens} tokens)ï¼Œåªä¿ç•™æœ€ç›¸å…³çš„ 1 ä¸ªæ–‡æ¡£")
        first_doc = documents[0]
        # ç»™æ–‡æ¡£ç•™ä¸€ç‚¹ç©ºé—´ï¼ˆè‡³å°‘ 1000 tokensï¼‰
        max_doc_chars = max(4000, remaining_tokens * CHARS_PER_TOKEN)
        truncated_doc = truncate_text(first_doc, max_doc_chars)
        return query, [truncated_doc], [0], True
    
    # ä»æœ€ç›¸å…³çš„å¼€å§‹æ·»åŠ æ–‡æ¡£ï¼Œç›´åˆ°è¾¾åˆ° token é™åˆ¶
    selected_docs = []
    selected_indices = []
    current_tokens = query_tokens
    
    for idx, doc in enumerate(documents):
        doc_tokens = estimate_tokens(doc)
        
        # æ£€æŸ¥æ·»åŠ è¿™ä¸ªæ–‡æ¡£åæ˜¯å¦ä¼šè¶…è¿‡é™åˆ¶
        if current_tokens + doc_tokens <= JINA_SAFE_MAX_TOKENS:
            # å¯ä»¥å®Œæ•´æ·»åŠ 
            selected_docs.append(doc)
            selected_indices.append(idx)
            current_tokens += doc_tokens
        else:
            # æ·»åŠ åä¼šè¶…è¿‡é™åˆ¶
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å‰©ä½™ç©ºé—´å¯ä»¥æ·»åŠ æˆªæ–­ç‰ˆæœ¬
            remaining_chars = (JINA_SAFE_MAX_TOKENS - current_tokens) * CHARS_PER_TOKEN
            
            if remaining_chars >= 2000:  # è‡³å°‘è¦æœ‰ 2000 å­—ç¬¦ï¼ˆçº¦ 500 tokensï¼‰æ‰å€¼å¾—æ·»åŠ 
                # æˆªæ–­å½“å‰æ–‡æ¡£å¹¶æ·»åŠ 
                truncated_doc = truncate_text(doc, remaining_chars)
                selected_docs.append(truncated_doc)
                selected_indices.append(idx)
            
            # è¾¾åˆ°é™åˆ¶ï¼Œåœæ­¢æ·»åŠ 
            break
    
    was_truncated = len(selected_docs) < len(documents)
    
    return query, selected_docs, selected_indices, was_truncated

def is_token_length_error(error: Exception) -> bool:
    """æ£€æŸ¥æ˜¯å¦æ˜¯ token è¶…é•¿é”™è¯¯"""
    error_msg = str(error).lower()
    return ('token' in error_msg and 'length' in error_msg) or \
           ('sequence length' in error_msg) or \
           ('longer than' in error_msg and 'maximum' in error_msg)

def is_cuda_oom_error(error: Exception) -> bool:
    """æ£€æŸ¥æ˜¯å¦æ˜¯ CUDA OOM é”™è¯¯"""
    error_msg = str(error).lower()
    return 'cuda out of memory' in error_msg or 'out of memory' in error_msg

def clear_cuda_cache():
    """æ¸…ç† CUDA ç¼“å­˜"""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        import gc
        gc.collect()

def reorder_with_jina(model, query_function: str, c_code_documents: list) -> list:
    """
    ä½¿ç”¨ Jina-reranker å¯¹ BM25 æ£€ç´¢åˆ°çš„ C ä»£ç è¿›è¡Œé‡æ’ã€‚
    
    ç­–ç•¥ï¼š
    1. Query å®Œæ•´ä¿ç•™ï¼ˆä¸æˆªæ–­ï¼‰
    2. Documents ä»æœ€ç›¸å…³çš„å¼€å§‹æ·»åŠ ï¼Œç›´åˆ°è¾¾åˆ° token é™åˆ¶
    3. å¦‚æœä»é‡åˆ° token è¶…é•¿é”™è¯¯ï¼Œå›é€€åˆ°æ›´æ¿€è¿›çš„æˆªæ–­é‡è¯•
    
    Args:
        model: åŠ è½½çš„ jina-reranker-v3 æ¨¡å‹
        query_function: åŸå§‹ C++ æŸ¥è¯¢å‡½æ•°ï¼ˆå®Œæ•´ä¿ç•™ï¼‰
        c_code_documents: ä» BM25 ç»“æœä¸­æå–çš„ C ä»£ç èŒƒä¾‹åˆ—è¡¨ï¼ˆæŒ‰ç›¸å…³æ€§æ’åºï¼‰
        
    Returns:
        ä¸€ä¸ªé‡æ’åçš„åˆ—è¡¨ï¼ŒåŒ…å« (score, original_index)
        æ³¨æ„ï¼šoriginal_index æ˜¯ç›¸å¯¹äºåŸå§‹ c_code_documents çš„ç´¢å¼•
    """
    if not c_code_documents:
        return []
    
    # é¢„é˜²æ€§æˆªæ–­ï¼ˆé¿å…è¶…è¿‡æ¨¡å‹é™åˆ¶ï¼‰
    # Query å®Œæ•´ä¿ç•™ï¼ŒDocuments ä»æœ€ç›¸å…³çš„å¼€å§‹æ·»åŠ 
    query, selected_docs, selected_indices, was_truncated = preemptive_truncate_for_rerank(
        query_function, c_code_documents
    )
    
    if was_truncated:
        num_orig = len(c_code_documents)
        num_selected = len(selected_docs)
        if num_selected < num_orig:
            print(f"  ğŸ“ æ–‡æ¡£ç­›é€‰: {num_orig} -> {num_selected} ä¸ª (ä¿ç•™æœ€ç›¸å…³çš„)")
    
    if not selected_docs:
        return []
    
    # ç¬¬ä¸€æ¬¡å°è¯•
    try:
        with torch.no_grad():
            results = model.rerank(
                query=query,
                documents=selected_docs,
                top_n=min(TOP_K, len(selected_docs))
            )
    except Exception as e:
        if is_token_length_error(e):
            # ä»ç„¶è¶…é•¿ï¼Œå›é€€åˆ°æ›´æ¿€è¿›çš„æˆªæ–­
            truncated_query, truncated_docs = truncate_for_rerank(query, selected_docs)
            total_chars = len(truncated_query) + sum(len(d) for d in truncated_docs)
            print(f"  âš  Token ä»è¶…é•¿ï¼Œæ¿€è¿›æˆªæ–­åé‡è¯• ({total_chars//1000}K chars)")
            
            with torch.no_grad():
                results = model.rerank(
                    query=truncated_query,
                    documents=truncated_docs,
                    top_n=min(TOP_K, len(truncated_docs))
                )
        else:
            raise  # å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡º
        
    # 'results' æ˜¯ä¸€ä¸ªåˆ—è¡¨: [{'index': 5, 'relevance_score': 0.95}, ...]
    # æ³¨æ„ï¼šres['index'] æ˜¯ç›¸å¯¹äº selected_docs çš„ç´¢å¼•
    # éœ€è¦æ˜ å°„å›åŸå§‹ c_code_documents çš„ç´¢å¼•
    reranked_results = []
    for res in results:
        selected_idx = res['index']  # åœ¨ selected_docs ä¸­çš„ç´¢å¼•
        # æ˜ å°„å›åŸå§‹ç´¢å¼•
        original_idx = selected_indices[selected_idx] if selected_idx < len(selected_indices) else selected_idx
        reranked_results.append({
            "score": res['relevance_score'],
            "original_index": original_idx
        })
    return reranked_results


def batch_reorder_with_jina(model, batch_data: list) -> list:
    """
    æ‰¹é‡ä½¿ç”¨ Jina-reranker å¯¹å¤šä¸ª query è¿›è¡Œé‡æ’ã€‚
    
    ç­–ç•¥ï¼š
    1. Query å®Œæ•´ä¿ç•™ï¼ŒDocuments ä»æœ€ç›¸å…³çš„å¼€å§‹æ·»åŠ ç›´åˆ°è¾¾åˆ° token é™åˆ¶
    2. å¦‚æœä»é‡åˆ° token è¶…é•¿é”™è¯¯ï¼Œå›é€€åˆ°æ›´æ¿€è¿›çš„æˆªæ–­é‡è¯•
    3. é‡åˆ° OOM é”™è¯¯æ—¶ï¼Œæ¸…ç†ç¼“å­˜åç”¨æˆªæ–­ç‰ˆæœ¬é‡è¯•
    
    Args:
        model: åŠ è½½çš„ jina-reranker-v3 æ¨¡å‹
        batch_data: åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ (query_function, c_code_documents)
        
    Returns:
        åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯å¯¹åº” query çš„é‡æ’ç»“æœï¼ˆç´¢å¼•æ˜ å°„å›åŸå§‹æ–‡æ¡£åˆ—è¡¨ï¼‰
    """
    results_list = []
    
    with torch.no_grad():
        for query_function, c_code_documents in batch_data:
            if not c_code_documents:
                results_list.append([])
                continue
            
            try:
                results = None
                
                # é¢„é˜²æ€§æˆªæ–­ï¼ˆé¿å…è¶…è¿‡æ¨¡å‹é™åˆ¶ï¼‰
                # Query å®Œæ•´ä¿ç•™ï¼ŒDocuments ä»æœ€ç›¸å…³çš„å¼€å§‹æ·»åŠ 
                query, selected_docs, selected_indices, was_truncated = preemptive_truncate_for_rerank(
                    query_function, c_code_documents
                )
                
                if not selected_docs:
                    results_list.append([])
                    continue
                
                # ç¬¬ä¸€æ¬¡å°è¯•
                try:
                    results = model.rerank(
                        query=query,
                        documents=selected_docs,
                        top_n=min(TOP_K, len(selected_docs))
                    )
                except Exception as e:
                    if is_token_length_error(e):
                        # ä»ç„¶è¶…é•¿ï¼Œå›é€€åˆ°æ›´æ¿€è¿›çš„æˆªæ–­
                        truncated_query, truncated_docs = truncate_for_rerank(query, selected_docs)
                        results = model.rerank(
                            query=truncated_query,
                            documents=truncated_docs,
                            top_n=min(TOP_K, len(truncated_docs))
                        )
                    elif is_cuda_oom_error(e):
                        # OOM é”™è¯¯ï¼Œæ¸…ç†ç¼“å­˜åç”¨æˆªæ–­ç‰ˆæœ¬é‡è¯•
                        clear_cuda_cache()
                        truncated_query, truncated_docs = truncate_for_rerank(
                            query, selected_docs,
                            max_query_chars=50000,  # Query ä¿æŒå®Œæ•´
                            max_doc_chars=15000     # æ›´æ¿€è¿›çš„æ–‡æ¡£æˆªæ–­
                        )
                        try:
                            results = model.rerank(
                                query=truncated_query,
                                documents=truncated_docs,
                                top_n=min(TOP_K, len(truncated_docs))
                            )
                        except Exception:
                            # ä»ç„¶å¤±è´¥ï¼Œè·³è¿‡æ­¤ query
                            results_list.append([])
                            continue
                    else:
                        raise
                
                # å°† rerank ç»“æœçš„ç´¢å¼•æ˜ å°„å›åŸå§‹æ–‡æ¡£ç´¢å¼•
                reranked_results = []
                for res in results:
                    selected_idx = res['index']  # åœ¨ selected_docs ä¸­çš„ç´¢å¼•
                    # æ˜ å°„å›åŸå§‹ç´¢å¼•
                    original_idx = selected_indices[selected_idx] if selected_idx < len(selected_indices) else selected_idx
                    reranked_results.append({
                        "score": res['relevance_score'],
                        "original_index": original_idx
                    })
                results_list.append(reranked_results)
            except Exception as e:
                print(f"Batch rerank å•ä¸ª query å¤±è´¥: {e}")
                results_list.append([])
    
    return results_list

# --- 3. æ–‡ä»¶è§£æä¸ä¸»å¾ªç¯ ---
def parse_bm25_file(file_content: str):
    """
    è§£æ elastic_search.py è¾“å‡ºçš„æ–‡ä»¶
    [V10 å‡çº§] æ”¯æŒè§£æ extracted_knowledge å­—æ®µ
    """
    try:
        header, rest = file_content.split("-" * 50 + "\n", 1)
        query_function = header.replace("target function is :", "").strip()
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– C å’Œ Rust ä»£ç å—
        c_pattern = re.compile(r"\[C_CODE\]\n(.*?)\n\[/C_CODE\]", re.DOTALL)
        r_pattern = re.compile(r"\[RUST_CODE\]\n(.*?)\n\[/RUST_CODE\]", re.DOTALL)
        k_pattern = re.compile(r"\[EXTRACTED_KNOWLEDGE\]\n(.*?)\n\[/EXTRACTED_KNOWLEDGE\]", re.DOTALL)
        
        c_docs = c_pattern.findall(rest)
        r_docs = r_pattern.findall(rest)
        k_docs = k_pattern.findall(rest)
        
        if len(c_docs) != len(r_docs):
            print(f"è­¦å‘Š: C/Rust ä»£ç å—æ•°é‡ä¸åŒ¹é…ã€‚ C: {len(c_docs)}, Rust: {len(r_docs)}")
            return query_function, [], [], []
        
        # è§£æçŸ¥è¯† JSONï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        knowledge_list = []
        for k_str in k_docs:
            try:
                knowledge_list.append(json.loads(k_str))
            except json.JSONDecodeError:
                knowledge_list.append([])
        
        # å¦‚æœçŸ¥è¯†åˆ—è¡¨é•¿åº¦ä¸åŒ¹é…ï¼Œç”¨ç©ºåˆ—è¡¨è¡¥é½
        while len(knowledge_list) < len(c_docs):
            knowledge_list.append([])
            
        return query_function, c_docs, r_docs, knowledge_list
        
    except Exception as e:
        print(f"é”™è¯¯: è§£æ BM25 æ–‡ä»¶å¤±è´¥: {e}")
        return None, [], [], []

def load_file_data(query_file, project_out_path):
    """
    åŠ è½½å•ä¸ªæ–‡ä»¶çš„æ•°æ®ï¼ˆç”¨äºå¹¶è¡Œ I/Oï¼‰
    
    Returns:
        (query_file, query_func, c_docs_list, r_docs_list, k_docs_list) æˆ– Noneï¼ˆå¦‚æœæ–‡ä»¶å·²å­˜åœ¨æˆ–å¤±è´¥ï¼‰
    """
    output_file_path = project_out_path / query_file.name
    
    # è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶
    if output_file_path.exists():
        return None
    
    try:
        with open(query_file, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()
    except Exception as e:
        return None
    
    query_func, c_docs_list, r_docs_list, k_docs_list = parse_bm25_file(content)
    
    if not query_func or not c_docs_list:
        return None
    
    return (query_file, query_func, c_docs_list, r_docs_list, k_docs_list)


def save_rerank_result(query_file, reranked_results, c_docs_list, r_docs_list, k_docs_list, project_out_path):
    """
    ä¿å­˜é‡æ’ç»“æœï¼ˆç”¨äºå¹¶è¡Œ I/Oï¼‰
    """
    output_file_path = project_out_path / query_file.name
    
    try:
        with open(output_file_path, 'w', encoding='utf-8') as f:
            for res in reranked_results:
                score = res['score']
                idx = res['original_index']
                c_code = c_docs_list[idx]
                rust_code = r_docs_list[idx]
                knowledge = k_docs_list[idx] if idx < len(k_docs_list) else []
                
                f.write(f"C_Code: \n{c_code}\n")
                f.write(f"Function: \n{rust_code}\n")
                
                if knowledge:
                    f.write(f"Extracted_Knowledge: \n{json.dumps(knowledge, ensure_ascii=False)}\n")
                
                f.write(f"Unixcoder Score: {score}\n")
                f.write("-" * 50 + "\n")
        return True
    except Exception as e:
        print(f"ä¿å­˜ç»“æœå¤±è´¥ {query_file}: {e}")
        return False


def efficient_batch_process(model, query_files, project_in_path, project_out_path, batch_size=8, num_io_workers=4):
    """
    é«˜æ•ˆæ‰¹é‡å¤„ç†ï¼šå•æ¨¡å‹å®ä¾‹ + å¤šçº¿ç¨‹ I/O + æ‰¹é‡æ¨ç†
    
    è¿™ç§æ–¹å¼æ¯”å¤šè¿›ç¨‹åŠ è½½å¤šä¸ªæ¨¡å‹æ›´é«˜æ•ˆï¼š
    1. åªåŠ è½½ä¸€ä¸ªæ¨¡å‹ï¼ŒèŠ‚çœæ˜¾å­˜
    2. å¤šçº¿ç¨‹å¹¶è¡Œè¯»å–æ–‡ä»¶ï¼ˆI/O å¯†é›†å‹ï¼Œä¸éœ€è¦å¤šè¿›ç¨‹ï¼‰
    3. æ‰¹é‡æ¨ç†ï¼Œæé«˜ GPU åˆ©ç”¨ç‡
    4. å¤šçº¿ç¨‹å¹¶è¡Œå†™å…¥ç»“æœ
    
    Args:
        model: å·²åŠ è½½çš„æ¨¡å‹
        query_files: å¾…å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
        project_in_path: è¾“å…¥è·¯å¾„
        project_out_path: è¾“å‡ºè·¯å¾„
        batch_size: æ‰¹é‡å¤§å°ï¼ˆåŒæ—¶å¤„ç†çš„ query æ•°é‡ï¼‰
        num_io_workers: I/O çº¿ç¨‹æ•°
    """
    from concurrent.futures import ThreadPoolExecutor, as_completed
    import gc
    
    total_files = len(query_files)
    processed = 0
    failed = 0
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè¯»å–æ–‡ä»¶
    with ThreadPoolExecutor(max_workers=num_io_workers) as io_executor:
        # åˆ†æ‰¹å¤„ç†
        for batch_start in range(0, total_files, batch_size):
            batch_end = min(batch_start + batch_size, total_files)
            batch_files = query_files[batch_start:batch_end]
            
            # 1. å¹¶è¡Œè¯»å–è¿™ä¸€æ‰¹æ–‡ä»¶
            load_futures = {
                io_executor.submit(load_file_data, qf, project_out_path): qf 
                for qf in batch_files
            }
            
            batch_data = []
            file_metadata = []  # ä¿å­˜æ¯ä¸ªæ–‡ä»¶çš„å…ƒæ•°æ®ï¼Œç”¨äºå†™å…¥ç»“æœ
            
            for future in as_completed(load_futures):
                result = future.result()
                if result is not None:
                    query_file, query_func, c_docs_list, r_docs_list, k_docs_list = result
                    batch_data.append((query_func, c_docs_list))
                    file_metadata.append({
                        'query_file': query_file,
                        'c_docs_list': c_docs_list,
                        'r_docs_list': r_docs_list,
                        'k_docs_list': k_docs_list
                    })
            
            if not batch_data:
                processed += len(batch_files)
                continue
            
            # 2. æ‰¹é‡æ¨ç†
            try:
                rerank_results = batch_reorder_with_jina(model, batch_data)
            except Exception as e:
                print(f"æ‰¹é‡æ¨ç†å¤±è´¥: {e}")
                torch.cuda.empty_cache()
                gc.collect()
                failed += len(batch_data)
                processed += len(batch_files)
                continue
            
            # 3. å¹¶è¡Œå†™å…¥ç»“æœ
            save_futures = []
            for i, (metadata, results) in enumerate(zip(file_metadata, rerank_results)):
                if results:  # åªå†™å…¥æœ‰ç»“æœçš„æ–‡ä»¶
                    future = io_executor.submit(
                        save_rerank_result,
                        metadata['query_file'],
                        results,
                        metadata['c_docs_list'],
                        metadata['r_docs_list'],
                        metadata['k_docs_list'],
                        project_out_path
                    )
                    save_futures.append(future)
            
            # ç­‰å¾…å†™å…¥å®Œæˆ
            for future in as_completed(save_futures):
                if not future.result():
                    failed += 1
            
            processed += len(batch_files)
            
            # å®šæœŸæ¸…ç† GPU å†…å­˜
            if processed % (batch_size * 10) == 0:
                torch.cuda.empty_cache()
                gc.collect()
    
    return processed, failed


def process_worker(device_id, file_queue, result_queue, project_in_path, project_out_path, load_failed_event=None):
    """
    å·¥ä½œè¿›ç¨‹ï¼šå¤„ç†åˆ†é…ç»™å®ƒçš„æ–‡ä»¶
    
    Args:
        device_id: GPU è®¾å¤‡ ID
        file_queue: æ–‡ä»¶é˜Ÿåˆ—
        result_queue: ç»“æœé˜Ÿåˆ—ï¼ˆç”¨äºè¿›åº¦è·Ÿè¸ªï¼‰
        project_in_path: è¾“å…¥è·¯å¾„
        project_out_path: è¾“å‡ºè·¯å¾„
        load_failed_event: å¯é€‰çš„äº‹ä»¶ï¼Œç”¨äºé€šçŸ¥æ¨¡å‹åŠ è½½å¤±è´¥
    """
    import time
    import gc
    
    try:
        # ç¡®ä¿å­è¿›ç¨‹ä¹Ÿè®¾ç½®æ­£ç¡®çš„ç¼“å­˜è·¯å¾„
        os.environ["HF_HOME"] = MY_CACHE_PATH
        os.environ["TRANSFORMERS_CACHE"] = MY_CACHE_PATH
        os.environ["HF_HUB_CACHE"] = str(Path(MY_CACHE_PATH) / "hub")
        
        # é”™å¼€å¯åŠ¨æ—¶é—´ï¼Œé¿å…æ‰€æœ‰ GPU åŒæ—¶åŠ è½½æ¨¡å‹å¯¼è‡´ OOM
        # åªéœ€è¦è½»å¾®é”™å¼€ï¼ˆ1ç§’ï¼‰ï¼Œé¿å…åŒæ—¶åˆ†é…å¤§å—å†…å­˜
        startup_delay = device_id * 1  # æ¯ä¸ª GPU é”™å¼€ 1 ç§’
        if startup_delay > 0:
            time.sleep(startup_delay)
        
        # æ¸…ç† GPU å†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            gc.collect()
        
        # æ¯ä¸ªè¿›ç¨‹åŠ è½½è‡ªå·±çš„æ¨¡å‹å®ä¾‹
        # ä½¿ç”¨æœ¬åœ°ç¼“å­˜åŠ è½½æ¨¡å‹ï¼ˆä¸»è¿›ç¨‹å·²é¢„åŠ è½½ï¼‰
        try:
            model, device = load_model(device_id, local_files_only=True, max_retries=3, retry_delay=15)
            print(f"[GPU {device_id}] æ¨¡å‹åŠ è½½å®Œæˆ")
        except Exception as e:
            print(f"[GPU {device_id}] æ¨¡å‹åŠ è½½æœ€ç»ˆå¤±è´¥: {e}")
            # é€šçŸ¥ä¸»è¿›ç¨‹åŠ è½½å¤±è´¥
            if load_failed_event:
                load_failed_event.set()
            # å°†é˜Ÿåˆ—ä¸­å‰©ä½™çš„æ–‡ä»¶æ ‡è®°ä¸ºå¤±è´¥
            while True:
                try:
                    item = file_queue.get_nowait()
                    if item is None:
                        break
                    result_queue.put(0)  # æ ‡è®°ä¸ºå¤±è´¥
                except:
                    break
            return
        
        processed = 0
        while True:
            # ä»é˜Ÿåˆ—è·å–æ–‡ä»¶
            item = file_queue.get()
            if item is None:  # ç»“æŸä¿¡å·
                break
            
            query_file = item
            output_file_path = project_out_path / query_file.name

            # è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶
            if output_file_path.exists():
                result_queue.put(1)  # å·²å­˜åœ¨
                continue

            # 1. è¯»å– BM25 ç»“æœæ–‡ä»¶
            try:
                with open(query_file, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
            except Exception as e:
                print(f"[GPU {device_id}] æ— æ³•è¯»å– {query_file}: {e}")
                result_queue.put(0)  # å¤±è´¥
                continue

            # 2. è§£ææŸ¥è¯¢å‡½æ•°å’Œ C/Rust æ–‡æ¡£
            query_func, c_docs_list, r_docs_list, k_docs_list = parse_bm25_file(content)
            
            if not query_func or not c_docs_list:
                result_queue.put(0)  # è·³è¿‡
                continue

            # 3. ä½¿ç”¨ Jina-Reranker é‡æ’
            try:
                reranked_results = reorder_with_jina(model, query_func, c_docs_list)
            except Exception as e:
                print(f"[GPU {device_id}] Jina Rerank å¤±è´¥ (æ–‡ä»¶: {query_file}): {e}")
                torch.cuda.empty_cache()
                result_queue.put(0)  # å¤±è´¥
                continue

            # 4. å†™å…¥é‡æ’åçš„ç»“æœï¼ˆCâ†’C é‡æ’ï¼Œä¿å­˜æ—¶è¡¥é½å¯¹åº” Rust å’ŒçŸ¥è¯†ï¼‰
            try:
                with open(output_file_path, 'w', encoding='utf-8') as f:
                    for res in reranked_results:
                        score = res['score']
                        idx = res['original_index']
                        c_code = c_docs_list[idx]
                        rust_code = r_docs_list[idx]
                        knowledge = k_docs_list[idx] if idx < len(k_docs_list) else []
                        
                        # ä¸ºå…¼å®¹ä¸‹æ¸¸ï¼Œä¿ç•™åŸæœ‰"Function"å­—æ®µæŒ‡å‘ Rustï¼›åŒæ—¶é¢å¤–è¾“å‡º C_Code æ–¹ä¾¿æ’æŸ¥
                        f.write(f"C_Code: \n{c_code}\n")
                        f.write(f"Function: \n{rust_code}\n")
                        
                        # [V10 æ–°å¢] å†™å…¥æå–çš„çŸ¥è¯†
                        if knowledge:
                            f.write(f"Extracted_Knowledge: \n{json.dumps(knowledge, ensure_ascii=False)}\n")
                        
                        f.write(f"Unixcoder Score: {score}\n")
                        f.write("-" * 50 + "\n")
                
                processed += 1
                result_queue.put(1)  # æˆåŠŸ
            except Exception as e:
                print(f"[GPU {device_id}] å†™å…¥å¤±è´¥ (æ–‡ä»¶: {output_file_path}): {e}")
                result_queue.put(0)  # å¤±è´¥
        
        print(f"[GPU {device_id}] å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {processed} ä¸ªæ–‡ä»¶")
        torch.cuda.empty_cache()
        
    except Exception as e:
        print(f"[GPU {device_id}] å·¥ä½œè¿›ç¨‹é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

def wait_for_gpu_memory(gpu_id: int, min_free_gb: float = 12.0, max_wait_seconds: int = 600) -> bool:
    """
    ç­‰å¾… GPU æœ‰è¶³å¤Ÿçš„ç©ºé—²å†…å­˜
    
    Args:
        gpu_id: GPU ID
        min_free_gb: æœ€å°ç©ºé—²å†…å­˜ï¼ˆGBï¼‰
        max_wait_seconds: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        
    Returns:
        æ˜¯å¦æˆåŠŸè·å–åˆ°è¶³å¤Ÿå†…å­˜
    """
    import gc
    
    waited = 0
    check_interval = 10
    
    while waited < max_wait_seconds:
        # æ¸…ç†ç¼“å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            gc.collect()
        
        free_memory = get_gpu_free_memory(gpu_id)
        
        if free_memory >= min_free_gb:
            print(f"[GPU {gpu_id}] ç©ºé—²å†…å­˜: {free_memory:.1f}GB >= {min_free_gb}GBï¼Œå¯ä»¥å¼€å§‹")
            return True
        
        if waited == 0:
            print(f"[GPU {gpu_id}] ç©ºé—²å†…å­˜ä¸è¶³: {free_memory:.1f}GB < {min_free_gb}GB")
            print(f"[GPU {gpu_id}] ç­‰å¾…å…¶ä»–è¿›ç¨‹é‡Šæ”¾å†…å­˜ï¼ˆæœ€å¤šç­‰å¾… {max_wait_seconds}sï¼‰...")
        
        time.sleep(check_interval)
        waited += check_interval
        
        if waited % 60 == 0:
            print(f"[GPU {gpu_id}] å·²ç­‰å¾… {waited}sï¼Œå½“å‰ç©ºé—²: {free_memory:.1f}GB")
    
    print(f"[GPU {gpu_id}] ç­‰å¾…è¶…æ—¶ï¼Œå½“å‰ç©ºé—²å†…å­˜: {get_gpu_free_memory(gpu_id):.1f}GB")
    return False


def acquire_gpu_slot(gpu_id: int, max_slots: int = 2, max_wait_seconds: int = 1800) -> tuple:
    """
    è·å– GPU æ§½ä½ï¼ˆæ¯ä¸ª GPU æœ€å¤šå…è®¸ max_slots ä¸ªå®ä¾‹åŒæ—¶è¿è¡Œï¼‰
    
    Args:
        gpu_id: GPU ID
        max_slots: æ¯ä¸ª GPU æœ€å¤§å¹¶è¡Œæ•°
        max_wait_seconds: æœ€å¤§ç­‰å¾…æ—¶é—´
        
    Returns:
        (slot_id, lock_file) æˆ– (None, None) å¦‚æœè·å–å¤±è´¥
    """
    waited = 0
    wait_interval = 3
    
    while waited < max_wait_seconds:
        # å°è¯•è·å–ä»»æ„ä¸€ä¸ªç©ºé—²æ§½ä½
        for slot_id in range(max_slots):
            lock_file_path = SCRIPT_DIR / f".jina_reranker_gpu{gpu_id}_slot{slot_id}.lock"
            try:
                lock_file = open(lock_file_path, 'w')
                fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
                # æˆåŠŸè·å–é”
                return slot_id, lock_file
            except (IOError, OSError):
                # è¿™ä¸ªæ§½ä½è¢«å ç”¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ª
                try:
                    lock_file.close()
                except:
                    pass
                continue
        
        # æ‰€æœ‰æ§½ä½éƒ½è¢«å ç”¨ï¼Œç­‰å¾…
        if waited == 0:
            print(f"[GPU {gpu_id}] æ‰€æœ‰ {max_slots} ä¸ªæ§½ä½éƒ½è¢«å ç”¨ï¼Œæ’é˜Ÿç­‰å¾…...")
        
        time.sleep(wait_interval)
        waited += wait_interval
        
        if waited % 30 == 0:
            print(f"[GPU {gpu_id}] å·²ç­‰å¾… {waited}s...")
    
    print(f"[GPU {gpu_id}] ç­‰å¾…æ§½ä½è¶…æ—¶ï¼ˆ{max_wait_seconds}sï¼‰")
    return None, None


def release_gpu_slot(lock_file):
    """é‡Šæ”¾ GPU æ§½ä½"""
    if lock_file:
        try:
            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
            lock_file.close()
        except:
            pass


def main():
    """
    ä¸»å‡½æ•°ï¼šæ”¯æŒå¤šé¡¹ç›®å¹¶è¡Œè¿è¡Œ
    æ¯ä¸ª GPU æœ€å¤šå…è®¸ DEFAULT_MAX_SLOTS_PER_GPU ä¸ª Jina Reranker å®ä¾‹åŒæ—¶è¿è¡Œ
    å¯¹äº 49GB æ˜¾å­˜çš„ GPUï¼ˆå¦‚ RTX 5880 Adaï¼‰ï¼Œé»˜è®¤ä¸º 4 ä¸ª
    """
    # æ¯ä¸ª GPU æœ€å¤§å¹¶è¡Œæ•°ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡è°ƒæ•´ï¼‰
    max_slots_per_gpu = int(os.environ.get("JINA_MAX_SLOTS_PER_GPU", str(DEFAULT_MAX_SLOTS_PER_GPU)))
    
    slot_id = None
    lock_file = None
    
    try:
        if torch.cuda.is_available() and NUM_GPUS > 0:
            global PROJECT_GPU_ID
            if EXTERNAL_GPU_SCHEDULER:
                # å¤–éƒ¨è°ƒåº¦å™¨å·²é€šè¿‡ CUDA_VISIBLE_DEVICES å°†æœ¬è¿›ç¨‹ç»‘å®šåˆ°æŸä¸ªâ€œç‰©ç† GPUâ€ï¼Œæ­¤æ—¶æœ¬è¿›ç¨‹åªåº”ä½¿ç”¨é€»è¾‘ cuda:0ã€‚
                # ä¸èƒ½å†ç”¨æœ¬è„šæœ¬çš„â€œå…¨å±€é”æ–‡ä»¶â€åšè·¨é¡¹ç›®æ’é˜Ÿï¼Œå¦åˆ™ä¸åŒç‰©ç† GPU ä¼šäº’ç›¸è¯¯ä¼¤ï¼ˆéƒ½å†™åŒä¸€ä¸ª gpu0_slot*.lockï¼‰ã€‚
                PROJECT_GPU_ID = 0
                cvd = os.environ.get("CUDA_VISIBLE_DEVICES", "")
                if cvd:
                    print(f"[é¡¹ç›® {PROJECT_NAME}] å¤–éƒ¨è°ƒåº¦æ¨¡å¼: CUDA_VISIBLE_DEVICES={cvd} (é€»è¾‘ä½¿ç”¨ cuda:0)")
            else:
                # é€‰æ‹©æœ€ä½³ GPUï¼ˆè„šæœ¬ç‹¬ç«‹è¿è¡Œæ—¶æ‰å¯ç”¨å†…éƒ¨è°ƒåº¦/é”æ§½ï¼‰
                best_gpu = get_best_gpu_for_task()
                PROJECT_GPU_ID = best_gpu

                print(f"[é¡¹ç›® {PROJECT_NAME}] åˆ†é…åˆ° GPU {PROJECT_GPU_ID}/{NUM_GPUS}")
                print(f"[é¡¹ç›® {PROJECT_NAME}] æ¯ä¸ª GPU æœ€å¤§å¹¶è¡Œæ•°: {max_slots_per_gpu}")

                # è·å– GPU æ§½ä½
                slot_id, lock_file = acquire_gpu_slot(PROJECT_GPU_ID, max_slots=max_slots_per_gpu)

                if slot_id is not None:
                    print(f"[é¡¹ç›® {PROJECT_NAME}] å·²è·å– GPU {PROJECT_GPU_ID} æ§½ä½ {slot_id}")
                else:
                    print(f"[é¡¹ç›® {PROJECT_NAME}] æ— æ³•è·å– GPU æ§½ä½ï¼Œå¼ºåˆ¶ç»§ç»­ï¼ˆå¯èƒ½å¯¼è‡´ OOMï¼‰...")

                # ç­‰å¾… GPU å†…å­˜é‡Šæ”¾
                # æ¯ä¸ª Jina Reranker è¿›ç¨‹çº¦éœ€ 6GB å†…å­˜
                min_required_memory = float(os.environ.get("JINA_MIN_GPU_MEMORY_GB", "6.0"))
                if not wait_for_gpu_memory(PROJECT_GPU_ID, min_required_memory, max_wait_seconds=300):
                    print(f"[è­¦å‘Š] GPU {PROJECT_GPU_ID} å†…å­˜ä¸è¶³ï¼ˆéœ€è¦ {min_required_memory}GBï¼‰ï¼Œå°è¯•ç»§ç»­è¿è¡Œ...")

            # ç¡®ä¿ä½¿ç”¨ spawn æ–¹æ³•ï¼ˆCUDA è¦æ±‚ï¼‰
            current_method = get_start_method(allow_none=True)
            if current_method != 'spawn':
                try:
                    set_start_method('spawn', force=True)
                    print(f"è®¾ç½® multiprocessing å¯åŠ¨æ–¹æ³•ä¸º 'spawn'ï¼ˆCUDA è¦æ±‚ï¼‰")
                except RuntimeError as e:
                    print(f"è­¦å‘Š: æ— æ³•è®¾ç½®å¯åŠ¨æ–¹æ³•: {e}")
        
        # è¿è¡Œ Jina Rerankerï¼ˆGPU æˆ– CPU æ¨¡å¼ï¼‰
        _run_jina_rerank()
        
    finally:
        # é‡Šæ”¾ GPU æ§½ä½
        if lock_file:
            release_gpu_slot(lock_file)
            print(f"[é¡¹ç›® {PROJECT_NAME}] å·²é‡Šæ”¾ GPU {PROJECT_GPU_ID} æ§½ä½ {slot_id}")

def _run_jina_rerank():
    """å®é™…çš„ Jina Reranker å¤„ç†é€»è¾‘"""
    print(f"--- (RAG æ­¥éª¤ 2) Jina é‡æ’å¼€å§‹ ---")
    print(f"é¡¹ç›®: {PROJECT_NAME}")
    print(f"BM25 ç»“æœè¾“å…¥: {RAG_PATH}")
    print(f"é‡æ’ç»“æœè¾“å‡º: {OUTPUT_PATH}")
    if torch.cuda.is_available() and NUM_GPUS > 0:
        print(f"æ£€æµ‹åˆ° {NUM_GPUS} ä¸ª GPUï¼Œé¡¹ç›® '{PROJECT_NAME}' ä½¿ç”¨ GPU {PROJECT_GPU_ID}")
        print(f"æç¤º: ä¸åŒé¡¹ç›®ä¼šè‡ªåŠ¨åˆ†é…åˆ°ä¸åŒGPUï¼Œæœ€å¤šå¯å¹¶è¡Œè¿è¡Œ {NUM_GPUS} ä¸ªé¡¹ç›®")
    else:
        print(f"ä½¿ç”¨ CPU æ¨¡å¼")

    if not RAG_PATH.exists():
        print(f"é”™è¯¯: BM25 ç»“æœç›®å½•ä¸å­˜åœ¨: {RAG_PATH}")
        return
    
    project = PROJECT_NAME
    project_in_path = RAG_PATH
    project_out_path = OUTPUT_PATH
    project_out_path.mkdir(parents=True, exist_ok=True)
    
    query_files = list(project_in_path.glob("*.txt"))
    # è¿‡æ»¤æ‰å·²å¤„ç†çš„æ–‡ä»¶
    query_files = [f for f in query_files if not (project_out_path / f.name).exists()]
    
    print(f"\næ­£åœ¨å¤„ç†é¡¹ç›®: {project} ({len(query_files)} ä¸ªæŸ¥è¯¢å‡½æ•°)")

    if not query_files:
        print("æ‰€æœ‰æ–‡ä»¶å·²å¤„ç†å®Œæˆï¼Œè·³è¿‡ã€‚")
        return

    # ä½¿ç”¨é«˜æ•ˆæ‰¹é‡å¤„ç†æ¨¡å¼ï¼šå•æ¨¡å‹å®ä¾‹ + å¤šçº¿ç¨‹ I/O + æ‰¹é‡æ¨ç†
    # è¿™ç§æ–¹å¼æ¯”å¤šè¿›ç¨‹åŠ è½½å¤šä¸ªæ¨¡å‹æ›´é«˜æ•ˆï¼Œå› ä¸ºï¼š
    # 1. åªåŠ è½½ä¸€ä¸ªæ¨¡å‹ï¼ŒèŠ‚çœæ˜¾å­˜ï¼ˆçº¦ 2-8GBï¼‰
    # 2. å¤šçº¿ç¨‹å¹¶è¡Œè¯»å–/å†™å…¥æ–‡ä»¶ï¼ˆI/O å¯†é›†å‹ï¼‰
    # 3. æ‰¹é‡æ¨ç†ï¼Œå……åˆ†åˆ©ç”¨ GPU å¹¶è¡Œèƒ½åŠ›
    
    USE_EFFICIENT_BATCH = True  # å¼€å¯é«˜æ•ˆæ‰¹é‡æ¨¡å¼
    
    if USE_EFFICIENT_BATCH and len(query_files) > 5:
        # é«˜æ•ˆæ‰¹é‡å¤„ç†æ¨¡å¼
        device_id = PROJECT_GPU_ID if torch.cuda.is_available() else -1
        
        print(f"ä½¿ç”¨é«˜æ•ˆæ‰¹é‡å¤„ç†æ¨¡å¼ (GPU {device_id})...")
        print(f"  - å•æ¨¡å‹å®ä¾‹ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰")
        print(f"  - æ‰¹é‡æ¨ç†ï¼ˆè‡ªé€‚åº” batch_sizeï¼‰")
        print(f"  - å¤šçº¿ç¨‹ I/O")
        
        # æ£€æŸ¥ GPU å†…å­˜
        if device_id >= 0:
            free_memory = get_gpu_free_memory(device_id)
            print(f"  - GPU {device_id} ç©ºé—²å†…å­˜: {free_memory:.1f} GB")
            
            if free_memory < 10.0:
                print(f"[è­¦å‘Š] GPU ç©ºé—²å†…å­˜ä¸è¶³ ({free_memory:.1f}GB < 10GB)ï¼Œç­‰å¾…é‡Šæ”¾...")
                wait_for_gpu_memory(device_id, min_free_gb=10.0, max_wait_seconds=120)
        
        # åŠ è½½æ¨¡å‹
        model, device = load_model(device_id)
        print(f"æ¨¡å‹å·²åŠ è½½åˆ°: {device}")
        
        # è®¡ç®—æœ€ä½³æ‰¹é‡å¤§å°ï¼ˆæ ¹æ® GPU å†…å­˜åŠ¨æ€è°ƒæ•´ï¼‰
        if device_id >= 0 and BATCH_SIZE_AUTO:
            batch_size = get_adaptive_batch_size(device_id)
            print(f"  - è‡ªé€‚åº” batch_size: {batch_size} (åŸºäº GPU ç©ºé—²å†…å­˜)")
        else:
            batch_size = min(32, max(8, len(query_files) // 10))
        
        # é™åˆ¶ batch_sizeï¼ˆæ ¹æ®æ˜¾å­˜åŠ¨æ€è°ƒæ•´ï¼Œä¸å†ç¡¬ç¼–ç ä¸º 8ï¼‰
        # å¯¹äº 49GB æ˜¾å­˜çš„ GPUï¼Œå¯ä»¥ä½¿ç”¨æ›´å¤§çš„æ‰¹é‡
        max_batch_size = int(os.environ.get("JINA_MAX_BATCH_SIZE", "32"))
        batch_size = min(batch_size, max_batch_size)
        num_io_workers = min(8, len(query_files) // 5 + 1)  # å¢åŠ  I/O workers
        
        print(f"æ‰¹é‡å¤§å°: {batch_size}, I/O çº¿ç¨‹æ•°: {num_io_workers}")
        
        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦
        with tqdm(total=len(query_files), desc=f"Jina Rerank ({project}, GPU {device_id}, batch={batch_size})") as pbar:
            from concurrent.futures import ThreadPoolExecutor, as_completed
            import gc
            
            processed = 0
            
            # åˆ†æ‰¹å¤„ç†
            for batch_start in range(0, len(query_files), batch_size):
                batch_end = min(batch_start + batch_size, len(query_files))
                batch_files = query_files[batch_start:batch_end]
                
                # 1. å¹¶è¡Œè¯»å–è¿™ä¸€æ‰¹æ–‡ä»¶
                with ThreadPoolExecutor(max_workers=num_io_workers) as io_executor:
                    load_futures = {
                        io_executor.submit(load_file_data, qf, project_out_path): qf 
                        for qf in batch_files
                    }
                    
                    batch_data = []
                    file_metadata = []
                    skipped = 0
                    
                    for future in as_completed(load_futures):
                        result = future.result()
                        if result is not None:
                            query_file, query_func, c_docs_list, r_docs_list, k_docs_list = result
                            batch_data.append((query_func, c_docs_list))
                            file_metadata.append({
                                'query_file': query_file,
                                'c_docs_list': c_docs_list,
                                'r_docs_list': r_docs_list,
                                'k_docs_list': k_docs_list
                            })
                        else:
                            skipped += 1
                
                if not batch_data:
                    pbar.update(len(batch_files))
                    continue
                
                # 2. æ‰¹é‡æ¨ç†ï¼ˆå¸¦ OOM æ¢å¤ï¼‰
                try:
                    rerank_results = batch_reorder_with_jina(model, batch_data)
                except (torch.cuda.OutOfMemoryError, RuntimeError) as e:
                    error_str = str(e).lower()
                    if "out of memory" in error_str or "cuda" in error_str:
                        print(f"\n[OOM] æ‰¹é‡æ¨ç†å¤±è´¥ï¼Œæ¸…ç†å†…å­˜å¹¶é‡è¯•å•æ¡å¤„ç†...")
                        torch.cuda.empty_cache()
                        gc.collect()
                        time.sleep(5)  # ç­‰å¾…å†…å­˜é‡Šæ”¾
                        
                        # é€æ¡å¤„ç†ï¼ˆé™çº§æ¨¡å¼ï¼‰
                        rerank_results = []
                        for query_func, c_docs_list in batch_data:
                            try:
                                result = reorder_with_jina(model, query_func, c_docs_list)
                                rerank_results.append(result)
                                torch.cuda.empty_cache()
                            except Exception as inner_e:
                                print(f"  å•æ¡å¤„ç†ä¹Ÿå¤±è´¥: {inner_e}")
                                rerank_results.append([])
                    else:
                        print(f"\næ‰¹é‡æ¨ç†å¤±è´¥: {e}")
                        torch.cuda.empty_cache()
                        gc.collect()
                        pbar.update(len(batch_files))
                        continue
                except Exception as e:
                    print(f"\næ‰¹é‡æ¨ç†å¤±è´¥: {e}")
                    torch.cuda.empty_cache()
                    gc.collect()
                    pbar.update(len(batch_files))
                    continue
                
                # 3. å¹¶è¡Œå†™å…¥ç»“æœ
                with ThreadPoolExecutor(max_workers=num_io_workers) as io_executor:
                    save_futures = []
                    for metadata, results in zip(file_metadata, rerank_results):
                        if results:
                            future = io_executor.submit(
                                save_rerank_result,
                                metadata['query_file'],
                                results,
                                metadata['c_docs_list'],
                                metadata['r_docs_list'],
                                metadata['k_docs_list'],
                                project_out_path
                            )
                            save_futures.append(future)
                    
                    for future in as_completed(save_futures):
                        future.result()
                
                pbar.update(len(batch_files))
                
                # å®šæœŸæ¸…ç† GPU å†…å­˜
                if (batch_start + batch_size) % (batch_size * 5) == 0:
                    torch.cuda.empty_cache()
                    gc.collect()
        
        print(f"é«˜æ•ˆæ‰¹é‡å¤„ç†å®Œæˆ")
    
    elif USE_MULTI_GPU and len(query_files) > 10:
        # å¤‡ç”¨ï¼šå¤šè¿›ç¨‹æ¨¡å¼ï¼ˆå½“é«˜æ•ˆæ¨¡å¼ä¸é€‚ç”¨æ—¶ï¼‰
        num_workers_per_gpu = min(2, len(query_files) // 20 + 1)
        
        print(f"ä½¿ç”¨å¤šè¿›ç¨‹æ¨¡å¼ (GPU {PROJECT_GPU_ID}, {num_workers_per_gpu} workers)...")
        
        preload_model()
        
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            import gc
            gc.collect()
        
        manager = Manager()
        file_queue = manager.Queue()
        result_queue = manager.Queue()
        load_failed_event = manager.Event()
        
        for query_file in query_files:
            file_queue.put(query_file)
        
        for _ in range(num_workers_per_gpu):
            file_queue.put(None)
        
        processes = []
        for worker_id in range(num_workers_per_gpu):
            p = Process(
                target=process_worker,
                args=(PROJECT_GPU_ID, file_queue, result_queue, project_in_path, project_out_path, load_failed_event)
            )
            p.start()
            processes.append(p)
        
        with tqdm(total=len(query_files), desc=f"Jina Rerank ({project}, GPU {PROJECT_GPU_ID}, {num_workers_per_gpu} workers)") as pbar:
            completed = 0
            while completed < len(query_files):
                result_queue.get()
                completed += 1
                pbar.update(1)
        
        for p in processes:
            p.join()
        
        print(f"GPU {PROJECT_GPU_ID} å¤„ç†å®Œæˆ")
    else:
        # å•è¿›ç¨‹å¤„ç†ï¼ˆæ–‡ä»¶æ•°é‡è¾ƒå°‘æ—¶ï¼‰
        device_id = PROJECT_GPU_ID if torch.cuda.is_available() else -1
        model, device = load_model(device_id)
        print(f"ä½¿ç”¨è®¾å¤‡: {device} (é¡¹ç›® {project})")

        for query_file in tqdm(query_files, desc=f"Jina Rerank ({project})"):
            output_file_path = project_out_path / query_file.name

            if output_file_path.exists():
                continue

            # 1. è¯»å– BM25 ç»“æœæ–‡ä»¶
            try:
                with open(query_file, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
            except Exception as e:
                print(f"æ— æ³•è¯»å– {query_file}: {e}")
                continue

            # 2. è§£ææŸ¥è¯¢å‡½æ•°å’Œ C/Rust æ–‡æ¡£
            query_func, c_docs_list, r_docs_list, k_docs_list = parse_bm25_file(content)
            
            if not query_func or not c_docs_list:
                continue

            # 3. ä½¿ç”¨ Jina-Reranker é‡æ’
            try:
                reranked_results = reorder_with_jina(model, query_func, c_docs_list)
            except Exception as e:
                print(f"Jina Rerank å¤±è´¥ (æ–‡ä»¶: {query_file}): {e}")
                torch.cuda.empty_cache()
                continue

            # 4. å†™å…¥é‡æ’åçš„ç»“æœï¼ˆCâ†’C é‡æ’ï¼Œä¿å­˜æ—¶è¡¥é½å¯¹åº” Rust å’ŒçŸ¥è¯†ï¼‰
            with open(output_file_path, 'w', encoding='utf-8') as f:
                for res in reranked_results:
                    score = res['score']
                    idx = res['original_index']
                    c_code = c_docs_list[idx]
                    rust_code = r_docs_list[idx]
                    knowledge = k_docs_list[idx] if idx < len(k_docs_list) else []
                    
                    # ä¸ºå…¼å®¹ä¸‹æ¸¸ï¼Œä¿ç•™åŸæœ‰"Function"å­—æ®µæŒ‡å‘ Rustï¼›åŒæ—¶é¢å¤–è¾“å‡º C_Code æ–¹ä¾¿æ’æŸ¥
                    f.write(f"C_Code: \n{c_code}\n")
                    f.write(f"Function: \n{rust_code}\n")
                    
                    # [V10 æ–°å¢] å†™å…¥æå–çš„çŸ¥è¯†
                    if knowledge:
                        f.write(f"Extracted_Knowledge: \n{json.dumps(knowledge, ensure_ascii=False)}\n")
                    
                    f.write(f"Unixcoder Score: {score}\n")
                    f.write("-" * 50 + "\n")
                    
    print("--- (RAG æ­¥éª¤ 2) Jina é‡æ’å®Œæˆ ---")

if __name__ == "__main__":
    # å¿…é¡»åœ¨ä¸»æ¨¡å—ä¸­è®¾ç½®å¯åŠ¨æ–¹æ³•ä¸º 'spawn'
    # è¿™æ˜¯ PyTorch CUDA ä¸ multiprocessing çš„è¦æ±‚
    # fork æ–¹æ³•ä¼šå¯¼è‡´ CUDA æ— æ³•åœ¨å­è¿›ç¨‹ä¸­é‡æ–°åˆå§‹åŒ–
    import multiprocessing
    try:
        multiprocessing.set_start_method('spawn', force=True)
    except RuntimeError:
        # å¦‚æœå·²ç»è®¾ç½®è¿‡ï¼Œå¿½ç•¥é”™è¯¯
        pass
    main()
