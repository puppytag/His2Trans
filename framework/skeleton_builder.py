#!/usr/bin/env python3
"""
åˆ†å±‚éª¨æ¶æ„å»ºå™¨ (Layered Skeleton Builder)

åŸºäºè®ºæ–‡æ–¹æ³•å®ç°çš„ C++ åˆ° Rust éª¨æ¶ç¿»è¯‘ï¼š
- Rustine: é¢„å¤„ç†é˜¶æ®µï¼ˆå®å±•å¼€ï¼‰
- LLMigrate/EvoC2Rust: ä½¿ç”¨ bindgen ç”Ÿæˆç±»å‹éª¨æ¶
- PTRMAPPER: å…¨å±€å˜é‡ä¸Šä¸‹æ–‡åˆ†æ
- EvoC2Rust: å¢é‡å¼éª¨æ¶æ„å»º

æ ¸å¿ƒç†å¿µï¼š
- é˜¶æ®µ A (Truth Layer): ä½¿ç”¨ bindgen ç”Ÿæˆç»å¯¹æ­£ç¡®çš„ç±»å‹å®šä¹‰
- é˜¶æ®µ B (State Layer): ä½¿ç”¨ tree-sitter ç²¾ç¡®æå–å…¨å±€/é™æ€å˜é‡
- é˜¶æ®µ C (Logic Skeleton): ç”Ÿæˆä»…åŒ…å«ç­¾åçš„ unimplemented!() æ¡©ä»£ç 
"""

import os
import re
import json
import subprocess
import tempfile
import time
from datetime import datetime
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Tuple, Set, Optional, Any, Sequence
from dataclasses import dataclass, field
import logging
import shutil

from tree_sitter import Language, Parser
import tree_sitter_cpp as tscpp

from workspace_config import safe_module_name

# å¯¼å…¥æ—¥å¿—é…ç½®
from log_config import ensure_logging_setup, LogPrinter
ensure_logging_setup()

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)
log = LogPrinter(__name__)

# ============================================================
# Tier-0: Deterministic primitive typedef mapping
# ============================================================
#
# When bindgen fails (or tree-sitter collects tokens as "types"), common C typedefs
# like INT32/UINT32/CHAR/BOOL are often generated as opaque structs:
#   pub struct INT32 { _private: [u8; 0] }
# This causes massive downstream mismatches (E0308/E0599).
#
# We deterministically map these well-known aliases to Rust primitive/type aliases.
# This mapping is intentionally conservative and aims for "compile-friendly" FFI.
PRIMITIVE_TYPEDEF_ALIASES = {
    # Signed/unsigned integers
    "INT8": "i8",
    "INT16": "i16",
    "INT32": "i32",
    "INT64": "i64",
    "UINT8": "u8",
    "UINT16": "u16",
    "UINT32": "u32",
    "UINT64": "u64",
    "INT": "i32",
    "UINT": "u32",
    "SHORT": "i16",
    "USHORT": "u16",
    "LONG": "i64",
    "ULONG": "u64",
    "LONGLONG": "i64",
    "ULONGLONG": "u64",
    # Characters / bytes
    "CHAR": "core::ffi::c_char",
    "UCHAR": "u8",
    "BYTE": "u8",
    "WORD": "u16",
    "DWORD": "u32",
    # Boolean-like typedefs (C projects commonly treat BOOL as int)
    "BOOL": "i32",
    # Size / pointer sized
    "size_t": "usize",
    "ssize_t": "isize",
    "ptrdiff_t": "isize",
    "intptr_t": "isize",
    "uintptr_t": "usize",
    "UINTPTR": "usize",
    "UINTPTR_T": "usize",
    "VADDR_T": "usize",
    # Common file/offset types (compile-friendly)
    "off_t": "i64",
    "off64_t": "i64",
}

# å¯¼å…¥ compile_commands.json è§£æå™¨
try:
    from compile_commands_parser import CompileCommandsParser
    COMPILE_COMMANDS_AVAILABLE = True
except ImportError:
    COMPILE_COMMANDS_AVAILABLE = False
    logger.warning("compile_commands_parser æ¨¡å—ä¸å¯ç”¨ï¼Œå°†è·³è¿‡ compile_commands.json æ”¯æŒ")

# å¯¼å…¥ç¡®å®šæ€§ç±»å‹æ˜ å°„å™¨
try:
    from type_mapper import TypeMapper
    TYPE_MAPPER_AVAILABLE = True
except ImportError:
    TYPE_MAPPER_AVAILABLE = False
    logger.warning("type_mapper æ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ—§çš„ç±»å‹æ˜ å°„æ–¹æ³•")

# å¯¼å…¥ç±»å‹å·¥å…·æ¨¡å—
try:
    from type_utils import is_valid_c_identifier, sanitize_parameter_names, extract_base_type
    TYPE_UTILS_AVAILABLE = True
except ImportError:
    TYPE_UTILS_AVAILABLE = False
    logger.warning("type_utils æ¨¡å—ä¸å¯ç”¨ï¼Œå°†è·³è¿‡ç±»å‹æ”¶é›†å’Œæ¸…æ´—åŠŸèƒ½")

# å¯¼å…¥å¢å¼ºé¢„å¤„ç†æ¨¡å— (åŸºäº EvoC2Rust æ–¹æ³•)
try:
    from preprocessing import (
        EnhancedPreprocessor,
        ASTHealthReport,
        PreprocessingResult,
        find_function_declarator_recursive,
        check_source_health
    )
    ENHANCED_PREPROCESSING_AVAILABLE = True
except ImportError:
    ENHANCED_PREPROCESSING_AVAILABLE = False
    logger.warning("preprocessing æ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨åŸºæœ¬é¢„å¤„ç†")

# å¯¼å…¥å¾®ä»»åŠ¡ä¿®å¤å™¨ (AI åŸç”Ÿè‡ªæ„ˆæ¶æ„)
try:
    from micro_task_repairer import SelfHealingLoop, MicroTaskRepairer, run_self_healing
    SELF_HEALING_AVAILABLE = True
except ImportError:
    SELF_HEALING_AVAILABLE = False
    logger.warning("micro_task_repairer æ¨¡å—ä¸å¯ç”¨ï¼Œå°†è·³è¿‡è‡ªæ„ˆå¾ªç¯")

# å¯¼å…¥ Rust ä»£ç ç”Ÿæˆå™¨ (å®‰å…¨çš„ä»£ç ç”Ÿæˆ)
try:
    from rust_code_builder import RustCodeBuilder, create_opaque_type, create_const
    RUST_CODE_BUILDER_AVAILABLE = True
except ImportError:
    RUST_CODE_BUILDER_AVAILABLE = False
    logger.warning("rust_code_builder æ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ä¼ ç»Ÿå­—ç¬¦ä¸²æ‹¼æ¥")

# å¯¼å…¥åŠ¨æ€å®å­¦ä¹ å™¨
try:
    from macro_learner import MacroLearner, get_global_macro_learner, expand_macros, get_gcc_macro_args
    MACRO_LEARNER_AVAILABLE = True
except ImportError:
    MACRO_LEARNER_AVAILABLE = False
    logger.warning("macro_learner æ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç¡¬ç¼–ç çš„å®å±•å¼€")

# å¯¼å…¥ LLM é©±åŠ¨çš„ç±»å‹æ˜ å°„å™¨
try:
    from llm_type_mapper import LLMTypeMapper, create_llm_type_mapper
    LLM_TYPE_MAPPER_AVAILABLE = True
except ImportError:
    LLM_TYPE_MAPPER_AVAILABLE = False
    logger.warning("llm_type_mapper æ¨¡å—ä¸å¯ç”¨ï¼Œå°†è·³è¿‡ LLM è¾…åŠ©ç±»å‹æ˜ å°„")

# å¯¼å…¥æ··åˆæ„å»ºæ”¯æŒ (C/Rust é“¾æ¥)
try:
    from hybrid_build import (
        HybridBuildManager, 
        NativeDirectoryManager,
        generate_build_rs,
        generate_extern_declarations,
        extract_compile_flags_from_commands,
        CSourceFile
    )
    HYBRID_BUILD_AVAILABLE = True
except ImportError:
    HYBRID_BUILD_AVAILABLE = False
    logger.warning("hybrid_build æ¨¡å—ä¸å¯ç”¨ï¼Œå°†è·³è¿‡æ··åˆæ„å»ºæ”¯æŒ")

# å¯¼å…¥è‡ªé€‚åº”é¢„å®šä¹‰ç®¡ç†å™¨
try:
    from config.predefines import get_predefine_manager, PredefineManager
    PREDEFINES_AVAILABLE = True
except ImportError:
    PREDEFINES_AVAILABLE = False
    logger.warning("config.predefines æ¨¡å—ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å†…ç½®çš„ç¡¬ç¼–ç å®šä¹‰")

# åˆå§‹åŒ– Tree-sitter C++ è§£æå™¨ï¼ˆå…¼å®¹æ–°ç‰ˆ bindingsï¼šLanguage(..., name)ï¼‰
try:
    CPP_LANGUAGE = Language(tscpp.language(), "cpp")
except TypeError:
    CPP_LANGUAGE = Language(tscpp.language())
cpp_parser = Parser()
try:
    cpp_parser.set_language(CPP_LANGUAGE)
except Exception:
    cpp_parser = Parser(CPP_LANGUAGE)


@dataclass
class TypeInfo:
    """ç±»å‹ä¿¡æ¯"""
    name: str
    kind: str  # struct, enum, union, typedef
    definition: str  # Rust å®šä¹‰
    source: str  # æ¥æº: bindgen, llm, placeholder


@dataclass
class VariableInfo:
    """å˜é‡ä¿¡æ¯"""
    name: str
    c_type: str
    rust_type: str
    rust_declaration: str
    is_static: bool
    is_pointer: bool
    is_array: bool
    # `extern` variable declaration (not a definition in this TU).
    # NOTE: Even if it is extern in C, for "pure Rust migration" we may still emit storage.
    is_extern: bool = False
    array_size: Optional[str] = None
    from_function: Optional[str] = None  # æ¥è‡ªå“ªä¸ªå‡½æ•°ï¼ˆç”¨äºå‡½æ•°å†… static å˜é‡æå‡ï¼‰
    # Source file-group (safe module name) that this variable is extracted from.
    # Used to locate the exact preprocessed `.i` for bindgen-truth globals generation.
    origin_file: Optional[str] = None
    # C initialization expression (e.g., "{ 619, 720, 127, ... }" for array initializers)
    # This is used to preserve the original initialization values in the generated Rust code.
    init_value: Optional[str] = None


@dataclass
class ExtractedVariable:
    """æå–çš„å˜é‡ä¿¡æ¯ï¼ˆç”¨äº libclang æå–æ¨¡å¼ï¼‰"""
    name: str
    c_type: str
    rust_type: str
    initial_value: Optional[str] = None
    is_const: bool = False
    is_static: bool = False
    is_extern: bool = False
    is_pointer: bool = False
    from_function: Optional[str] = None  # æ¥è‡ªå“ªä¸ªå‡½æ•°ï¼ˆç”¨äºå‡½æ•°å†… static å˜é‡æå‡ï¼‰
    array_size: Optional[str] = None
    is_array: bool = False  # æ˜¯å¦æ˜¯æ•°ç»„ç±»å‹
    
    @property
    def rust_declaration(self) -> str:
        """ç”Ÿæˆ Rust å˜é‡å£°æ˜è¯­å¥"""
        # ç¡®å®šæ˜¯ static mut è¿˜æ˜¯ const
        if self.is_const:
            keyword = "pub const"
            # const éœ€è¦åˆå§‹å€¼ï¼Œå¤„ç† C é£æ ¼åˆå§‹åŒ–
            init = self._convert_initial_value(self.initial_value, self.rust_type)
            return f"{keyword} {self.name.upper()}: {self.rust_type} = {init};"
        else:
            keyword = "pub static mut"
            # static mut ä½¿ç”¨é›¶åˆå§‹åŒ–æˆ–é»˜è®¤å€¼
            if self.rust_type == "*mut c_void" or self.rust_type.startswith("*mut"):
                init = "std::ptr::null_mut()"
            elif self.rust_type.startswith("*const"):
                init = "std::ptr::null()"
            elif self.rust_type in ("i32", "i64", "u32", "u64", "i8", "u8", "i16", "u16", "isize", "usize", "c_int", "c_uint", "c_long", "c_ulong", "c_char", "c_uchar", "c_short", "c_ushort"):
                init = "0"
            elif self.rust_type in ("f32", "f64"):
                init = "0.0"
            elif self.rust_type == "bool":
                init = "false"
            elif self.initial_value and not self._is_c_struct_initializer(self.initial_value):
                # åªæœ‰å½“åˆå§‹å€¼ä¸æ˜¯ C é£æ ¼ç»“æ„ä½“åˆå§‹åŒ–æ—¶æ‰ä½¿ç”¨
                init = self._convert_initial_value(self.initial_value, self.rust_type)
            else:
                # ç»“æ„ä½“/å¤æ‚ç±»å‹ä½¿ç”¨ zeroed() å®‰å…¨åˆå§‹åŒ–
                return f"{keyword} {self.name}: {self.rust_type} = unsafe {{ std::mem::zeroed() }};"
            return f"{keyword} {self.name}: {self.rust_type} = {init};"
    
    def _is_c_struct_initializer(self, value: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯ C é£æ ¼çš„ç»“æ„ä½“åˆå§‹åŒ–å™¨ï¼ˆå¦‚ {0}, {.member = val}ï¼‰"""
        if not value:
            return False
        value = value.strip()
        return value.startswith('{') or value.startswith('(')
    
    def _convert_initial_value(self, value: str, rust_type: str) -> str:
        """è½¬æ¢ C åˆå§‹å€¼ä¸º Rust å…¼å®¹æ ¼å¼"""
        if not value:
            # æ ¹æ®ç±»å‹è¿”å›é»˜è®¤å€¼
            if rust_type.startswith("*"):
                return "std::ptr::null_mut()" if "mut" in rust_type else "std::ptr::null()"
            elif rust_type in ("i32", "i64", "u32", "u64", "i8", "u8", "i16", "u16", "isize", "usize"):
                return "0"
            elif rust_type in ("f32", "f64"):
                return "0.0"
            elif rust_type == "bool":
                return "false"
            else:
                return "unsafe { std::mem::zeroed() }"
        
        value = value.strip()
        
        # C é£æ ¼ç»“æ„ä½“åˆå§‹åŒ– â†’ zeroed()
        if value.startswith('{') or value.startswith('('):
            return "unsafe { std::mem::zeroed() }"
        
        # NULL â†’ null_mut()/null()
        if value.upper() in ('NULL', '0', '((VOID*)0)', '((void*)0)'):
            if rust_type.startswith("*"):
                return "std::ptr::null_mut()" if "mut" in rust_type else "std::ptr::null()"
            return "0"
        
        # å¸ƒå°”å€¼è½¬æ¢
        if value.lower() in ('true', 'false'):
            return value.lower()
        
        # æ•°å­—ä¿æŒä¸å˜
        return value


@dataclass
class FunctionSignature:
    """å‡½æ•°ç­¾åä¿¡æ¯"""
    name: str
    c_signature: str
    rust_signature: str
    return_type: str
    parameters: List[Tuple[str, str]]  # [(param_name, param_type), ...]
    is_static: bool = False  # C static å‡½æ•°
    is_callback: bool = False  # ç”¨ä½œå›è°ƒ/å‡½æ•°æŒ‡é’ˆ


@dataclass
class SkeletonComponents:
    """éª¨æ¶ç»„ä»¶"""
    types: Dict[str, TypeInfo] = field(default_factory=dict)
    variables: Dict[str, VariableInfo] = field(default_factory=dict)
    functions: Dict[str, FunctionSignature] = field(default_factory=dict)
    extern_c_declarations: List[str] = field(default_factory=list)
    macro_rules: List[str] = field(default_factory=list)
    imports: Set[str] = field(default_factory=set)


class SkeletonBuilder:
    """åˆ†å±‚éª¨æ¶æ„å»ºå™¨"""
    
    def __init__(
        self, 
        project_root: Path, 
        output_dir: Path,
        compile_commands_path: Path = None,
        ohos_root: Path = None
    ):
        """
        åˆå§‹åŒ–éª¨æ¶æ„å»ºå™¨
        
        Args:
            project_root: C++ é¡¹ç›®æ ¹ç›®å½•
            output_dir: Rust è¾“å‡ºç›®å½•
            compile_commands_path: compile_commands.json çš„è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            ohos_root: OpenHarmony æºç æ ¹ç›®å½•ï¼ˆå¯é€‰ï¼Œç”¨äºè·¯å¾„è§„èŒƒåŒ–ï¼‰
        """
        self.project_root = Path(project_root)
        self.output_dir = Path(output_dir)
        self.components = SkeletonComponents()
        self.preprocessed_cache: Dict[str, str] = {}
        # bindgen allowlist cache (signatures): {(pre_path, lang, md5(sorted(names))): {name: rust_sig}}
        self._bindgen_fn_sig_cache: Dict[str, Dict[str, str]] = {}
        self.collected_custom_types = set()  # ç”¨äºæ”¶é›†æ‰€æœ‰éåŸç”Ÿç±»å‹
        self.ohos_root = Path(ohos_root) if ohos_root else None
        self._ohos_build_out_dir: Optional[Path] = None
        # TU ä¸Šä¸‹æ–‡æ˜ å°„ï¼ˆç”± get_dependencies.py ç”Ÿæˆï¼‰ï¼šç”¨äºåœ¨ skeleton/bindgen é˜¶æ®µå¤ç”¨â€œåŒä¸€å¥— TU flags/å®/include é¡ºåºâ€
        self._tu_context_map_path: Optional[Path] = None
        self._tu_context_files: Dict[str, Dict[str, Any]] = {}

        # SelfContained æ¨¡å—å¸¸å¸¦ original_path.txtï¼ˆOpenHarmony æºç ä¸­çš„åŸå§‹ç›¸å¯¹è·¯å¾„ï¼‰
        # ç”¨äºæŠŠ self.project_root ä¸‹çš„æ–‡ä»¶æ˜ å°„å› ohos_root çš„çœŸå®è·¯å¾„ï¼Œä»¥ä¾¿ç²¾ç¡®åŒ¹é… compile_commands.jsonã€‚
        self._ohos_project_root: Optional[Path] = None
        self._ohos_project_rel: Optional[Path] = None
        try:
            original_path_file = self.project_root / "original_path.txt"
            if self.ohos_root and original_path_file.exists():
                original_rel = original_path_file.read_text(encoding="utf-8", errors="ignore").strip()
                if original_rel:
                    self._ohos_project_rel = Path(original_rel)
                    candidate = (self.ohos_root / original_rel).resolve()
                    if candidate.exists():
                        self._ohos_project_root = candidate
        except Exception:
            # ä¸å½±å“ä¸»æµç¨‹ï¼šæ— æ³•æ˜ å°„åˆ™é€€å›æ–‡ä»¶ååŒ¹é…
            self._ohos_project_root = None
            self._ohos_project_rel = None
        
        # compile_commands.json æ”¯æŒ
        self.compile_commands_parser = None
        if compile_commands_path and COMPILE_COMMANDS_AVAILABLE:
            try:
                print(f"  [åˆå§‹åŒ–] åˆ›å»º CompileCommandsParser...")
                self.compile_commands_parser = CompileCommandsParser(
                    compile_commands_path,
                    ohos_root
                )
                print(f"  âœ“ CompileCommandsParser åˆå§‹åŒ–æˆåŠŸ")
                logger.info(f"å·²åŠ è½½ compile_commands.json: {compile_commands_path}")
            except Exception as e:
                logger.warning(f"åŠ è½½ compile_commands.json å¤±è´¥: {e}")
                print(f"  âœ— CompileCommandsParser åˆå§‹åŒ–å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()

        # æ¨æ–­ OpenHarmony çš„çœŸå® out_dirï¼ˆç”¨äºç”Ÿæˆ out/.../gen/... ç”Ÿæˆç‰©ï¼‰
        try:
            self._ohos_build_out_dir = self._infer_ohos_build_out_dir()
        except Exception:
            self._ohos_build_out_dir = None
        
        # æ”¶é›†æ‰€æœ‰å¯èƒ½çš„å¤´æ–‡ä»¶ç›®å½•
        print(f"  [æ”¶é›†] æ­£åœ¨æ”¶é›†å¤´æ–‡ä»¶æœç´¢ç›®å½•...")
        self.include_dirs = self._collect_include_dirs()
        print(f"  âœ“ æ”¶é›†å®Œæˆ: {len(self.include_dirs)} ä¸ªå¤´æ–‡ä»¶æœç´¢ç›®å½•")

        # åœ¨ include æ”¶é›†å®ŒæˆååŠ è½½ TU ä¸Šä¸‹æ–‡æ˜ å°„ï¼ˆå¯é€‰ï¼‰
        # æ³¨æ„ï¼šæ˜ å°„æ–‡ä»¶ä½äº <workspace>/.preprocessed/tu_context_map.jsonï¼Œç”±é˜¶æ®µ1ä¾èµ–åˆ†æäº§ç”Ÿã€‚
        self._load_tu_context_map()
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)
        (self.output_dir / "src").mkdir(exist_ok=True)

    def _load_tu_context_map(self) -> None:
        """
        Load TU context mapping produced by stage1 (get_dependencies.py).

        The mapping pins a file-group (safe_module_name) to the exact compile_commands entry and the
        resulting preprocessed `.i`, so later stages don't "re-pick" a different TU when multi-profile
        entries exist.
        """
        self._tu_context_files = {}
        candidates: List[Path] = []
        env_dir = os.environ.get("PREPROCESS_OUTPUT_DIR", "").strip()
        if env_dir:
            candidates.append(Path(env_dir) / "tu_context_map.json")
        # Best-effort fallback: infer workspace root from output_dir (workspace/skeletons/<proj>)
        try:
            ws_root = self.output_dir.parent.parent
            candidates.append(ws_root / ".preprocessed" / "tu_context_map.json")
        except Exception:
            pass

        for p in candidates:
            try:
                if not p.exists():
                    continue
                data = json.loads(p.read_text(encoding="utf-8", errors="ignore") or "{}")
                files = data.get("files") if isinstance(data, dict) else None
                if isinstance(files, dict):
                    self._tu_context_map_path = p
                    self._tu_context_files = {str(k): (v if isinstance(v, dict) else {}) for k, v in files.items()}
                    logger.info(f"å·²åŠ è½½ TU ä¸Šä¸‹æ–‡æ˜ å°„: {p} (files={len(self._tu_context_files)})")
                    return
            except Exception as e:
                logger.debug(f"è¯»å– TU ä¸Šä¸‹æ–‡æ˜ å°„å¤±è´¥: {p}: {e}")
                continue

    def _map_to_ohos_path(self, path: Path) -> Path:
        """
        å°† SelfContained æ¨¡å—ä¸­çš„è·¯å¾„æ˜ å°„åˆ° OpenHarmony æºç æ ‘ä¸­çš„åŸå§‹è·¯å¾„ï¼ˆå¦‚æœå¯ç”¨ï¼‰ã€‚

        ç›®çš„ï¼šè®© CompileCommandsParser èƒ½ç”¨â€œç²¾ç¡®è·¯å¾„åŒ¹é…â€å‘½ä¸­ compile_commands.json çš„æ¡ç›®ï¼Œ
        é¿å…é€€åŒ–åˆ°æ–‡ä»¶ååŒ¹é…å¯¼è‡´æ‹¿åˆ°é”™è¯¯çš„ç¼–è¯‘ä¸Šä¸‹æ–‡ï¼ˆinclude é¡ºåº/å®å®šä¹‰ç­‰ä¼šé”™ï¼‰ã€‚
        """
        if not self._ohos_project_root or not self.ohos_root:
            return Path(path)

        try:
            project_root_resolved = self.project_root.resolve()
            path_resolved = Path(path).resolve()
            rel = path_resolved.relative_to(project_root_resolved)
            candidate = (self._ohos_project_root / rel).resolve()
            return candidate if candidate.exists() else Path(path)
        except Exception:
            return Path(path)

    def _infer_ohos_build_out_dir(self) -> Optional[Path]:
        """
        å°è¯•æ¨æ–­ OpenHarmony çœŸæ­£çš„ build out_dirï¼ˆç”¨äºç”Ÿæˆ out/.../gen/... ç”Ÿæˆç‰©ï¼‰ã€‚

        æƒ…å†µï¼š
        1) compile_commands.json ä½äº OHOS_ROOT/out/.../compile_commands.json
        2) compile_commands.json æ˜¯ä» registry archive è§£å‹å‡ºæ¥çš„ï¼ˆtranslation_outputs/shared/...ï¼‰ï¼Œ
           åŒç›®å½•å­˜åœ¨ profile.jsonï¼ŒåŒ…å« out_dir å­—æ®µ
        """
        if not self.ohos_root or not self.compile_commands_parser:
            return None
        try:
            ohos_root = Path(self.ohos_root).resolve()
        except Exception:
            return None

        try:
            cc_path = Path(self.compile_commands_parser.compile_db_path).resolve()
        except Exception:
            return None

        # Case 1: within OHOS tree.
        try:
            rel = cc_path.relative_to(ohos_root)
            if rel.parts and rel.parts[0] == "out":
                out_dir = (ohos_root / rel.parent).resolve()
                return out_dir if out_dir.exists() else out_dir
        except Exception:
            pass

        # Case 2: extracted archive with metadata.
        meta = cc_path.parent / "profile.json"
        if meta.exists():
            try:
                data = json.loads(meta.read_text(encoding="utf-8", errors="ignore"))
                out_dir_rel = str(data.get("out_dir") or "").replace("\\", "/").strip("/")
                if out_dir_rel:
                    out_dir = (ohos_root / out_dir_rel).resolve()
                    return out_dir if out_dir.exists() else out_dir
            except Exception:
                return None

        return None

    def _maybe_generate_ohos_out_gen_artifacts(self, attempt_debug: Dict[str, Any]) -> bool:
        """
        å½“ bindgen/clang æŠ¥é”™æç¤ºç¼ºå°‘ out/.../gen/... ç›¸å…³ include æ—¶ï¼Œå°è¯•é€šè¿‡ ninja ç”Ÿæˆã€‚

        è¿™æ˜¯â€œæå‡ stub é™çº§ç‡â€çš„å…³é”®ï¼šcompile_commands.json å¯èƒ½å¼•ç”¨ out/.../gen/...ï¼Œ
        ä½†ä»… gn gen å¹¶ä¸ä¼šå®é™…ç”Ÿæˆè¿™äº›æ–‡ä»¶ï¼Œéœ€è¦ ninja/action æ‰ä¼šäº§å‡ºã€‚
        """
        # Allow disabling for environments where building OpenHarmony is undesirable.
        if not self._env_flag("C2R_OHOS_GEN_ENSURE", default="1"):
            attempt_debug.setdefault("ohos_gen_ensure", {})["skipped"] = "disabled"
            return False
        if not self.ohos_root or not self.compile_commands_parser:
            return False
        if not self._ohos_build_out_dir:
            return False

        out_dir = Path(self._ohos_build_out_dir)
        build_ninja = out_dir / "build.ninja"
        if not build_ninja.exists():
            return False

        # Marker: avoid repeating heavy ninja work across retries in the same output tree.
        marker = None
        try:
            cc_path = Path(self.compile_commands_parser.compile_db_path).resolve()
            meta = cc_path.parent / "profile.json"
            if meta.exists():
                marker = cc_path.parent / "gen_ensured.marker"
                if marker.exists():
                    attempt_debug.setdefault("ohos_gen_ensure", {})["skipped"] = "marker_exists"
                    return False
        except Exception:
            marker = None

        # Only attempt if we can see that out/gen includes are currently missing.
        try:
            if (out_dir / "gen").exists():
                # Even if gen exists, some subpaths may still be missing; rely on bindgen include diag.
                pass
        except Exception:
            pass

        ninja = shutil.which("ninja")
        if not ninja:
            attempt_debug.setdefault("ohos_gen_ensure", {})["skipped"] = "ninja_not_found"
            return False

        # Seed targets: pick a few generated sources under out_dir/gen that are referenced by the compile DB
        # but not yet present on disk. Building generated *sources* tends to also materialize adjacent headers.
        seed_max = 12
        try:
            seed_max = int(os.environ.get("C2R_OHOS_GEN_SEED_MAX", str(seed_max)))
        except Exception:
            seed_max = 12

        targets: List[str] = []
        try:
            compile_db = getattr(self.compile_commands_parser, "compile_db", None) or []
            out_dir_str = str(out_dir).replace("\\", "/")
            for entry in compile_db:
                f = (entry or {}).get("file") or ""
                if not isinstance(f, str) or not f:
                    continue
                fp = f.replace("\\", "/")
                if "/gen/" not in fp:
                    continue
                # Absolute path within this out_dir
                if fp.startswith(out_dir_str + "/"):
                    p = Path(fp)
                else:
                    # Some compdb entries may be relative to `directory`
                    directory = (entry or {}).get("directory") or ""
                    if isinstance(directory, str) and directory:
                        p = (Path(directory) / f).resolve()
                    else:
                        p = Path(f)
                if not str(p).replace("\\", "/").startswith(out_dir_str + "/"):
                    continue
                if p.exists():
                    continue
                try:
                    rel = p.resolve().relative_to(out_dir.resolve())
                except Exception:
                    # best-effort
                    rel = Path(str(p).replace(out_dir_str + "/", ""))
                rel_s = str(rel).replace("\\", "/")
                if rel_s and rel_s not in targets:
                    targets.append(rel_s)
                if len(targets) >= seed_max:
                    break
        except Exception:
            targets = []

        if not targets:
            attempt_debug.setdefault("ohos_gen_ensure", {})["skipped"] = "no_missing_gen_targets"
            return False

        timeout_s = 600
        try:
            timeout_s = int(os.environ.get("C2R_OHOS_GEN_NINJA_TIMEOUT", str(timeout_s)))
        except Exception:
            timeout_s = 600

        attempt_debug.setdefault("ohos_gen_ensure", {}).update(
            {
                "out_dir": str(out_dir),
                "targets_count": len(targets),
                "targets_head": targets[:10],
                "timeout_s": timeout_s,
            }
        )

        try:
            proc = subprocess.run(
                [ninja, "-C", str(out_dir), *targets],
                capture_output=True,
                text=True,
                timeout=timeout_s,
            )
            attempt_debug["ohos_gen_ensure"].update(
                {
                    "returncode": proc.returncode,
                    "stdout_tail": (proc.stdout or "")[-2000:],
                    "stderr_tail": (proc.stderr or "")[-2000:],
                }
            )
            if proc.returncode == 0:
                if marker:
                    try:
                        marker.write_text(time.strftime("%Y-%m-%dT%H:%M:%S"), encoding="utf-8")
                    except Exception:
                        pass
                return True
            return False
        except subprocess.TimeoutExpired:
            attempt_debug["ohos_gen_ensure"].update({"returncode": "timeout"})
            return False
        except Exception as e:
            attempt_debug["ohos_gen_ensure"].update({"returncode": "exception", "error": str(e)[:300]})
            return False
    
    def _collect_include_dirs(self) -> List[Path]:
        """
        æ”¶é›†é¡¹ç›®ä¸­æ‰€æœ‰å¯èƒ½çš„å¤´æ–‡ä»¶ç›®å½•
        
        ä¼˜å…ˆä½¿ç”¨ compile_commands.json ä¸­çš„è·¯å¾„ï¼Œç„¶åæ·»åŠ é¡¹ç›®å†…çš„è·¯å¾„
        """
        include_dirs = set()
        
        # ä¼˜å…ˆï¼šä» compile_commands.json è·å–æ‰€æœ‰ include è·¯å¾„
        if self.compile_commands_parser:
            try:
                print(f"    [compile_commands] ä» compile_commands.json æå–æ‰€æœ‰ include è·¯å¾„...")
                # ä¼˜åŒ–ï¼šä¸ä¼ å…¥ source_filesï¼Œç›´æ¥æå–æ‰€æœ‰ include è·¯å¾„ï¼ˆæ›´å¿«ï¼‰
                compile_includes = self.compile_commands_parser.get_all_include_dirs()
                include_dirs.update(compile_includes)
                print(f"    âœ“ ä» compile_commands.json è·å–äº† {len(compile_includes)} ä¸ª include è·¯å¾„")
                logger.info(f"ä» compile_commands.json è·å–äº† {len(compile_includes)} ä¸ª include è·¯å¾„")
            except Exception as e:
                logger.warning(f"ä» compile_commands.json è·å– include è·¯å¾„å¤±è´¥: {e}")
                print(f"    âœ— ä» compile_commands.json è·å– include è·¯å¾„å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # å…¶æ¬¡ï¼šæ·»åŠ é¡¹ç›®æ ¹ç›®å½•
        include_dirs.add(self.project_root)
        
        # æŸ¥æ‰¾æ‰€æœ‰åŒ…å« .h æ–‡ä»¶çš„ç›®å½•
        for h_file in self.project_root.glob("**/*.h"):
            include_dirs.add(h_file.parent)
        for h_file in self.project_root.glob("**/*.hpp"):
            include_dirs.add(h_file.parent)
        
        # å¸¸è§çš„å¤´æ–‡ä»¶ç›®å½•å
        common_include_names = ['include', 'inc', 'headers', 'src', 'source']
        for name in common_include_names:
            for d in self.project_root.glob(f"**/{name}"):
                if d.is_dir():
                    include_dirs.add(d)
        
        return list(include_dirs)
    
    # =========================================================================
    # é˜¶æ®µ A: é¢„å¤„ç†ä¸ç±»å‹å±‚ (The Truth Layer)
    # =========================================================================
    
    def _extract_source_includes(self, source_files: List[Path]) -> List[str]:
        """
        ä»æºæ–‡ä»¶ä¸­æå– #include æŒ‡ä»¤å¼•ç”¨çš„å¤´æ–‡ä»¶å
        
        å…³é”®åŠŸèƒ½ï¼šåˆ†ææºæ–‡ä»¶ï¼ˆ.c/.cppï¼‰ä¸­çš„ include è¯­å¥ï¼Œ
        æ‰¾å‡ºé‚£äº›ä¸åœ¨é¡¹ç›® include ç›®å½•ä¸­çš„å¤–éƒ¨ä¾èµ–å¤´æ–‡ä»¶ã€‚
        
        æ³¨æ„ï¼šåªæ£€æŸ¥é¡¹ç›®è‡ªå·±çš„ include ç›®å½•ï¼Œè€Œä¸æ˜¯å…¨éƒ¨ compile_commands.json
        ä¸­çš„ 5000+ ä¸ªç›®å½•ã€‚è¿™æ ·æ‰èƒ½æ­£ç¡®è¯†åˆ«éœ€è¦é¢å¤–åŒ…å«çš„å¤–éƒ¨å¤´æ–‡ä»¶ã€‚
        
        Args:
            source_files: æºæ–‡ä»¶åˆ—è¡¨
        
        Returns:
            å¤–éƒ¨å¤´æ–‡ä»¶ååˆ—è¡¨ï¼ˆä¾‹å¦‚ ["softbus_error_code.h", "xxx.h"]ï¼‰
        """
        external_includes = set()
        
        # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… #include æŒ‡ä»¤
        include_pattern = re.compile(r'#\s*include\s*[<"]([^>"]+)[>"]')
        
        # åªä½¿ç”¨é¡¹ç›®è‡ªå·±çš„ include ç›®å½•ï¼ˆä¸ä½¿ç”¨å…¨éƒ¨ 5000+ ä¸ªç›®å½•ï¼‰
        project_include_dirs = []
        for src_file in source_files:
            if src_file.exists():
                # é¡¹ç›®çš„ include ç›®å½•é€šå¸¸ä¸ src åŒçº§
                project_root = src_file.parent.parent
                include_dir = project_root / "include"
                if include_dir.exists() and include_dir not in project_include_dirs:
                    project_include_dirs.append(include_dir)
        
        for src_file in source_files:
            if not src_file.exists():
                continue
            
            try:
                with open(src_file, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                for match in include_pattern.finditer(content):
                    header_name = match.group(1)
                    
                    # è·³è¿‡æ ‡å‡†åº“å¤´æ–‡ä»¶ï¼ˆæ²¡æœ‰æ‰©å±•åçš„é€šå¸¸æ˜¯ C++ æ ‡å‡†åº“ï¼‰
                    if not header_name.endswith('.h') and not header_name.endswith('.hpp'):
                        continue
                    
                    # è·³è¿‡ç³»ç»Ÿå¤´æ–‡ä»¶ï¼ˆä»¥ <> åŒ…å«çš„ï¼‰
                    # æ­£åˆ™å·²ç»åŒ¹é…äº† <> å’Œ "" ä¸¤ç§æƒ…å†µï¼Œè¿™é‡Œé€šè¿‡è·¯å¾„åˆ¤æ–­
                    if '/' in header_name and header_name.startswith(('sys/', 'linux/', 'bits/')):
                        continue

                    # è·³è¿‡å¸¸è§ç³»ç»Ÿå¤´æ–‡ä»¶ï¼ˆä¸éœ€è¦æ˜¾å¼åŠ å…¥ wrapperï¼›åº”ç”± sysroot/æ ‡å‡† include è§£æï¼‰
                    # å¦åˆ™å®¹æ˜“è¢«é”™è¯¯è§£æåˆ° OpenHarmony æºç æ ‘é‡Œçš„ musl å†…éƒ¨å¤´ï¼ˆthird_party/musl/src/include/*ï¼‰
                    # å¯¼è‡´å‡ºç° `hidden` ç­‰å†…éƒ¨å®/å…³é”®å­—è§£æé”™è¯¯ã€‚
                    if header_name in {
                        "assert.h",
                        "ctype.h",
                        "errno.h",
                        "fcntl.h",
                        "inttypes.h",
                        "limits.h",
                        "locale.h",
                        "math.h",
                        "pthread.h",
                        "sched.h",
                        "setjmp.h",
                        "signal.h",
                        "stdarg.h",
                        "stdbool.h",
                        "stddef.h",
                        "stdint.h",
                        "stdio.h",
                        "stdlib.h",
                        "string.h",
                        "time.h",
                        "unistd.h",
                    }:
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦åœ¨é¡¹ç›®è‡ªå·±çš„ include ç›®å½•ä¸­
                    is_in_project = False
                    for inc_dir in project_include_dirs:
                        if (inc_dir / header_name).exists():
                            is_in_project = True
                            break
                    
                    if not is_in_project:
                        external_includes.add(header_name)
            
            except Exception as e:
                logger.debug(f"åˆ†æ {src_file} çš„ include æŒ‡ä»¤å¤±è´¥: {e}")
        
        return list(external_includes)
    
    def _resolve_external_headers(self, header_names: List[str], source_files: Optional[List[Path]] = None) -> List[Path]:
        """
        é€šè¿‡ compile_commands.json è§£æå¤–éƒ¨å¤´æ–‡ä»¶çš„çœŸå®è·¯å¾„
        
        æ³¨æ„ï¼šåŒä¸€ä¸ªå¤´æ–‡ä»¶åå¯èƒ½å­˜åœ¨äºå¤šä¸ªä½ç½®ï¼Œä¼˜å…ˆé€‰æ‹©ï¼š
        1. åœ¨ interfaces/kits ç›®å½•ä¸‹çš„ï¼ˆé€šå¸¸æ˜¯å®˜æ–¹ APIï¼‰
        2. åœ¨ foundation/communication ç›®å½•ä¸‹çš„
        3. å…¶ä»–ä½ç½®
        
        Args:
            header_names: å¤´æ–‡ä»¶ååˆ—è¡¨ï¼ˆä¾‹å¦‚ ["softbus_error_code.h"]ï¼‰
            source_files: æºæ–‡ä»¶åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œç”¨äºæŒ‰çœŸå® TU çš„ include é¡ºåºè§£æåŒåå¤´æ–‡ä»¶ï¼‰
        
        Returns:
            æ‰¾åˆ°çš„å¤´æ–‡ä»¶å®Œæ•´è·¯å¾„åˆ—è¡¨
        """
        resolved_headers = []
        
        if not self.compile_commands_parser:
            logger.warning("æ²¡æœ‰ compile_commands.jsonï¼Œæ— æ³•è§£æå¤–éƒ¨å¤´æ–‡ä»¶")
            return resolved_headers
        
        # å…³é”®ç‚¹ï¼šåŒåå¤´æ–‡ä»¶åœ¨ OpenHarmony æºç æ ‘é‡Œéå¸¸å¸¸è§ï¼Œå¿…é¡»å°½é‡å¤ç°â€œçœŸå® TU çš„ include æœç´¢é¡ºåºâ€ã€‚
        # å¦åˆ™ä¼šéšæœºå‘½ä¸­åˆ° C++ å¤´ï¼ˆinnerkits/ipc_coreï¼‰ç­‰ä¸ç›¸å…³å®ç°ï¼Œå¯¼è‡´ bindgen å¤§é¢ç§¯å¤±è´¥ã€‚
        ordered_include_dirs: List[Path] = []
        if source_files:
            try:
                rep_src = None
                for s in source_files:
                    suf = str(s).lower()
                    if suf.endswith((".c", ".cc", ".cpp", ".cxx", ".c++")):
                        rep_src = Path(s)
                        break
                if rep_src:
                    ordered_include_dirs = list(
                        self.compile_commands_parser.get_includes_for_file(
                            self._map_to_ohos_path(rep_src),
                            normalize_paths=True,
                        ) or []
                    )
            except Exception:
                ordered_include_dirs = []

        # è·å–æ‰€æœ‰å·²çŸ¥çš„ include ç›®å½•ï¼ˆä½œä¸ºå…œåº•ï¼‰
        try:
            all_include_dirs = list(self.compile_commands_parser.get_all_include_dirs() or [])
        except Exception:
            all_include_dirs = []
        all_include_dirs = sorted(all_include_dirs, key=lambda p: str(p))
        
        for header_name in header_names:
            candidates = []
            
            # 1) å…ˆæŒ‰çœŸå® TU include é¡ºåºæŸ¥æ‰¾ï¼šæ‰¾åˆ°ç¬¬ä¸€ä¸ªå³ä¸ºâ€œçœŸå®å‘½ä¸­â€
            for inc_dir in ordered_include_dirs:
                header_path = Path(inc_dir) / header_name
                if header_path.exists():
                    candidates.append(header_path)
                    break

            # 2) å…œåº•ï¼šåœ¨æ‰€æœ‰ include ç›®å½•ä¸­æŸ¥æ‰¾æ‰€æœ‰åŒ¹é…é¡¹ï¼ˆç”¨äº TU æœªè¦†ç›–åˆ°çš„ includesï¼‰
            if not candidates:
                for inc_dir in all_include_dirs:
                    header_path = inc_dir / header_name
                    if header_path.exists():
                        candidates.append(header_path)
            
            if candidates:
                # ä¼˜å…ˆé€‰æ‹©æœ€åˆé€‚çš„è·¯å¾„ï¼ˆå½“ candidates>1 æ—¶éœ€è¦ç¨³å®šå†³ç­–ï¼‰
                filtered = []
                for c in candidates:
                    s = str(c).replace("\\", "/")
                    # Avoid musl source-internal headers (not public; also tends to be incompatible with target configs).
                    if "/third_party/musl/src/include/" in s:
                        continue
                    filtered.append(c)
                candidates = filtered or candidates

                def _rank(p: Path) -> Tuple[int, str]:
                    s = str(p).replace("\\", "/")
                    # Prefer C innerkits over C++ core headers when names collide.
                    if "/interfaces/innerkits/c/" in s:
                        return (0, s)
                    # Official kits APIs
                    if "interfaces/kits" in s:
                        return (1, s)
                    # Communication module (common for ipc/rpc)
                    if "foundation/communication" in s:
                        # De-prioritize ipc_core C++ headers when we're generating C bindings
                        if "/innerkits/ipc_core/" in s or "/include/c++/" in s or "/c++/" in s:
                            return (50, s)
                        return (2, s)
                    if "dsoftbus" in s:
                        return (3, s)
                    return (10, s)

                best_candidate = sorted(candidates, key=_rank)[0]

                resolved_headers.append(best_candidate)
                logger.info(f"âœ“ æ‰¾åˆ°å¤–éƒ¨å¤´æ–‡ä»¶: {header_name} -> {best_candidate}")
            else:
                logger.debug(f"æœªæ‰¾åˆ°å¤–éƒ¨å¤´æ–‡ä»¶: {header_name}")
        
        return resolved_headers
    
    def preprocess_source(self, c_file_path: Path, include_dirs: List[Path] = None) -> str:
        """
        é¢„å¤„ç† C/C++ æºæ–‡ä»¶
        
        ç­–ç•¥ï¼ˆå‚è€ƒ EvoC2rustï¼‰ï¼š
        1. é¦–å…ˆå°è¯•"è½»é‡é¢„å¤„ç†": gcc -fpreprocessed -dD -E
           - ä¸å±•å¼€ #includeï¼Œåªç§»é™¤æ³¨é‡Š
           - ä¸éœ€è¦å¤´æ–‡ä»¶ï¼Œæ°¸ä¸å¤±è´¥
        2. å¦‚æœéœ€è¦å®Œæ•´é¢„å¤„ç†ï¼ˆæœ‰ compile_commands.jsonï¼‰ï¼Œåˆ™å°è¯• gcc -E
        
        Args:
            c_file_path: C/C++ æºæ–‡ä»¶è·¯å¾„
            include_dirs: é¢å¤–çš„å¤´æ–‡ä»¶æœç´¢è·¯å¾„
        
        Returns:
            é¢„å¤„ç†åçš„æºä»£ç 
        """
        if str(c_file_path) in self.preprocessed_cache:
            return self.preprocessed_cache[str(c_file_path)]
        
        # ========== ç­–ç•¥ 1: è½»é‡é¢„å¤„ç† + å®å±•å¼€ ==========
        # å¢å¼ºç‰ˆï¼šåœ¨ç§»é™¤æ³¨é‡Šçš„åŒæ—¶ï¼Œå±•å¼€ OpenHarmony/LiteOS å¸¸ç”¨å®
        # è§£å†³ STATIC UINT32 TelnetOpen(...) è¢«è§£æä¸º fn UINT32 çš„é—®é¢˜
        try:
            # å…ˆå¤„ç†ç»­è¡Œç¬¦ \\\n
            with open(c_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                raw_content = f.read()
            
            # ç§»é™¤ç»­è¡Œç¬¦
            content_no_continuation = raw_content.replace('\\\n', '')
            
            # ğŸ”‘ å…³é”®ä¿®å¤ï¼šå±•å¼€ OpenHarmony/LiteOS å¸¸ç”¨å®
            # è¿™äº›å®åœ¨æºç ä¸­å¤§é‡ä½¿ç”¨ï¼Œå¦‚æœä¸å±•å¼€ä¼šå¯¼è‡´ Tree-sitter è§£æé”™è¯¯
            # 
            # â˜…â˜…â˜… æ–°å¢ï¼šä½¿ç”¨ MacroLearner è¿›è¡ŒåŠ¨æ€å®å±•å¼€ â˜…â˜…â˜…
            # ä¼˜åŠ¿ï¼š
            # 1. å¯ä»¥è·¨é¡¹ç›®å…±äº«å­¦ä¹ åˆ°çš„å®
            # 2. è‡ªåŠ¨ä»è§£æé”™è¯¯ä¸­å­¦ä¹ æ–°å®
            # 3. æŒä¹…åŒ–ä¿å­˜ï¼Œè¶Šç”¨è¶Šèªæ˜
            
            if MACRO_LEARNER_AVAILABLE:
                # ä½¿ç”¨ MacroLearner (æ¨è)
                macro_learner = get_global_macro_learner()
                processed_content = macro_learner.expand_all(content_no_continuation)
                logger.debug(f"ä½¿ç”¨ MacroLearner å±•å¼€å®: {macro_learner.get_macro_count()}")
            else:
                # å›é€€åˆ°ç¡¬ç¼–ç å®åˆ—è¡¨
                ohos_macro_expansions = {
                    # å­˜å‚¨ç±»è¯´æ˜ç¬¦å®
                    'STATIC': 'static',
                    'INLINE': 'inline',
                    'LITE_OS_SEC_TEXT': '',
                    'LITE_OS_SEC_TEXT_MINOR': '',
                    'LITE_OS_SEC_TEXT_INIT': '',
                    'LITE_OS_SEC_DATA': '',
                    'LITE_OS_SEC_DATA_INIT': '',
                    'LITE_OS_SEC_BSS': '',
                    'LITE_OS_SEC_RODATA': '',
                    
                    
                    # åŸºç¡€ç±»å‹å®
                    'VOID': 'void',
                    'CHAR': 'char',
                    'BOOL': '_Bool',
                    'INT8': 'signed char',
                    'UINT8': 'unsigned char',
                    'INT16': 'short',
                    'UINT16': 'unsigned short',
                    'INT32': 'int',
                    'UINT32': 'unsigned int',
                    'INT64': 'long long',
                    'UINT64': 'unsigned long long',
                    'FLOAT': 'float',
                    'DOUBLE': 'double',
                    'UINTPTR': 'uintptr_t',
                    'INTPTR': 'intptr_t',
                    'AARCHPTR': 'uintptr_t',
                    'size_t': 'unsigned long',
                    'ssize_t': 'long',
                }
                
                # ä½¿ç”¨æ­£åˆ™æ›¿æ¢å®ï¼ˆåªæ›¿æ¢ç‹¬ç«‹çš„æ ‡è¯†ç¬¦ï¼Œä¸æ›¿æ¢å­ä¸²ï¼‰
                processed_content = content_no_continuation
                for macro, expansion in ohos_macro_expansions.items():
                    # ä½¿ç”¨ word boundary é¿å…éƒ¨åˆ†åŒ¹é…
                    pattern = rf'\b{re.escape(macro)}\b'
                    processed_content = re.sub(pattern, expansion, processed_content)
                
            
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            import tempfile
            with tempfile.NamedTemporaryFile(mode='w', suffix=c_file_path.suffix, delete=False, encoding='utf-8') as tmp:
                tmp.write(processed_content)
                tmp_path = tmp.name
            
            try:
                # è½»é‡é¢„å¤„ç†ï¼šåªç§»é™¤æ³¨é‡Šï¼Œ-P ç§»é™¤è¡Œå·æ ‡è®°
                light_cmd = ["gcc", "-fpreprocessed", "-dD", "-E", "-P", tmp_path]
                result = subprocess.run(light_cmd, capture_output=True, text=True, timeout=30)
                
                if result.returncode == 0 and result.stdout.strip():
                    preprocessed = result.stdout
                    self.preprocessed_cache[str(c_file_path)] = preprocessed
                    logger.info(f"è½»é‡é¢„å¤„ç†æˆåŠŸ (å«å®å±•å¼€): {c_file_path.name}")
                    return preprocessed
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    os.unlink(tmp_path)
                except:
                    pass
        except Exception as e:
            logger.debug(f"è½»é‡é¢„å¤„ç†å¼‚å¸¸: {c_file_path.name}, {e}")
        
        # ========== ç­–ç•¥ 2: å®Œæ•´é¢„å¤„ç† (éœ€è¦å¤´æ–‡ä»¶) ==========
        try:
            cmd = ["gcc", "-E", "-P"]  # -P ä¸è¾“å‡ºè¡Œå·æ ‡è®°
            
            # ä¼˜å…ˆï¼šä» compile_commands.json è·å–è¯¥æ–‡ä»¶çš„ç²¾ç¡® include è·¯å¾„
            compile_includes = []
            if self.compile_commands_parser:
                try:
                    compile_includes = self.compile_commands_parser.get_includes_for_file(
                        self._map_to_ohos_path(c_file_path),
                        normalize_paths=True
                    )
                    if compile_includes:
                        logger.debug(f"ä» compile_commands.json è·å–äº† {len(compile_includes)} ä¸ª include è·¯å¾„: {c_file_path.name}")
                except Exception as e:
                    logger.debug(f"è·å– compile_commands include è·¯å¾„å¤±è´¥: {e}")
            
            # æ·»åŠ  compile_commands.json çš„è·¯å¾„ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
            added_dirs = set()
            for inc_dir in compile_includes:
                inc_str = str(inc_dir)
                if inc_str not in added_dirs:
                    cmd.extend(["-I", inc_str])
                    added_dirs.add(inc_str)
            
            # æ·»åŠ æ‰€æœ‰æ”¶é›†åˆ°çš„å¤´æ–‡ä»¶æœç´¢è·¯å¾„ï¼ˆä½œä¸ºè¡¥å……ï¼‰
            for inc_dir in self.include_dirs:
                inc_str = str(inc_dir)
                if inc_str not in added_dirs:
                    cmd.extend(["-I", inc_str])
                    added_dirs.add(inc_str)
            
            # æ·»åŠ é¢å¤–æŒ‡å®šçš„æœç´¢è·¯å¾„
            if include_dirs:
                for inc_dir in include_dirs:
                    inc_str = str(inc_dir)
                    if inc_str not in added_dirs:
                        cmd.extend(["-I", inc_str])
                        added_dirs.add(inc_str)
            
            # æ·»åŠ æºæ–‡ä»¶æ‰€åœ¨ç›®å½•
            source_dir_str = str(c_file_path.parent)
            if source_dir_str not in added_dirs:
                cmd.extend(["-I", source_dir_str])
            
            # å®šä¹‰å¸¸ç”¨å®ä»¥é¿å…ç¼–è¯‘é”™è¯¯
            cmd.extend([
                "-D__attribute__(x)=",
                "-D__extension__=",
                "-D__restrict=",
                "-D__inline=inline",
                "-D__inline__=inline",
                "-D__asm__(x)=",
                "-D__volatile__=",
                "-D__builtin_va_list=void*",
            ])
            
            cmd.append(str(c_file_path))
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                preprocessed = result.stdout
                self.preprocessed_cache[str(c_file_path)] = preprocessed
                logger.info(f"é¢„å¤„ç†æˆåŠŸ: {c_file_path.name}")
                return preprocessed
            else:
                logger.warning(f"é¢„å¤„ç†å¤±è´¥: {c_file_path.name}, ä½¿ç”¨æ¸…ç†åçš„æºç ")
                logger.debug(f"é”™è¯¯: {result.stderr[:500]}")
                # å¤±è´¥æ—¶è¿”å›æ¸…ç†åçš„æºç ï¼ˆç§»é™¤ä¼šå¯¼è‡´ tree-sitter è§£æå¤±è´¥çš„è¯­æ³•ï¼‰
                with open(c_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    raw_code = f.read()
                return self._sanitize_source_for_treesitter(raw_code)
                    
        except subprocess.TimeoutExpired:
            logger.warning(f"é¢„å¤„ç†è¶…æ—¶: {c_file_path.name}")
            with open(c_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                raw_code = f.read()
            return self._sanitize_source_for_treesitter(raw_code)
        except Exception as e:
            logger.error(f"é¢„å¤„ç†å¼‚å¸¸: {c_file_path.name}, {e}")
            with open(c_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                raw_code = f.read()
            return self._sanitize_source_for_treesitter(raw_code)
    
    def _sanitize_source_for_treesitter(self, source_code: str) -> str:
        """
        æ¸…ç†æºç ä»¥æé«˜ tree-sitter è§£ææˆåŠŸç‡
        
        å½“ gcc -E é¢„å¤„ç†å¤±è´¥æ—¶ä½¿ç”¨æ­¤æ–¹æ³•
        
        å¤„ç†çš„é—®é¢˜ï¼š
        1. __attribute__((xxx)) - GCC æ‰©å±•è¯­æ³•
        2. #include "xxx.txt" - åµŒå…¥å¼åŒ…å«
        3. __asm__ å—
        4. å¤šè¡Œæ³¨é‡Šä¸­çš„ä¸­æ–‡
        """
        import re
        
        result = source_code
        
        # 1. ç§»é™¤ __attribute__((xxx))
        # å¤„ç†å¤šè¡Œå’ŒåµŒå¥—æ‹¬å·
        result = re.sub(r'__attribute__\s*\(\([^)]*\)\)', '', result)
        result = re.sub(r'__attribute__\s*\(\(.*?\)\)', '', result, flags=re.DOTALL)
        
        # 2. æ³¨é‡Šæ‰åµŒå…¥å¼ #include (å¦‚ #include "xxx.txt")
        result = re.sub(r'(#include\s+"[^"]+\.txt")', r'/* \1 */', result)
        
        # 3. ç§»é™¤ __asm__ å’Œ __volatile__
        result = re.sub(r'__asm__\s*\([^;]*\);', ';', result)
        result = re.sub(r'__volatile__', '', result)
        
        # 4. ç§»é™¤ __extension__
        result = re.sub(r'__extension__', '', result)
        
        # 5. ç§»é™¤ __restrict
        result = re.sub(r'__restrict', '', result)
        
        # 6. ç®€åŒ– __builtin_xxx è°ƒç”¨
        result = re.sub(r'__builtin_va_list', 'void*', result)
        result = re.sub(r'__builtin_offsetof\s*\([^)]+\)', '0', result)
        
        # 7. ç§»é™¤ aligned(N) å±æ€§ (å¦‚æœæ®‹ç•™)
        result = re.sub(r'__aligned\s*\(\s*\d+\s*\)', '', result)
        
        # 8. ç§»é™¤å¤šè¡Œæ³¨é‡Šä¸­å¯èƒ½å¯¼è‡´é—®é¢˜çš„å†…å®¹ï¼ˆä¿ç•™æ³¨é‡Šæ ‡è®°ï¼‰
        def clean_multiline_comment(match):
            content = match.group(0)
            # åªä¿ç•™ ASCII å­—ç¬¦å’ŒåŸºæœ¬æ¢è¡Œ
            cleaned = ''.join(c if ord(c) < 128 or c in '\n\r\t ' else ' ' for c in content)
            return cleaned
        
        result = re.sub(r'/\*.*?\*/', clean_multiline_comment, result, flags=re.DOTALL)
        
        return result
    
    def _count_parse_errors(self, root_node) -> int:
        """ç»Ÿè®¡ AST ä¸­çš„ ERROR èŠ‚ç‚¹æ•°é‡"""
        count = 0
        if root_node.type == 'ERROR':
            count = 1
        for child in root_node.children:
            count += self._count_parse_errors(child)
        return count
    
    # =========================================================================
    # å¤´æ–‡ä»¶é¢„æ£€ç³»ç»Ÿ (Pre-flight Include Check)
    # =========================================================================
    
    def _resolve_include_path(self, header_name: str, search_paths: List[Path]) -> Optional[Path]:
        """
        æ¨¡æ‹Ÿç¼–è¯‘å™¨çš„æŸ¥æ‰¾é€»è¾‘ï¼šåœ¨æœç´¢è·¯å¾„ä¸­æ£€æŸ¥å¤´æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        
        Args:
            header_name: å¤´æ–‡ä»¶åï¼ˆå¯èƒ½åŒ…å«ç›¸å¯¹è·¯å¾„ï¼Œå¦‚ "sys/types.h"ï¼‰
            search_paths: æœç´¢è·¯å¾„åˆ—è¡¨
        
        Returns:
            æ‰¾åˆ°çš„å®Œæ•´è·¯å¾„ï¼Œæˆ– None
        """
        for path in search_paths:
            potential_path = Path(path) / header_name
            if potential_path.exists():
                return potential_path
        return None
    
    def _preflight_check_includes(
        self, 
        header_files: List[Path],
        verbose: bool = True
    ) -> Tuple[bool, Set[Path]]:
        """
        åœ¨è¿è¡Œ bindgen å‰ï¼Œé¢„å…ˆæ£€æŸ¥æ‰€æœ‰å¤´æ–‡ä»¶æ˜¯å¦å¯è¾¾ã€‚
        å¦‚æœä¸å¯è¾¾ï¼Œå°è¯•é€šè¿‡å…¨å±€ç´¢å¼•ä¿®è¡¥ã€‚
        
        è¿™æ˜¯ä¸€ç§ä¸»åŠ¨ä¿®å¤ç­–ç•¥ï¼Œè€Œéè¢«åŠ¨ç­‰å¾… bindgen æŠ¥é”™ã€‚
        
        Args:
            header_files: è¦å¤„ç†çš„å¤´æ–‡ä»¶åˆ—è¡¨
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
        
        Returns:
            (æ˜¯å¦æ‰€æœ‰å¤´æ–‡ä»¶éƒ½å¯è¾¾, æ–°å¢çš„æœç´¢è·¯å¾„é›†åˆ)
        """
        all_includes_found = True
        new_paths = set()
        missing_headers = []
        
        # æå–æ‰€æœ‰éœ€è¦æ£€æŸ¥çš„ #include
        headers_to_check = set()
        
        include_pattern = re.compile(r'#\s*include\s*(?:"([^"]+)"|<([^>]+)>)')
        
        for header_file in header_files:
            if not header_file.exists():
                continue
            
            try:
                with open(header_file, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                matches = include_pattern.findall(content)
                for m in matches:
                    header_name = m[0] or m[1]
                    if header_name:
                        headers_to_check.add(header_name)
            except Exception as e:
                logger.debug(f"è¯»å–å¤´æ–‡ä»¶ {header_file} å¤±è´¥: {e}")
        
        if verbose:
            print(f"ğŸ” Pre-flight check: Verifying {len(headers_to_check)} includes...")
        
        # å½“å‰çš„æœç´¢è·¯å¾„
        current_search_paths = list(self.include_dirs)
        
        # é€ä¸ªæ£€æŸ¥
        for header in sorted(headers_to_check):
            # 1. å…ˆåœ¨ç°æœ‰è·¯å¾„é‡Œæ‰¾
            if self._resolve_include_path(header, current_search_paths):
                continue  # æ‰¾åˆ°äº†ï¼Œä¸‹ä¸€ä¸ª
            
            # 2. æ²¡æ‰¾åˆ°ï¼è§¦å‘æš´åŠ›æœç´¢
            if verbose:
                print(f"  âš ï¸ Missing: {header}")
            
            found_path = None
            
            # 2.1 å°è¯•é€šè¿‡ compile_commands.json æŸ¥æ‰¾
            if self.compile_commands_parser:
                try:
                    found_path = self.compile_commands_parser.find_header_path(header)
                except Exception as e:
                    logger.debug(f"é€šè¿‡ compile_commands æŸ¥æ‰¾ {header} å¤±è´¥: {e}")
            
            # 2.2 å°è¯•åœ¨é¡¹ç›®ç›®å½•é€’å½’æœç´¢
            if not found_path and self.project_root:
                for candidate in self.project_root.rglob(Path(header).name):
                    if candidate.is_file():
                        found_path = candidate.parent
                        break
            
            if found_path:
                if found_path not in current_search_paths and found_path not in new_paths:
                    if verbose:
                        print(f"    âœ… Auto-fixed: Adding {found_path}")
                    new_paths.add(found_path)
                    current_search_paths.append(found_path)
            else:
                all_includes_found = False
                missing_headers.append(header)
                if verbose:
                    print(f"    âŒ Not found anywhere")
        
        # å°†æ–°è·¯å¾„æ·»åŠ åˆ° include_dirs
        for p in new_paths:
            if p not in self.include_dirs:
                self.include_dirs.append(p)
        
        if missing_headers:
            logger.warning(f"Pre-flight: {len(missing_headers)} headers not found: {missing_headers[:10]}")
        elif verbose:
            print(f"âœ… Pre-flight check passed! All includes resolved.")
        
        return all_includes_found, new_paths
    
    # =========================================================================
    # åŠ¨æ€å®å­¦ä¹ ç³»ç»Ÿ (Dynamic Macro Learning)
    # =========================================================================
    
    # å·²å­¦ä¹ çš„å®å®šä¹‰ï¼ˆè·¨é¡¹ç›®æŒä¹…åŒ–ï¼‰
    _learned_macros: Dict[str, str] = {}
    
    def _learn_macro_from_parse_error(
        self, 
        source_code: str, 
        error_line: int
    ) -> Optional[Tuple[str, str]]:
        """
        ä» Tree-sitter è§£æé”™è¯¯ä¸­å­¦ä¹ æ–°çš„å®å®šä¹‰
        
        å½“ Tree-sitter è§£æå¤±è´¥æ—¶ï¼Œåˆ†æé”™è¯¯è¡Œçš„ä»£ç ï¼Œ
        å°è¯•è¯†åˆ«å¹²æ‰°è§£æçš„å®ã€‚
        
        Args:
            source_code: æºä»£ç 
            error_line: é”™è¯¯è¡Œå·ï¼ˆ1-basedï¼‰
        
        Returns:
            (å®å, å±•å¼€åçš„å€¼) æˆ– None
        """
        lines = source_code.split('\n')
        if error_line < 1 or error_line > len(lines):
            return None
        
        line = lines[error_line - 1].strip()
        
        # å¸¸è§çš„å®æ¨¡å¼
        # æ¨¡å¼1: MACRO type function(...) - ç±»å‹è¯´æ˜ç¬¦å®
        type_specifier_pattern = re.match(
            r'^([A-Z][A-Z0-9_]*)\s+((?:unsigned\s+|signed\s+)?(?:int|long|short|char|void|float|double|_Bool|\w+_t))\s+(\w+)\s*\(',
            line
        )
        if type_specifier_pattern:
            potential_macro = type_specifier_pattern.group(1)
            # æ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥çš„ç±»å‹ä¿®é¥°ç¬¦å®
            if potential_macro in ['STATIC', 'INLINE', 'EXTERN', 'CONST', 
                                   'LITE_OS_SEC_TEXT', 'LITE_OS_SEC_DATA',
                                   'HDF_STATIC', 'OHOS_API']:
                # è¿™æ˜¯å­˜å‚¨ç±»è¯´æ˜ç¬¦å®ï¼Œåº”è¯¥å±•å¼€ä¸ºç©ºæˆ– static/inline
                if 'STATIC' in potential_macro:
                    return (potential_macro, 'static')
                elif 'INLINE' in potential_macro:
                    return (potential_macro, 'inline')
                else:
                    return (potential_macro, '')
        
        # æ¨¡å¼2: MACRO function(...) - å®è¢«è¯¯è®¤ä¸ºå‡½æ•°å
        func_name_pattern = re.match(
            r'^(?:static\s+|inline\s+)*([A-Z][A-Z0-9_]*)\s+(\w+)\s*\(',
            line
        )
        if func_name_pattern:
            potential_macro = func_name_pattern.group(1)
            # æ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥çš„ç±»å‹å®
            known_type_macros = {
                'VOID': 'void', 'CHAR': 'char', 'BOOL': '_Bool',
                'INT8': 'signed char', 'UINT8': 'unsigned char',
                'INT16': 'short', 'UINT16': 'unsigned short',
                'INT32': 'int', 'UINT32': 'unsigned int',
                'INT64': 'long long', 'UINT64': 'unsigned long long',
                'FLOAT': 'float', 'DOUBLE': 'double',
                'UINTPTR': 'uintptr_t', 'INTPTR': 'intptr_t',
            }
            if potential_macro in known_type_macros:
                return (potential_macro, known_type_macros[potential_macro])
            
            # å°è¯•æ¨æ–­ï¼šå…¨å¤§å†™æ ‡è¯†ç¬¦åœ¨å‡½æ•°å®šä¹‰å¼€å¤´ï¼Œå¯èƒ½æ˜¯ç±»å‹å®
            if len(potential_macro) >= 2 and potential_macro.isupper():
                logger.info(f"ğŸ“ Learned new type macro: {potential_macro} -> int")
                return (potential_macro, 'int')  # é»˜è®¤å‡è®¾ä¸º int
        
        return None
    
    def _expand_learned_macros(self, source_code: str) -> str:
        """
        åº”ç”¨å·²å­¦ä¹ çš„å®å±•å¼€
        
        Args:
            source_code: æºä»£ç 
        
        Returns:
            å®å±•å¼€åçš„æºä»£ç 
        """
        result = source_code
        
        for macro, expansion in self._learned_macros.items():
            pattern = rf'\b{re.escape(macro)}\b'
            result = re.sub(pattern, expansion, result)
        
        return result
    
    def _parse_with_macro_learning(
        self, 
        source_code: str,
        max_learning_iterations: int = 3
    ) -> Tuple[Any, str]:
        """
        å¸¦å®å­¦ä¹ çš„ Tree-sitter è§£æ
        
        å¦‚æœè§£æå¤±è´¥ï¼ˆERROR èŠ‚ç‚¹è¿‡å¤šï¼‰ï¼Œå°è¯•è‡ªåŠ¨å­¦ä¹ æ–°å®å¹¶é‡è¯•ã€‚
        
        â˜…â˜…â˜… å¢å¼ºï¼šä½¿ç”¨ MacroLearner æ¨¡å—è¿›è¡ŒæŒä¹…åŒ–çš„å®å­¦ä¹  â˜…â˜…â˜…
        - å­¦ä¹ åˆ°çš„å®å¯ä»¥è·¨é¡¹ç›®å¤ç”¨
        - è‡ªåŠ¨ä¿å­˜åˆ° ~/.c2rust/learned_macros.json
        - ç³»ç»Ÿè¶Šç”¨è¶Šèªæ˜
        
        Args:
            source_code: æºä»£ç 
            max_learning_iterations: æœ€å¤§å­¦ä¹ è¿­ä»£æ¬¡æ•°
        
        Returns:
            (AST tree, å¤„ç†åçš„æºä»£ç )
        """
        current_source = source_code
        
        # ä¼˜å…ˆä½¿ç”¨ MacroLearnerï¼ˆå¦‚æœå¯ç”¨ï¼‰
        macro_learner = get_global_macro_learner() if MACRO_LEARNER_AVAILABLE else None
        
        for iteration in range(max_learning_iterations):
            # è§£æ
            tree = cpp_parser.parse(bytes(current_source, 'utf-8'))
            
            # æ£€æŸ¥å¥åº·åº¦
            error_rate = self._get_error_rate(tree.root_node)
            
            if error_rate < 0.1:  # å°äº 10% é”™è¯¯ç‡ï¼Œè®¤ä¸ºè§£ææˆåŠŸ
                if iteration > 0:
                    logger.info(f"ğŸ“ Macro learning successful after {iteration} iterations")
                return tree, current_source
            
            # å°è¯•ä»é”™è¯¯ä½ç½®å­¦ä¹ å®
            error_locations = self._get_error_locations(tree.root_node)
            
            if not error_locations:
                break
            
            learned_any = False
            
            if macro_learner:
                # â˜… ä½¿ç”¨ MacroLearner å­¦ä¹ æ–°å® â˜…
                result = macro_learner.learn_from_parse_errors(
                    current_source, 
                    error_locations,
                    max_learn=10
                )
                if result.learned:
                    logger.info(f"ğŸ“ Learned {len(result.learned)} macros via MacroLearner")
                    learned_any = True
                    current_source = result.source_modified
            else:
                # å›é€€åˆ°æœ¬åœ°å­¦ä¹ ï¼ˆä¸æŒä¹…åŒ–ï¼‰
                for line_num, _ in error_locations[:5]:
                    result = self._learn_macro_from_parse_error(current_source, line_num)
                    if result:
                        macro_name, expansion = result
                        if macro_name not in self._learned_macros:
                            logger.info(f"ğŸ“ Auto-learned macro: {macro_name} -> {expansion}")
                            self._learned_macros[macro_name] = expansion
                            learned_any = True
                
                if learned_any:
                    current_source = self._expand_learned_macros(current_source)
            
            if not learned_any:
                break
        
        return tree, current_source
    
    def _get_error_rate(self, root_node) -> float:
        """è®¡ç®— AST é”™è¯¯ç‡"""
        total = [0]
        errors = [0]
        
        def traverse(node):
            total[0] += 1
            if node.type == 'ERROR':
                errors[0] += 1
            for child in node.children:
                traverse(child)
        
        traverse(root_node)
        return errors[0] / total[0] if total[0] > 0 else 0.0
    
    def _get_error_locations(self, root_node) -> List[Tuple[int, int]]:
        """è·å–æ‰€æœ‰ ERROR èŠ‚ç‚¹çš„ä½ç½®"""
        locations = []
        
        def traverse(node):
            if node.type == 'ERROR':
                locations.append((
                    node.start_point[0] + 1,  # è¡Œå·ä» 1 å¼€å§‹
                    node.start_point[1]
                ))
            for child in node.children:
                traverse(child)
        
        traverse(root_node)
        return locations
    
    # =========================================================================
    # ç±»å‹éª¨æ¶ç”Ÿæˆ
    # =========================================================================
    
    def generate_type_skeleton(
        self, 
        header_files: List[Path], 
        output_file: str = "types.rs",
        source_files: List[Path] = None
    ) -> bool:
        """
        ä½¿ç”¨ bindgen ç”Ÿæˆ types.rsï¼ŒåŒ…å«æ‰€æœ‰ C çš„ struct, enum, union, typedef
        
        è¿™æ˜¯é¡¹ç›®çš„"çœŸç†å±‚"â€”â€”ç±»å‹å®šä¹‰ç»å¯¹æ­£ç¡®
        
        å‚è€ƒ LLMigrate å’Œ EvoC2Rust çš„æ–¹æ³•
        
        å¢å¼ºåŠŸèƒ½ï¼š
        1. åŸºäºæ„å»ºæ•°æ®åº“çš„æ™ºèƒ½å¯»è·¯ (Build-Database Guided Discovery)
        2. è‡ªåŠ¨åˆ†ææºæ–‡ä»¶ä¸­çš„ #include æŒ‡ä»¤ï¼Œè§£æå¤–éƒ¨ä¾èµ–å¤´æ–‡ä»¶
        
        Args:
            header_files: å¤´æ–‡ä»¶åˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶å
            source_files: æºæ–‡ä»¶åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œç”¨äºåˆ†æå¤–éƒ¨ä¾èµ–ï¼‰
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if not header_files:
            logger.warning("æ²¡æœ‰å¤´æ–‡ä»¶ï¼Œè·³è¿‡ bindgen ç±»å‹ç”Ÿæˆ")
            return False
        
        # ========== å¢å¼ºï¼šåˆ†ææºæ–‡ä»¶ä¸­çš„å¤–éƒ¨ä¾èµ– ==========
        all_headers = list(header_files)  # å¤åˆ¶åˆ—è¡¨
        
        if source_files:
            external_includes = self._extract_source_includes(source_files)
            if external_includes:
                print(f"  âœ“ å‘ç° {len(external_includes)} ä¸ªå¤–éƒ¨å¤´æ–‡ä»¶ä¾èµ–: {external_includes}")
                logger.info(f"å‘ç° {len(external_includes)} ä¸ªå¤–éƒ¨å¤´æ–‡ä»¶ä¾èµ–: {external_includes}")
                
                # å°è¯•è§£æå¤–éƒ¨å¤´æ–‡ä»¶çš„çœŸå®è·¯å¾„
                resolved_headers = self._resolve_external_headers(external_includes, source_files=source_files)
                if resolved_headers:
                    print(f"  âœ“ æˆåŠŸè§£æ {len(resolved_headers)} ä¸ªå¤–éƒ¨å¤´æ–‡ä»¶")
                    logger.info(f"æˆåŠŸè§£æ {len(resolved_headers)} ä¸ªå¤–éƒ¨å¤´æ–‡ä»¶")
                    all_headers.extend(resolved_headers)
        
        # ========== â˜…â˜…â˜… æ–°å¢ï¼šé¢„æ£€ä¸ä¿®è¡¥ â˜…â˜…â˜… ==========
        # åœ¨è¿è¡Œ bindgen å‰ï¼Œä¸»åŠ¨æ£€æŸ¥æ‰€æœ‰å¤´æ–‡ä»¶æ˜¯å¦å¯è¾¾
        # å¦‚æœå‘ç°ç¼ºå¤±ï¼Œç«‹å³è§¦å‘å…¨å±€æœç´¢ä¿®è¡¥ï¼Œé¿å…è¢«åŠ¨ç­‰å¾… bindgen æŠ¥é”™
        print("\nğŸ“‹ Stage A.1: Pre-flight Include Check")
        all_resolved, new_paths = self._preflight_check_includes(all_headers, verbose=True)
        
        if new_paths:
            print(f"  âœ… Pre-flight fixed {len(new_paths)} include paths")
            logger.info(f"é¢„æ£€ä¿®è¡¥äº† {len(new_paths)} ä¸ª include è·¯å¾„")
        
        # ========== â˜…â˜…â˜… ç°åœ¨å†è¿è¡Œ bindgenï¼ŒæˆåŠŸç‡æé«˜ â˜…â˜…â˜… ==========
        print("\nğŸ“‹ Stage A.2: Running Bindgen")
        # bindgen çš„â€œæ™ºèƒ½å¯»è·¯é‡è¯•â€æ¬¡æ•°ã€‚
        # ç»éªŒï¼šå¾ˆå¤š OHOS å¤´æ–‡ä»¶ç¼ºå¤±æ˜¯â€œé“¾å¼â€çš„ï¼ˆè¡¥é½ä¸€ä¸ªå¤´åï¼Œä¸‹ä¸€å±‚åˆç¼ºï¼‰ï¼Œ
        # ä¸ºäº†å°½é‡é™ä½ stub æ¯”ä¾‹ï¼Œé»˜è®¤ç»™åˆ°æ›´é«˜çš„é‡è¯•ä¸Šé™ï¼ˆä»ä¼šåœ¨æ— è¿›å±•æ—¶æå‰é€€å‡ºï¼‰ã€‚
        try:
            max_retries = int(os.environ.get("C2R_BINDGEN_MAX_RETRIES", "12"))
            if max_retries < 1:
                max_retries = 1
        except Exception:
            max_retries = 12
        success = self._run_bindgen_with_smart_discovery(
            all_headers,
            output_file,
            max_retries=max_retries,
            source_files=source_files,
        )
        return success
    
    def _run_bindgen_with_smart_discovery(
        self,
        header_files: List[Path],
        output_file: str,
        max_retries: int = 5,
        source_files: List[Path] = None,
    ) -> bool:
        """
        ä¸‰æ®µå¼å›é€€çš„ types.rs ç”Ÿæˆå™¨

        Phase 1 æ”¹è¿›ï¼šç§»é™¤ LLM ä¾èµ–ï¼Œä½¿ç”¨ç¡®å®šæ€§çš„ä¸‰æ®µå¼å›é€€

        ç­–ç•¥ï¼š
        - Tier A: bindgen (primary)
        - Tier B: clang -E é¢„å¤„ç† â†’ bindgen (secondary)
        - Tier C: stub types.rs (æœ€ç»ˆå…œåº•ï¼Œä¿è¯ç¼–è¯‘é€šè¿‡)

        åŒæ—¶ç”Ÿæˆ types_generation_report.json ç”¨äºè°ƒè¯•

        Args:
            header_files: å¤´æ–‡ä»¶åˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶å
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        import json

        truth_mode = self._env_flag("C2R_TRUTH_MODE", "0")
        # In truth-mode, disable any "make it compile" fallbacks that are not true C/Rust bindings.
        # Keep the code paths for future rollback/ablation via env overrides.
        enable_types_rs_sanitizer = (not truth_mode) or self._env_flag("C2R_TRUTH_ALLOW_TYPES_RS_SANITIZER", "0")
        enable_tier_b = (not truth_mode) or self._env_flag("C2R_TRUTH_ALLOW_BINDGEN_TIER_B", "0")
        enable_tier_c_stub = (not truth_mode) or self._env_flag("C2R_TRUTH_ALLOW_BINDGEN_TIER_C_STUB", "0")

        # åˆå§‹åŒ– include è·¯å¾„é›†åˆ
        #
        # é‡è¦ï¼šä¸è¦ä¸€å¼€å§‹å°±æŠŠâ€œå…¨å±€ include å¹¶é›†â€å¡è¿› bindgenã€‚
        # è¿™ä¼šå¼•å…¥å¤§é‡åŒåå¤´æ–‡ä»¶ç¢°æ’ï¼ˆä¾‹å¦‚ string.h/session.hï¼‰ï¼Œå¯¼è‡´é€‰é”™å¤´æ–‡ä»¶è€Œå¤±è´¥æˆ–ç”Ÿæˆé”™è¯¯è¯­ä¹‰ã€‚
        #
        # å¦‚æœæœ‰ compile_commands + source_filesï¼Œæˆ‘ä»¬ä¼˜å…ˆä¾èµ–â€œå•ä¸ª TU çš„çœŸå®ä¸Šä¸‹æ–‡ï¼ˆä¿åºï¼‰â€ï¼›
        # ç¼ºå•¥å¤´æ–‡ä»¶å†æŒ‰éœ€è¡¥é½ï¼ˆsmart discoveryï¼‰ã€‚
        current_includes: Set[Path] = set()
        if not self.compile_commands_parser or not source_files:
            current_includes = set(self.include_dirs)

        # è®°å½•å·²å°è¯•æŸ¥æ‰¾ä½†æ‰¾ä¸åˆ°çš„å¤´æ–‡ä»¶ï¼ˆé¿å…é‡å¤æŸ¥æ‰¾ï¼‰
        unresolvable_headers = set()

        output_path = self.output_dir / "src" / output_file

        # ç”ŸæˆæŠ¥å‘Šçš„æ•°æ®
        report = {
            "mode": None,
            "success": False,
            "missing_types": [],
            "source_scan_files": [str(h) for h in header_files],
            "compile_commands_loaded": bool(self.compile_commands_parser),
            "compile_commands_path": str(self.compile_commands_parser.compile_db_path) if self.compile_commands_parser else None,
            "project_root": str(self.project_root),
            "ohos_root": str(self.ohos_root) if self.ohos_root else None,
            "ohos_project_rel": str(self._ohos_project_rel) if self._ohos_project_rel else None,
            "bindgen_debug": self._env_flag("C2R_BINDGEN_DEBUG"),
            "bindgen_debug_keep_files": self._env_flag("C2R_BINDGEN_DEBUG_KEEP_FILES"),
            "truth_mode": truth_mode,
            "enable_types_rs_sanitizer": enable_types_rs_sanitizer,
            "enable_tier_b": enable_tier_b,
            "enable_tier_c_stub": enable_tier_c_stub,
            # æ˜¯å¦å­˜åœ¨å¤š build profileï¼šåŒä¸€ source file åœ¨ compile_commands.json ä¸­å‡ºç°å¤šæ¡ä¸åŒå‘½ä»¤
            "has_multiple_build_profiles": False,
            # ä»…è®°å½•å‰è‹¥å¹²æ¡æ ·ä¾‹ï¼Œé¿å…æŠ¥å‘Šè¿‡å¤§
            "multi_build_profiles": [],
            "attempts": [],
            "final_output_valid": False
        }

        # Hint subpaths (relative to OHOS root) for smarter missing-header resolution.
        # Use a few prefix segments to avoid overly-specific matches.
        preferred_subpaths: Optional[List[str]] = None
        try:
            if self._ohos_project_rel:
                parts = list(self._ohos_project_rel.parts)
                max_parts = min(len(parts), 6)
                preferred_subpaths = [str(Path(*parts[:n])) for n in range(max_parts, 1, -1)]
        except Exception:
            preferred_subpaths = None

        # ------------------------------------------------------------------
        # Build profile è¯Šæ–­ï¼ˆä¸å½±å“ types ç”Ÿæˆï¼Œåªç”¨äºè¾“å‡ºå¯è§£é‡Šçš„â€œæ„å»ºä¸Šä¸‹æ–‡é£é™©â€ï¼‰
        # ------------------------------------------------------------------
        if source_files and self.compile_commands_parser:
            try:
                max_samples = 20
                multi_profiles = []
                for src in source_files:
                    mapped_src = self._map_to_ohos_path(Path(src))
                    try:
                        src_resolved = Path(mapped_src).resolve(strict=False)
                    except Exception:
                        src_resolved = Path(mapped_src)

                    entries = self.compile_commands_parser.get_all_entries_for_file(src_resolved)
                    if not entries or len(entries) <= 1:
                        continue

                    # ä»…ä¿ç•™â€œç¡®å®å‘½ä¸­åŒä¸€è·¯å¾„â€çš„æ¡ç›®ï¼Œé¿å…æ–‡ä»¶åç¢°æ’å¯¼è‡´è¯¯æŠ¥
                    resolved_entries = []
                    for e in entries:
                        ef = e.get("file")
                        if not ef:
                            continue
                        entry_dir = e.get("directory") or ""
                        ef_path = Path(ef)
                        if not ef_path.is_absolute() and entry_dir:
                            ef_path = Path(entry_dir) / ef_path
                        try:
                            if ef_path.resolve(strict=False) == src_resolved:
                                resolved_entries.append(e)
                        except Exception:
                            continue

                    if len(resolved_entries) <= 1:
                        continue

                    # ç»Ÿè®¡ unique commandï¼ˆåŒä¸€ file è‹¥å­˜åœ¨å¤šæ¡ä¸åŒ commandï¼Œè§†ä¸º multi-profileï¼‰
                    unique_cmds = set()
                    for e in resolved_entries:
                        cmd = e.get("command")
                        if not cmd:
                            args = e.get("arguments")
                            if isinstance(args, list) and args:
                                cmd = " ".join(str(a) for a in args)
                        if cmd:
                            unique_cmds.add(cmd)

                    if len(unique_cmds) <= 1:
                        # å¤šæ¡ entry ä½†å‘½ä»¤ç›¸åŒ â†’ è§†ä¸ºé‡å¤ï¼Œä¸ç®—å¤š profile
                        continue

                    multi_profiles.append({
                        "file": str(src_resolved),
                        "unique_commands": len(unique_cmds),
                        "entries": len(resolved_entries),
                    })

                    if len(multi_profiles) >= max_samples:
                        break

                if multi_profiles:
                    report["has_multiple_build_profiles"] = True
                    report["multi_build_profiles"] = multi_profiles
            except Exception as e:
                # è¯Šæ–­å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                report["build_profile_diagnostic_error"] = str(e)[:300]

        # ========== Tier A: ç›´æ¥ bindgen ==========
        print("\nğŸ“‹ Tier A: Direct Bindgen")
        for attempt in range(max_retries):
            # å°è¯•è¿è¡Œ bindgen
            success, error_msg, missing_files, attempt_debug = self._attempt_bindgen(
                header_files, output_file, current_includes, source_files=source_files
            )

            report["attempts"].append({
                "tier": "A",
                "attempt": attempt + 1,
                "success": success,
                "error": error_msg[:500] if error_msg else None,
                "missing_files": missing_files,
                "debug": attempt_debug,
            })

            if success:
                # éªŒè¯è¾“å‡º
                is_valid, validation_msg = self._validate_types_rs(output_path)

                # å¦‚æœéªŒè¯å¤±è´¥ï¼Œå°è¯•å‡€åŒ–
                if not is_valid:
                    if enable_types_rs_sanitizer:
                        logger.info(f"bindgen è¾“å‡ºéªŒè¯å¤±è´¥: {validation_msg}ï¼Œå°è¯•å‡€åŒ–...")
                        modified, fix_count = self._sanitize_types_rs(output_path)
                        if modified:
                            logger.info(f"å‡€åŒ–å™¨ä¿®å¤äº† {fix_count} ä¸ªé—®é¢˜ï¼Œé‡æ–°éªŒè¯...")
                            is_valid, validation_msg = self._validate_types_rs(output_path)
                    else:
                        logger.info("types.rs å‡€åŒ–å™¨å·²ç¦ç”¨ï¼ˆtruth-mode æˆ–æœªæ˜¾å¼å¼€å¯ï¼‰ï¼Œä¿ç•™åŸå§‹ bindgen è¾“å‡º")

                if is_valid:
                    report["mode"] = "bindgen"
                    report["success"] = True
                    report["final_output_valid"] = True
                    self._write_types_generation_report(report)
                    if attempt > 0:
                        print(f"âœ… Bindgen successful after {attempt} retries!")
                        logger.info(f"bindgen æˆåŠŸï¼ˆç»è¿‡ {attempt} æ¬¡é‡è¯•ï¼‰")
                    else:
                        print("âœ… Bindgen successful!")
                    return True
                else:
                    logger.warning(f"bindgen è¾“å‡ºéªŒè¯å¤±è´¥ï¼ˆå‡€åŒ–åä»ç„¶å¤±è´¥ï¼‰: {validation_msg}")
                    # è®°å½•éªŒè¯å¤±è´¥åŸå› ï¼Œä¾¿äºåç»­å®šä½â€œbindgen æˆåŠŸä½†è¾“å‡ºä¸å¯ç”¨â€çš„åœºæ™¯
                    try:
                        report["attempts"][-1]["validation_error"] = validation_msg
                    except Exception:
                        pass
                    # ç»§ç»­å°è¯•ï¼Œå¯èƒ½æ˜¯è¾“å‡ºä¸å®Œæ•´
                    continue

            # === å¤±è´¥å¤„ç†ï¼šåˆ†æé”™è¯¯æ—¥å¿—ï¼Œå¯»æ‰¾ç¼ºå¤±çš„å¤´æ–‡ä»¶ ===
            # æ³¨æ„ï¼šä»…å¯¹ bindgen è¿›ç¨‹æœ¬èº«å¤±è´¥ï¼ˆsuccess=Falseï¼‰æ‰§è¡Œè¯¥é€»è¾‘ã€‚
            if success:
                continue
            if not missing_files:
                # éå¤´æ–‡ä»¶ç¼ºå¤±é—®é¢˜
                logger.warning(f"bindgen å¤±è´¥ï¼ˆéå¤´æ–‡ä»¶ç¼ºå¤±é—®é¢˜ï¼‰: {error_msg[:300]}")
                break

            # è¿‡æ»¤æ‰å·²çŸ¥æ— æ³•è§£å†³çš„å¤´æ–‡ä»¶
            new_missing = [h for h in missing_files if h not in unresolvable_headers]

            if not new_missing:
                logger.warning("æ‰€æœ‰ç¼ºå¤±çš„å¤´æ–‡ä»¶éƒ½å·²å°è¯•æŸ¥æ‰¾ä½†å¤±è´¥")
                break

            # å°è¯•é€šè¿‡å…¨å±€æ•°æ®åº“æ‰¾åˆ°ç¼ºå¤±çš„æ–‡ä»¶
            found_new_path = False

            if self.compile_commands_parser:
                try:
                    new_includes, still_missing, resolved_map = self.compile_commands_parser.get_resolved_includes_for_bindgen(
                        new_missing,
                        current_includes,
                        preferred_subpaths=preferred_subpaths,
                    )

                    added_count = len(new_includes) - len(current_includes)
                    if added_count > 0:
                        found_new_path = True
                        print(f"  âœ¨ Found {added_count} new include paths")
                        current_includes = new_includes

                    # è®°å½•æœ¬æ¬¡â€œç¼ºå¤±å¤´æ–‡ä»¶ â†’ include è·¯å¾„â€çš„è§£æç»“æœï¼Œä¾¿äºå®šä½åˆ°åº•æ˜¯è·¯å¾„æ²¡åŠ ä¸Šè¿˜æ˜¯æ–‡ä»¶æ ¹æœ¬ä¸å­˜åœ¨
                    try:
                        report["attempts"][-1]["auto_resolve"] = {
                            "resolved": {k: v for k, v in (resolved_map or {}).items() if v},
                            "unresolved": list(still_missing),
                            "include_dirs_added": added_count,
                        }
                    except Exception:
                        pass

                    unresolvable_headers.update(still_missing)
                except Exception as e:
                    logger.warning(f"æ™ºèƒ½å¯»è·¯å¤±è´¥: {e}")
                    unresolvable_headers.update(new_missing)
            else:
                unresolvable_headers.update(new_missing)

            if not found_new_path:
                print(f"  âš ï¸ Attempt {attempt + 1}/{max_retries} failed, no new paths found")
                break

        # ========== Tier B: clang -E é¢„å¤„ç†åå† bindgen ==========
        print("\nğŸ“‹ Tier B: Clang Preprocessed Bindgen")
        tier_b_success = False
        if enable_tier_b:
            tier_b_success = self._attempt_clang_preprocessed_bindgen(
                header_files, output_path, current_includes, report, source_files=source_files
            )
        else:
            report["attempts"].append({
                "tier": "B",
                "success": False,
                "skipped": True,
                "error": "disabled (truth-mode)" if truth_mode else "disabled",
            })

        if tier_b_success:
            # éªŒè¯è¾“å‡º
            is_valid, validation_msg = self._validate_types_rs(output_path)

            # å¦‚æœéªŒè¯å¤±è´¥ï¼Œå°è¯•å‡€åŒ–
            if not is_valid:
                if enable_types_rs_sanitizer:
                    logger.info(f"Tier B è¾“å‡ºéªŒè¯å¤±è´¥: {validation_msg}ï¼Œå°è¯•å‡€åŒ–...")
                    modified, fix_count = self._sanitize_types_rs(output_path)
                    if modified:
                        logger.info(f"å‡€åŒ–å™¨ä¿®å¤äº† {fix_count} ä¸ªé—®é¢˜ï¼Œé‡æ–°éªŒè¯...")
                        is_valid, validation_msg = self._validate_types_rs(output_path)
                else:
                    logger.info("types.rs å‡€åŒ–å™¨å·²ç¦ç”¨ï¼ˆtruth-mode æˆ–æœªæ˜¾å¼å¼€å¯ï¼‰ï¼Œä¿ç•™ Tier B åŸå§‹è¾“å‡º")

            if is_valid:
                report["mode"] = "clang_preprocessed_bindgen"
                report["success"] = True
                report["final_output_valid"] = True
                self._write_types_generation_report(report)
                print("âœ… Tier B (clang -E + bindgen) successful!")
                return True
            else:
                logger.warning(f"Tier B è¾“å‡ºéªŒè¯å¤±è´¥ï¼ˆå‡€åŒ–åä»ç„¶å¤±è´¥ï¼‰: {validation_msg}")

        # ========== Tier C: Stub types.rs (ä¿è¯ç¼–è¯‘é€šè¿‡) ==========
        if not enable_tier_c_stub:
            report["mode"] = "bindgen_failed"
            report["success"] = False
            report["final_output_valid"] = False
            report["stub_disabled"] = True
            self._write_types_generation_report(report)
            print("âœ— Bindgen failed and stub fallback is disabled; leaving types.rs unresolved.")
            return False

        print("\nğŸ“‹ Tier C: Generating Stub types.rs (guaranteed compilation)")
        self._generate_stub_types_rs(output_path, header_files)

        # éªŒè¯ stub è¾“å‡º
        is_valid, validation_msg = self._validate_types_rs(output_path)

        # å³ä½¿æ˜¯ stub ä¹Ÿå¯èƒ½éœ€è¦å‡€åŒ–ï¼ˆä¾‹å¦‚å¤´æ–‡ä»¶æ‰«ææ—¶å¼•å…¥äº†é—®é¢˜ç±»å‹ï¼‰
        if not is_valid:
            if enable_types_rs_sanitizer:
                logger.info(f"Stub types.rs éªŒè¯å¤±è´¥: {validation_msg}ï¼Œå°è¯•å‡€åŒ–...")
                modified, fix_count = self._sanitize_types_rs(output_path)
                if modified:
                    logger.info(f"å‡€åŒ–å™¨ä¿®å¤äº† {fix_count} ä¸ªé—®é¢˜ï¼Œé‡æ–°éªŒè¯...")
                    is_valid, validation_msg = self._validate_types_rs(output_path)
            else:
                logger.info("types.rs å‡€åŒ–å™¨å·²ç¦ç”¨ï¼Œä¿ç•™ stub åŸå§‹è¾“å‡º")

        report["mode"] = "stub"
        report["success"] = is_valid
        report["final_output_valid"] = is_valid

        if not is_valid:
            logger.error(f"Stub types.rs éªŒè¯å¤±è´¥: {validation_msg}")
            report["stub_validation_error"] = validation_msg

        self._write_types_generation_report(report)

        if is_valid:
            print("âœ… Stub types.rs generated (guaranteed compilation)")
        else:
            print("âš ï¸ Stub types.rs generated but validation failed")

        return is_valid

    def _validate_types_rs(self, types_path: Path) -> Tuple[bool, str]:
        """
        éªŒè¯ types.rs çš„è¯­æ³•æ­£ç¡®æ€§

        Phase 1 çš„å…³é”®å‡½æ•°ï¼šæ£€æµ‹ bindgen è¾“å‡ºæ˜¯å¦æœ‰æ•ˆ

        æ£€æŸ¥é¡¹ï¼š
        1. æ–‡ä»¶å­˜åœ¨ä¸”éç©º
        2. æ²¡æœ‰æ˜æ˜¾çš„è¯­æ³•é”™è¯¯ï¼ˆunclosed delimiterï¼‰
        3. æ²¡æœ‰é€’å½’ç±»å‹åˆ«åï¼ˆE0391ï¼‰
        4. æ²¡æœ‰é‡å¤å®šä¹‰ï¼ˆE0428ï¼‰

        Args:
            types_path: types.rs æ–‡ä»¶è·¯å¾„

        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯åŸå› )
        """
        if not types_path.exists():
            return False, "file does not exist"

        try:
            with open(types_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            return False, f"cannot read file: {e}"

        if len(content.strip()) < 50:
            return False, "file is too small (possibly empty or failed generation)"

        # æ£€æŸ¥é€’å½’ç±»å‹åˆ«åï¼ˆE0391ï¼‰
        # ä¾‹å¦‚: pub type i32 = i32;
        recursive_pattern = re.compile(r'pub\s+type\s+(\w+)\s*=\s*\1\s*;')
        recursive_match = recursive_pattern.search(content)
        if recursive_match:
            return False, f"recursive type alias: {recursive_match.group(0)}"

        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜æ˜¾çš„é”™è¯¯æ¨¡å¼
        error_patterns = [
            (r'error\[E\d+\]', "contains error message"),
            (r'^\s*\d+\s*\|', "contains line number (possibly error output)"),
            (r'cannot find type', "contains 'cannot find type' error"),
        ]

        for pattern, msg in error_patterns:
            if re.search(pattern, content, re.MULTILINE):
                return False, msg

        # æœ€åç”¨ rustc åšä¸€æ¬¡è¯­æ³•/ç±»å‹æ£€æŸ¥ï¼Œé¿å…â€œæ‹¬å·è®¡æ•°â€è¿™ç±»å®¹æ˜“è¢« doc æ³¨é‡Š/å­—ç¬¦ä¸²è¯¯ä¼¤çš„å‡é˜³æ€§ã€‚
        # è¿™é‡Œä¸è¿½æ±‚å®Œå…¨é€šè¿‡ï¼ˆé‡å¤å®šä¹‰ç­‰ä¼šåœ¨åç»­å‡€åŒ–ä¿®å¤ï¼‰ï¼Œä½†è¦èƒ½è¢« rustc æ­£å¸¸è§£æã€‚
        try:
            import tempfile

            with tempfile.TemporaryDirectory(prefix="c2r_types_check_") as td:
                cmd = [
                    "rustc",
                    "--edition",
                    "2021",
                    "--crate-type",
                    "lib",
                    "--emit=metadata",
                    "--out-dir",
                    td,
                    str(types_path),
                ]
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=60,
                )

            if result.returncode != 0:
                stderr = (result.stderr or "").strip()
                if not stderr:
                    return False, "rustc validation failed (no stderr)"
                # åªä¿ç•™å°¾éƒ¨ï¼Œé¿å…æŠŠå·¨é‡é”™è¯¯åˆ·å±
                tail = "\n".join(stderr.splitlines()[-30:])
                return False, f"rustc validation failed:\n{tail}"
        except FileNotFoundError:
            # æç«¯ç¯å¢ƒä¸‹ rustc ä¸å¯ç”¨ï¼šå›é€€ä¸ºâ€œå°½åŠ›è€Œä¸ºâ€çš„æ£€æŸ¥
            pass
        except subprocess.TimeoutExpired:
            return False, "rustc validation timeout"
        except Exception as e:
            return False, f"rustc validation error: {e}"

        return True, "ok"

    def _sanitize_types_rs(self, types_path: Path) -> Tuple[bool, int]:
        """
        Phase 2: types.rs å‡€åŒ–å™¨

        ä¸»åŠ¨ä¿®å¤ types.rs ä¸­çš„å¸¸è§é—®é¢˜ï¼Œç¡®ä¿ç¼–è¯‘é€šè¿‡ã€‚

        ä¿®å¤é¡¹ï¼š
        1. E0428 - å»é‡ï¼ˆé‡å¤å®šä¹‰ï¼‰
        2. E0391 - ç§»é™¤é€’å½’ç±»å‹åˆ«åï¼ˆå¦‚ pub type i32 = i32;ï¼‰
        3. E0740 - å¤„ç† union Copy é—®é¢˜ï¼ˆç§»é™¤ union çš„ Copy/Clone deriveï¼‰
        4. å¤„ç† Rust ä¿ç•™å­—æ ‡è¯†ç¬¦ï¼ˆr#å‰ç¼€æˆ–é‡å‘½åï¼‰
        5. ç§»é™¤æ— æ•ˆçš„ extern crate å’Œ use è¯­å¥
        6. ä¿®å¤å¸¸è§çš„ bindgen ç”Ÿæˆé—®é¢˜ï¼ˆå«å­¤ç«‹ attributesï¼‰
        6.5. E0425 - è¡¥å……ç¼ºå¤±çš„ glibc å†…éƒ¨ç±»å‹å®šä¹‰ï¼ˆå¦‚ __suseconds_t, __blksize_t ç­‰ï¼‰

        Args:
            types_path: types.rs æ–‡ä»¶è·¯å¾„

        Returns:
            (æ˜¯å¦ä¿®æ”¹äº†æ–‡ä»¶, ä¿®å¤æ•°é‡)
        """
        if not types_path.exists():
            return False, 0

        try:
            with open(types_path, 'r', encoding='utf-8') as f:
                original_content = f.read()
        except Exception as e:
            logger.error(f"æ— æ³•è¯»å– types.rs: {e}")
            return False, 0

        content = original_content
        fixes_applied = 0

        # ========== 1. ç§»é™¤é€’å½’ç±»å‹åˆ«å (E0391) ==========
        # ä¾‹å¦‚: pub type i32 = i32;
        recursive_pattern = re.compile(r'^\s*pub\s+type\s+(\w+)\s*=\s*\1\s*;\s*$', re.MULTILINE)
        matches = recursive_pattern.findall(content)
        if matches:
            content = recursive_pattern.sub('', content)
            fixes_applied += len(matches)
            logger.info(f"ç§»é™¤ {len(matches)} ä¸ªé€’å½’ç±»å‹åˆ«å: {matches[:5]}")

        # ========== 2. å»é‡ (E0428) ==========
        # æŒ‰å®šä¹‰ç±»å‹åˆ†åˆ«å¤„ç†ï¼Œä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„å®šä¹‰
        lines = content.split('\n')
        seen_definitions = {}  # {(type, name): first_line_idx}
        lines_to_remove = set()

        # å®šä¹‰ç±»å‹çš„æ­£åˆ™è¡¨è¾¾å¼
        def_patterns = [
            (r'^\s*pub\s+type\s+(\w+)', 'type'),
            (r'^\s*pub\s+struct\s+(\w+)', 'struct'),
            (r'^\s*pub\s+enum\s+(\w+)', 'enum'),
            (r'^\s*pub\s+union\s+(\w+)', 'union'),
            # NOTE: Require ':' to avoid matching `pub const fn ...` (bindgen emits const fns).
            (r'^\s*pub\s+const\s+([A-Za-z_]\w*)\s*:', 'const'),
            # Handle both `pub static NAME: ...` and `pub static mut NAME: ...` without capturing `mut` as name.
            (r'^\s*pub\s+static\s+(?:mut\s+)?([A-Za-z_]\w*)\s*:', 'static'),
        ]

        def _find_item_start(def_line_idx: int) -> int:
            """
            For duplicate items, also remove preceding contiguous attributes / doc comments.

            bindgen ç”Ÿæˆçš„å±æ€§é€šå¸¸ç´§è´´åœ¨ item ä¹‹å‰ï¼Œä¾‹å¦‚ï¼š
              #[repr(C)]
              #[derive(Debug, Copy, Clone)]
              pub struct Foo
              {
                  ...
              }
            """
            start = def_line_idx
            while start > 0:
                prev = lines[start - 1]
                if re.match(r'^\s*#\s*\[', prev):
                    start -= 1
                    continue
                if re.match(r'^\s*///', prev) or re.match(r'^\s*//!', prev):
                    start -= 1
                    continue
                break
            return start

        def _find_item_end(def_line_idx: int, def_type: str) -> int:
            """
            Find the end line (inclusive) of a Rust item starting at def_line_idx.

            Handles cases where '{' is on the next line (bindgen sometimes emits):
              pub struct Foo
              {
                  ...
              }
            """
            # Single-line items (type alias / const / static) usually end with ';' on the same line.
            if def_type not in ("struct", "enum", "union"):
                return def_line_idx

            # Multi-line items: scan until we hit ';' (tuple/unit struct) OR braces are balanced.
            brace_count = 0
            saw_open = False
            end = def_line_idx
            while end < len(lines):
                line = lines[end]

                # Tuple / unit-like forms end with ';' without a block.
                if not saw_open and (";" in line) and ("{" not in line):
                    return end

                brace_count += line.count("{") - line.count("}")
                if "{" in line:
                    saw_open = True

                if saw_open and brace_count == 0:
                    return end

                end += 1

            return len(lines) - 1

        i = 0
        while i < len(lines):
            line = lines[i]
            for pattern, def_type in def_patterns:
                match = re.match(pattern, line)
                if match:
                    name = match.group(1)
                    key = (def_type, name)

                    if key in seen_definitions:
                        # æ‰¾åˆ°é‡å¤å®šä¹‰ï¼Œéœ€è¦ç§»é™¤
                        # å¯¹äºå¤šè¡Œå®šä¹‰ï¼ˆstruct, enum, unionï¼‰ï¼Œéœ€è¦æ‰¾åˆ°å®Œæ•´çš„å®šä¹‰å—
                        if def_type in ('struct', 'enum', 'union'):
                            start_idx = _find_item_start(i)
                            end_idx = _find_item_end(i, def_type)
                            for j in range(start_idx, end_idx + 1):
                                lines_to_remove.add(j)
                            i = end_idx  # è·³è¿‡æ•´ä¸ªå—ï¼Œé¿å…é‡å¤æ‰«æ
                        else:
                            start_idx = _find_item_start(i)
                            end_idx = _find_item_end(i, def_type)
                            for j in range(start_idx, end_idx + 1):
                                lines_to_remove.add(j)

                        fixes_applied += 1
                        logger.debug(f"ç§»é™¤é‡å¤å®šä¹‰: {def_type} {name}")
                    else:
                        seen_definitions[key] = i
                    break
            i += 1

        if lines_to_remove:
            new_lines = [line for idx, line in enumerate(lines) if idx not in lines_to_remove]
            content = '\n'.join(new_lines)
            logger.info(f"ç§»é™¤ {len(lines_to_remove)} è¡Œé‡å¤å®šä¹‰")

        # ========== 3. å¤„ç† union Copy é—®é¢˜ (E0740) ==========
        # ç§»é™¤ union å®šä¹‰ä¸Šçš„ Copy å’Œ Clone derive
        # åŒ¹é…: #[derive(...Copy...)] åé¢ç´§è·Ÿ pub union
        union_copy_pattern = re.compile(
            r'(#\[derive\([^)]*)\bCopy\b([^)]*)\]\s*\n(\s*pub\s+union\s+)',
            re.MULTILINE
        )

        def remove_copy_from_union(match):
            prefix = match.group(1)
            suffix = match.group(2)
            union_decl = match.group(3)

            # ç§»é™¤ Copy å’Œå¯èƒ½çš„é€—å·
            derives = prefix + suffix
            # æ¸…ç†é€—å·
            derives = re.sub(r',\s*,', ',', derives)
            derives = re.sub(r'\(\s*,', '(', derives)
            derives = re.sub(r',\s*\)', ')', derives)

            # å¦‚æœ derive ä¸ºç©ºï¼Œç§»é™¤æ•´ä¸ª derive å±æ€§
            if re.match(r'#\[derive\(\s*\)\]', derives + ')]'):
                return union_decl

            return derives + ')]\n' + union_decl

        new_content = union_copy_pattern.sub(remove_copy_from_union, content)
        if new_content != content:
            fixes_applied += content.count('pub union') - new_content.count('#[derive')  # ä¼°ç®—
            content = new_content
            logger.info("ç§»é™¤ union å®šä¹‰ä¸Šçš„ Copy derive")

        # åŒæ ·å¤„ç† Cloneï¼ˆé€šå¸¸ Copy éœ€è¦ Cloneï¼Œä½† Clone å•ç‹¬å­˜åœ¨äº union ä¹Ÿå¯èƒ½æœ‰é—®é¢˜ï¼‰
        union_clone_pattern = re.compile(
            r'(#\[derive\([^)]*)\bClone\b([^)]*)\]\s*\n(\s*pub\s+union\s+)',
            re.MULTILINE
        )
        new_content = union_clone_pattern.sub(remove_copy_from_union, content)
        if new_content != content:
            content = new_content
            fixes_applied += 1

        # ========== 4. å¤„ç† Rust ä¿ç•™å­—æ ‡è¯†ç¬¦ ==========
        rust_keywords = {
            'as', 'break', 'const', 'continue', 'crate', 'else', 'enum',
            'extern', 'false', 'fn', 'for', 'if', 'impl', 'in', 'let',
            'loop', 'match', 'mod', 'move', 'mut', 'pub', 'ref', 'return',
            'self', 'Self', 'static', 'struct', 'super', 'trait', 'true',
            'type', 'unsafe', 'use', 'where', 'while', 'async', 'await',
            'dyn', 'abstract', 'become', 'box', 'do', 'final', 'macro',
            'override', 'priv', 'typeof', 'unsized', 'virtual', 'yield', 'try'
        }

        # æŸ¥æ‰¾ç”¨ä½œå­—æ®µåæˆ–å‚æ•°åçš„ä¿ç•™å­—
        # æ¨¡å¼: å­—æ®µå£°æ˜ pub name: Type
        field_pattern = re.compile(r'(\s+pub\s+)(' + '|'.join(rust_keywords) + r')(\s*:\s*)')

        def escape_keyword_field(match):
            prefix = match.group(1)
            keyword = match.group(2)
            suffix = match.group(3)
            return f'{prefix}r#{keyword}{suffix}'

        new_content = field_pattern.sub(escape_keyword_field, content)
        if new_content != content:
            diff_count = len(field_pattern.findall(content))
            fixes_applied += diff_count
            content = new_content
            logger.info(f"è½¬ä¹‰ {diff_count} ä¸ªä¿ç•™å­—å­—æ®µå")

        # ========== 5. ç§»é™¤æ— æ•ˆçš„ extern crate è¯­å¥ ==========
        # ç§»é™¤ extern crate std; è¿™ç±»åœ¨ 2018 edition ä¸­ä¸éœ€è¦çš„è¯­å¥
        extern_crate_pattern = re.compile(r'^\s*extern\s+crate\s+std\s*;\s*$', re.MULTILINE)
        new_content = extern_crate_pattern.sub('', content)
        if new_content != content:
            fixes_applied += 1
            content = new_content

        # ========== 6. ä¿®å¤å¸¸è§çš„ bindgen ç”Ÿæˆé—®é¢˜ ==========
        # 6.1 ç§»é™¤ç©ºçš„ impl å—
        empty_impl_pattern = re.compile(r'impl\s+\w+\s*\{\s*\}', re.MULTILINE)
        new_content = empty_impl_pattern.sub('', content)
        if new_content != content:
            fixes_applied += len(empty_impl_pattern.findall(content))
            content = new_content

        # 6.2 ä¿®å¤ bindgen ç”Ÿæˆçš„æ— æ•ˆ repr å±æ€§
        # ä¾‹å¦‚: #[repr(C, packed(0))] -> #[repr(C, packed)]
        packed_zero_pattern = re.compile(r'packed\s*\(\s*0\s*\)')
        new_content = packed_zero_pattern.sub('packed', content)
        if new_content != content:
            fixes_applied += len(packed_zero_pattern.findall(content))
            content = new_content

        # 6.3 ç§»é™¤æ— æ•ˆçš„ #[link] å±æ€§ï¼ˆé’ˆå¯¹ä¸å­˜åœ¨çš„åº“ï¼‰
        # è¿™ä¸ªæ¯”è¾ƒå±é™©ï¼Œåªç§»é™¤æ˜æ˜¾æœ‰é—®é¢˜çš„
        invalid_link_pattern = re.compile(r'#\[link\s*\(\s*name\s*=\s*""\s*\)\]', re.MULTILINE)
        new_content = invalid_link_pattern.sub('', content)
        if new_content != content:
            fixes_applied += len(invalid_link_pattern.findall(content))
            content = new_content

        # 6.4 ç§»é™¤â€œå­¤ç«‹ attributesâ€ï¼ˆå¸¸è§æŠ¥é”™ï¼šexpected item after attributesï¼‰
        # å½“ types.rs æœ«å°¾æˆ–æŸå¤„å‡ºç° #[...] ä½†åé¢æ²¡æœ‰ä»»ä½• itemï¼Œä¼šå¯¼è‡´è¯­æ³•é”™è¯¯ã€‚
        # å…¸å‹åœºæ™¯ï¼šbindgen/åå¤„ç†è¿‡ç¨‹ä¸­æˆªæ–­æˆ–ç§»é™¤äº† itemï¼Œä½†é—ç•™äº†å±æ€§è¡Œã€‚
        lines = content.split('\n')
        new_lines: List[str] = []
        i = 0
        removed_attrs = 0

        item_start_pattern = re.compile(
            r'^\s*(?:pub\s+)?(?:'
            r'struct|enum|union|type|const|static|fn|extern|mod|use|trait|impl|macro_rules!'
            r')\b'
        )

        while i < len(lines):
            line = lines[i]
            if line.lstrip().startswith('#['):
                # æ”¶é›†è¿ç»­çš„å±æ€§è¡Œ
                attr_block = []
                while i < len(lines) and lines[i].lstrip().startswith('#['):
                    attr_block.append(lines[i])
                    i += 1

                # æ‰¾åˆ°ä¸‹ä¸€ä¸ªéç©ºè¡Œ
                j = i
                while j < len(lines) and lines[j].strip() == '':
                    j += 1

                # æ–‡ä»¶ç»“æŸï¼šä¸¢å¼ƒå±æ€§å—
                if j >= len(lines):
                    removed_attrs += len(attr_block)
                    fixes_applied += len(attr_block)
                    continue

                next_line = lines[j].lstrip()

                # ä¸‹ä¸€è¡Œæ˜¯ item / doc comment / å¦ä¸€ä¸ªå±æ€§ï¼šä¿ç•™
                if next_line.startswith('#[') or next_line.startswith('///') or next_line.startswith('//!') or item_start_pattern.match(lines[j]):
                    new_lines.extend(attr_block)
                else:
                    # å­¤ç«‹å±æ€§ï¼šä¸¢å¼ƒ
                    removed_attrs += len(attr_block)
                    fixes_applied += len(attr_block)
                continue

            new_lines.append(line)
            i += 1

        if removed_attrs:
            content = '\n'.join(new_lines)
            logger.info(f"ç§»é™¤ {removed_attrs} è¡Œå­¤ç«‹ attributes")

        # ========== 6.5 ä¿®å¤ E0425: è¡¥å……ç¼ºå¤±çš„ glibc å†…éƒ¨ç±»å‹ ==========
        # bindgen ç»å¸¸ç”Ÿæˆå¼•ç”¨ glibc å†…éƒ¨ç±»å‹çš„åˆ«åï¼Œå¦‚:
        #   pub type suseconds_t = __suseconds_t;
        # ä½† __suseconds_t æ²¡æœ‰å®šä¹‰ï¼Œå¯¼è‡´ E0425 é”™è¯¯ã€‚
        # è¿™é‡Œè‡ªåŠ¨è¡¥å……è¿™äº›å·²çŸ¥çš„ glibc å†…éƒ¨ç±»å‹å®šä¹‰ã€‚

        # å·²çŸ¥çš„ glibc å†…éƒ¨ç±»å‹æ˜ å°„ (Linux x86_64)
        glibc_internal_types = {
            # æ—¶é—´ç›¸å…³ç±»å‹
            "__suseconds_t": "i64",
            "__time_t": "i64",
            "__clock_t": "i64",
            "__clockid_t": "i32",
            "__timer_t": "*mut ::core::ffi::c_void",

            # æ–‡ä»¶ç³»ç»Ÿç›¸å…³ç±»å‹
            "__blksize_t": "i64",
            "__blkcnt_t": "i64",
            "__blkcnt64_t": "i64",
            "__fsblkcnt_t": "u64",
            "__fsblkcnt64_t": "u64",
            "__fsfilcnt_t": "u64",
            "__fsfilcnt64_t": "u64",
            "__fsword_t": "i64",
            "__off_t": "i64",
            "__off64_t": "i64",
            "__loff_t": "i64",
            "__ino_t": "u64",
            "__ino64_t": "u64",
            "__nlink_t": "u64",
            "__dev_t": "u64",
            "__mode_t": "u32",

            # è¿›ç¨‹/ç”¨æˆ·ç›¸å…³ç±»å‹
            "__pid_t": "i32",
            "__uid_t": "u32",
            "__gid_t": "u32",
            "__id_t": "u32",
            "__key_t": "i32",

            # æ•´æ•°ç±»å‹
            "__int8_t": "i8",
            "__int16_t": "i16",
            "__int32_t": "i32",
            "__int64_t": "i64",
            "__uint8_t": "u8",
            "__uint16_t": "u16",
            "__uint32_t": "u32",
            "__uint64_t": "u64",
            "__int_least8_t": "i8",
            "__int_least16_t": "i16",
            "__int_least32_t": "i32",
            "__int_least64_t": "i64",
            "__uint_least8_t": "u8",
            "__uint_least16_t": "u16",
            "__uint_least32_t": "u32",
            "__uint_least64_t": "u64",
            "__int_fast8_t": "i8",
            "__int_fast16_t": "i64",
            "__int_fast32_t": "i64",
            "__int_fast64_t": "i64",
            "__uint_fast8_t": "u8",
            "__uint_fast16_t": "u64",
            "__uint_fast32_t": "u64",
            "__uint_fast64_t": "u64",
            "__intmax_t": "i64",
            "__uintmax_t": "u64",

            # æŒ‡é’ˆç›¸å…³ç±»å‹
            "__intptr_t": "isize",
            "__uintptr_t": "usize",
            "__ssize_t": "isize",
            "__syscall_slong_t": "i64",
            "__syscall_ulong_t": "u64",

            # socket ç›¸å…³ç±»å‹
            "__socklen_t": "u32",
            "__sig_atomic_t": "i32",

            # å…¶ä»–å¸¸è§ç±»å‹
            "__caddr_t": "*mut i8",
            "__daddr_t": "i32",
            "__swblk_t": "i64",
            "__quad_t": "i64",
            "__u_quad_t": "u64",
            "__qaddr_t": "*mut i64",
            "__rlim_t": "u64",
            "__rlim64_t": "u64",
            "__useconds_t": "u32",
            "__wchar_t": "i32",
            "__wint_t": "u32",
        }

        # 6.5.1 å¤æ‚çš„ glibc å†…éƒ¨ç»“æ„ä½“ç±»å‹ï¼ˆéœ€è¦ç”Ÿæˆ opaque structï¼‰
        # è¿™äº›ç±»å‹æ˜¯ç»“æ„ä½“è€Œä¸æ˜¯ç®€å•çš„ typedefï¼Œéœ€è¦ç”Ÿæˆ opaque å®šä¹‰
        glibc_internal_structs = {
            # FILE å’Œç›¸å…³ç±»å‹
            "__fpos_t": "#[repr(C)]\n#[derive(Copy, Clone)]\npub struct __fpos_t { _opaque: [u8; 16] }",
            "__fpos64_t": "#[repr(C)]\n#[derive(Copy, Clone)]\npub struct __fpos64_t { _opaque: [u8; 16] }",
            "__mbstate_t": "#[repr(C)]\n#[derive(Copy, Clone)]\npub struct __mbstate_t { _opaque: [u8; 8] }",

            # locale ç›¸å…³
            "__locale_struct": "#[repr(C)]\npub struct __locale_struct { _opaque: [u8; 232] }",

            # va_list ç›¸å…³
            "__va_list_tag": "#[repr(C)]\n#[derive(Copy, Clone)]\npub struct __va_list_tag { pub gp_offset: u32, pub fp_offset: u32, pub overflow_arg_area: *mut ::core::ffi::c_void, pub reg_save_area: *mut ::core::ffi::c_void }",

            # pthread ç›¸å…³
            "__pthread_mutex_s": "#[repr(C)]\npub struct __pthread_mutex_s { _opaque: [u8; 40] }",
            "__pthread_cond_s": "#[repr(C)]\npub struct __pthread_cond_s { _opaque: [u8; 48] }",
            "__pthread_rwlock_arch_t": "#[repr(C)]\npub struct __pthread_rwlock_arch_t { _opaque: [u8; 56] }",
            "__pthread_internal_list": "#[repr(C)]\npub struct __pthread_internal_list { pub __prev: *mut __pthread_internal_list, pub __next: *mut __pthread_internal_list }",
            "__pthread_internal_slist": "#[repr(C)]\npub struct __pthread_internal_slist { pub __next: *mut __pthread_internal_slist }",
            "__pthread_list_t": "pub type __pthread_list_t = __pthread_internal_list;",
            "__pthread_slist_t": "pub type __pthread_slist_t = __pthread_internal_slist;",

            # ç›®å½•ç›¸å…³
            "__dirstream": "#[repr(C)]\npub struct __dirstream { _opaque: [u8; 0] }",

            # sigset ç›¸å…³
            "__sigset_t": "#[repr(C)]\n#[derive(Copy, Clone)]\npub struct __sigset_t { pub __val: [u64; 16] }",

            # æ–‡ä»¶ç³»ç»Ÿç›¸å…³
            "__fsid_t": "#[repr(C)]\n#[derive(Copy, Clone)]\npub struct __fsid_t { pub __val: [i32; 2] }",

            # å…¶ä»–
            "__once_flag": "#[repr(C)]\npub struct __once_flag { __data: i32 }",
        }

        # 1. æ‰¾å‡ºæ‰€æœ‰å·²å®šä¹‰çš„ç±»å‹
        defined_types = set()
        type_def_pattern = re.compile(r'^\s*pub\s+(?:type|struct|enum|union)\s+(\w+)', re.MULTILINE)
        for match in type_def_pattern.finditer(content):
            defined_types.add(match.group(1))

        # 1.1 ä¹Ÿæ£€æŸ¥ pub use å¯¼å…¥çš„ç±»å‹ï¼ˆé¿å… E0255 é‡å¤å®šä¹‰ï¼‰
        # åŒ¹é…: pub use module::{Type1, Type2, Type3};
        # æˆ–: pub use module::*;
        pub_use_pattern = re.compile(r'pub\s+use\s+\w+::\{([^}]+)\}')
        for match in pub_use_pattern.finditer(content):
            imported_types = match.group(1)
            # è§£æé€—å·åˆ†éš”çš„ç±»å‹å
            for type_name in imported_types.split(','):
                type_name = type_name.strip()
                # å¤„ç† as åˆ«å: Type as Alias
                if ' as ' in type_name:
                    type_name = type_name.split(' as ')[0].strip()
                if type_name:
                    defined_types.add(type_name)

        # 1.2 æ£€æŸ¥ pub use module::* çš„æƒ…å†µ - éœ€è¦æ£€æŸ¥è¢«åŒ…å«çš„æ¨¡å—
        # å¦‚æœæœ‰ include! å®ï¼Œå°è¯•è¯»å–å¹¶è§£æå…¶ä¸­å®šä¹‰çš„ç±»å‹
        include_pattern = re.compile(r'include!\s*\(\s*"([^"]+)"\s*\)')
        for match in include_pattern.finditer(content):
            include_path = match.group(1)
            # ç›¸å¯¹äº types.rs æ‰€åœ¨ç›®å½•è§£æè·¯å¾„
            types_dir = types_path.parent
            full_include_path = types_dir / include_path
            if full_include_path.exists():
                try:
                    with open(full_include_path, 'r', encoding='utf-8') as f:
                        include_content = f.read()
                    # ä»åŒ…å«çš„æ–‡ä»¶ä¸­æå–ç±»å‹å®šä¹‰
                    for def_match in type_def_pattern.finditer(include_content):
                        defined_types.add(def_match.group(1))
                except Exception:
                    pass  # å¿½ç•¥è¯»å–é”™è¯¯

        # 2. æ‰¾å‡ºæ‰€æœ‰è¢«å¼•ç”¨ä½†å¯èƒ½æœªå®šä¹‰çš„ç±»å‹
        # 2.1 ç®€å•ç±»å‹åˆ«å (å¦‚ __suseconds_t)
        referenced_types = set()
        ref_pattern = re.compile(r'[=:,\s\(](__[a-z_]+_t)\b')
        for match in ref_pattern.finditer(content):
            type_name = match.group(1)
            if type_name not in defined_types and type_name in glibc_internal_types:
                referenced_types.add(type_name)

        # 2.2 å¤æ‚ç»“æ„ä½“ç±»å‹ (å¦‚ __fpos_t, __locale_struct, __va_list_tag)
        # ä½¿ç”¨æ›´å®½æ¾çš„æ¨¡å¼åŒ¹é…ï¼ŒåŒ…æ‹¬ __xxx_t å’Œ __xxx_struct ä»¥åŠ __xxx_tag
        # æ·»åŠ  \[ ä»¥åŒ¹é…æ•°ç»„ä¸­çš„ç±»å‹ï¼Œå¦‚ [__va_list_tag; 1usize]
        referenced_structs = set()
        struct_ref_pattern = re.compile(r'[=:,\s\(\*\[](__[a-z_]+(?:_t|_struct|_tag|_s|_list))\b')
        for match in struct_ref_pattern.finditer(content):
            type_name = match.group(1)
            if type_name not in defined_types and type_name in glibc_internal_structs:
                referenced_structs.add(type_name)

        # 3. ç”Ÿæˆç¼ºå¤±ç±»å‹çš„å®šä¹‰
        if referenced_types or referenced_structs:
            missing_defs = []
            missing_defs.append("")
            missing_defs.append("// ============================================================")
            missing_defs.append("// Auto-generated glibc internal type definitions (E0425 fix)")
            missing_defs.append("// ============================================================")

            # 3.1 å…ˆæ·»åŠ ç»“æ„ä½“å®šä¹‰ï¼ˆå®ƒä»¬å¯èƒ½è¢«ç±»å‹åˆ«åå¼•ç”¨ï¼‰
            for type_name in sorted(referenced_structs):
                struct_def = glibc_internal_structs[type_name]
                missing_defs.append(struct_def)

            # 3.2 å†æ·»åŠ ç±»å‹åˆ«åå®šä¹‰
            for type_name in sorted(referenced_types):
                rust_type = glibc_internal_types[type_name]
                missing_defs.append(f"pub type {type_name} = {rust_type};")

            missing_defs.append("")

            # 4. å°†å®šä¹‰æ’å…¥åˆ°æ–‡ä»¶å¼€å¤´ï¼ˆåœ¨ #![allow(...)] ä¹‹åï¼‰
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªéå±æ€§ã€éæ³¨é‡Šçš„ä½ç½®
            lines = content.split('\n')
            insert_idx = 0
            for idx, line in enumerate(lines):
                stripped = line.strip()
                if stripped.startswith('#![') or stripped.startswith('//!') or stripped == '':
                    insert_idx = idx + 1
                elif stripped.startswith('//'):
                    insert_idx = idx + 1
                else:
                    break

            # æ’å…¥ç¼ºå¤±çš„ç±»å‹å®šä¹‰
            new_lines = lines[:insert_idx] + missing_defs + lines[insert_idx:]
            content = '\n'.join(new_lines)
            total_added = len(referenced_types) + len(referenced_structs)
            fixes_applied += total_added
            all_types = sorted(list(referenced_types) + list(referenced_structs))
            logger.info(f"è¡¥å…… {total_added} ä¸ªç¼ºå¤±çš„ glibc å†…éƒ¨ç±»å‹: {all_types[:5]}...")

        # ========== 7. æ¸…ç†å¤šä½™ç©ºè¡Œ ==========
        # è¿ç»­è¶…è¿‡2ä¸ªç©ºè¡Œå‹ç¼©ä¸º2ä¸ª
        content = re.sub(r'\n{4,}', '\n\n\n', content)

        # ========== 8. ç¡®ä¿æ–‡ä»¶æœ«å°¾æœ‰æ¢è¡Œ ==========
        if not content.endswith('\n'):
            content += '\n'

        # æ£€æŸ¥æ˜¯å¦æœ‰ä¿®æ”¹
        if content != original_content:
            try:
                with open(types_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                logger.info(f"types.rs å‡€åŒ–å®Œæˆï¼Œå…±ä¿®å¤ {fixes_applied} ä¸ªé—®é¢˜")
                return True, fixes_applied
            except Exception as e:
                logger.error(f"å†™å…¥å‡€åŒ–åçš„ types.rs å¤±è´¥: {e}")
                return False, 0

        return False, fixes_applied

    def _attempt_clang_preprocessed_bindgen(
        self,
        header_files: List[Path],
        output_path: Path,
        include_dirs: Set[Path],
        report: dict,
        source_files: List[Path] = None,
    ) -> bool:
        """
        Tier B: ä½¿ç”¨ clang -E é¢„å¤„ç†åå†è¿è¡Œ bindgen

        ç­–ç•¥ï¼š
        1. åˆå¹¶æ‰€æœ‰å¤´æ–‡ä»¶å†…å®¹
        2. ä½¿ç”¨ clang -E é¢„å¤„ç†ï¼ˆå±•å¼€å®ã€å¤„ç†æ¡ä»¶ç¼–è¯‘ï¼‰
        3. å¯¹é¢„å¤„ç†åçš„è¾“å‡ºè¿è¡Œ bindgen

        Args:
            header_files: å¤´æ–‡ä»¶åˆ—è¡¨
            output_path: è¾“å‡ºè·¯å¾„
            include_dirs: include è·¯å¾„é›†åˆ
            report: æŠ¥å‘Šæ•°æ®

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            keep_files = self._env_flag("C2R_BINDGEN_DEBUG_KEEP_FILES")

            # include ç›®å½•è¯Šæ–­ï¼ˆå¸®åŠ©å®šä½ out/.../gen ç¼ºå¤±ã€ç›®å½•ä¸å­˜åœ¨ç­‰ï¼‰
            include_dirs_list = sorted(str(p) for p in (include_dirs or set()))
            nonexistent_dirs = [p for p in include_dirs_list if p and not Path(p).exists()]
            out_gen_dirs = [p for p in include_dirs_list if "/out/" in p.replace("\\", "/") and "/gen" in p.replace("\\", "/")]
            include_diag = {
                "include_dirs_count": len(include_dirs_list),
                "nonexistent_dir_count": len(nonexistent_dirs),
                "nonexistent_dir_sample": nonexistent_dirs[:20],
                "out_gen_dir_count": len(out_gen_dirs),
                "out_gen_dir_existing_count": sum(1 for p in out_gen_dirs if Path(p).exists()),
            }

            wrapper_path = self.output_dir / "wrapper_for_clang.h"
            wrapper_extra_system_includes: List[str] = []
            wrapper_type_shims: List[str] = []
            wrapper_enum_shims: List[str] = []
            wrapper_rename_dprintf: bool = False
            wrapper_shimmed_type_names: Set[str] = set()
            wrapper_shimmed_enum_names: Set[str] = set()
            wrapper_fixup_actions: List[Dict[str, Any]] = []

            def _write_wrapper_for_clang():
                # åˆ›å»ºä¸´æ—¶çš„åˆå¹¶å¤´æ–‡ä»¶ï¼ˆä¿æŒç®€å•ï¼šä¸è¦ç”¨ extern \"C\" åŒ…è£¹ï¼Œé¿å… C++ å¤´è¢«å¼ºè¡Œ C linkageï¼‰
                wrapper_content: List[str] = []
                wrapper_content.append("// Auto-generated wrapper for clang -E preprocessing")
                wrapper_content.append("")
                # musl's bits/alltypes.h uses __NEED_* gating. Keep only safe defaults here:
                # - For sched_param, prefer including <sched.h> (avoid defining __NEED_struct_sched_param manually).
                wrapper_content.append("#ifndef __NEED_struct_cpu_set_t")
                wrapper_content.append("#define __NEED_struct_cpu_set_t 1")
                wrapper_content.append("#endif")
                wrapper_content.append("")
                wrapper_content.append("#include <sched.h>")
                wrapper_content.append("")
                # Linux/UAPI-style annotation macros: make them parseable outside full kernel build context.
                wrapper_content.append("#ifndef __must_check")
                wrapper_content.append("#define __must_check __attribute__((warn_unused_result))")
                wrapper_content.append("#endif")
                wrapper_content.append("#ifndef __packed")
                wrapper_content.append("#define __packed __attribute__((packed))")
                wrapper_content.append("#endif")
                wrapper_content.append("#ifndef __aligned")
                wrapper_content.append("#define __aligned(x) __attribute__((aligned(x)))")
                wrapper_content.append("#endif")
                wrapper_content.append("#ifndef __user")
                wrapper_content.append("#define __user")
                wrapper_content.append("#endif")
                wrapper_content.append("#ifndef __force")
                wrapper_content.append("#define __force")
                wrapper_content.append("#endif")
                wrapper_content.append("#ifndef __iomem")
                wrapper_content.append("#define __iomem")
                wrapper_content.append("#endif")
                wrapper_content.append("")
                # Common storage specifier macros in some vendor codebases.
                wrapper_content.append("#ifndef STATIC")
                wrapper_content.append("#define STATIC static")
                wrapper_content.append("#endif")
                wrapper_content.append("#ifndef INLINE")
                wrapper_content.append("#define INLINE inline")
                wrapper_content.append("#endif")
                wrapper_content.append("")

                # Provide common fundamental typedefs early.
                # Some OpenHarmony headers assume these are already available (via transitive includes in real TUs).
                wrapper_content.append("#include <stddef.h>")
                wrapper_content.append("#include <stdint.h>")
                wrapper_content.append("#include <stdbool.h>")
                wrapper_content.append("")

                # If we need to disambiguate libc-vs-LiteOS symbol prototypes (e.g., dprintf),
                # include the libc header first so its prototype wins, then rename the LiteOS one.
                if wrapper_rename_dprintf:
                    wrapper_content.append("#include <stdio.h>")
                    wrapper_content.append("")
                    wrapper_content.append("// Avoid signature conflict between musl's dprintf and LiteOS los_printf.h dprintf")
                    wrapper_content.append("#ifdef dprintf")
                    wrapper_content.append("#undef dprintf")
                    wrapper_content.append("#endif")
                    wrapper_content.append("#define dprintf c2r_liteos_dprintf")
                    wrapper_content.append("")

                if wrapper_type_shims or wrapper_enum_shims:
                    wrapper_content.append("// Type/enum shims (auto-fix for unknown/incomplete types)")
                    wrapper_content.extend(wrapper_type_shims)
                    wrapper_content.extend(wrapper_enum_shims)
                    wrapper_content.append("")

                if wrapper_extra_system_includes:
                    wrapper_content.append("// Extra system includes (auto-fix for unknown types)")
                    for inc in wrapper_extra_system_includes:
                        wrapper_content.append(f"#include {inc}")
                    wrapper_content.append("")

                for h in header_files:
                    if h.exists():
                        wrapper_content.append(f'#include "{h}"')

                wrapper_content.append("")

                if wrapper_rename_dprintf:
                    wrapper_content.append("#ifdef dprintf")
                    wrapper_content.append("#undef dprintf")
                    wrapper_content.append("#endif")
                    wrapper_content.append("")

                with open(wrapper_path, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(wrapper_content))

            _write_wrapper_for_clang()

            # é€‰æ‹© clangï¼ˆä¼˜å…ˆ OpenHarmony é¢„ç½® clangï¼Œé¿å…å®¿ä¸»æœº toolchain ä¸ --target ä¸åŒ¹é…ï¼‰
            clang_bin = shutil.which("clang") or "clang"
            if self.ohos_root:
                ohos_clang = self.ohos_root / "prebuilts" / "clang" / "ohos" / "linux-x86_64" / "llvm" / "bin" / "clang"
                if ohos_clang.exists():
                    clang_bin = str(ohos_clang)

            # Build ordered clang context flags (prefer a representative TU's compile_commands entry).
            context_flags: List[str] = []
            added_dirs: Set[str] = set()
            cc_context_used = False

            rep_src: Optional[Path] = None
            if source_files:
                for src in source_files:
                    p = Path(src)
                    if p.exists():
                        rep_src = p
                        break

            prefer_cxx = False
            if rep_src and rep_src.suffix.lower() in {".cc", ".cpp", ".cxx", ".c++"}:
                prefer_cxx = True

            tu_ctx: Dict[str, Any] = {}
            if self.compile_commands_parser and rep_src:
                mapped_src = self._map_to_ohos_path(rep_src)
                tu_ctx.update({
                    "rep_src": str(rep_src),
                    "mapped_src": str(mapped_src),
                    "used_proxy": False,
                })
                try:
                    # Prefer stage1-selected TU context (pins flags/macros/include order).
                    entry: Optional[Dict[str, Any]] = None
                    match_info: Dict[str, Any] = {}
                    try:
                        safe_name = self._get_safe_module_name(rep_src)
                        rec = self._tu_context_files.get(safe_name) if getattr(self, "_tu_context_files", None) else None
                        if isinstance(rec, dict) and isinstance(rec.get("compile_commands_entry"), dict):
                            entry = rec.get("compile_commands_entry")
                            match_info = {
                                "reason": "tu_context_map",
                                "tu_context_map": str(getattr(self, "_tu_context_map_path", "")) if getattr(self, "_tu_context_map_path", None) else None,
                                "entry_hash": rec.get("entry_hash"),
                            }
                            tu_ctx["tu_context_map_used"] = True
                            tu_ctx["tu_context_safe_name"] = safe_name
                    except Exception:
                        entry = None
                        match_info = {}

                    if not entry:
                        entry, match_info = self.compile_commands_parser.get_entry_for_file_with_reason(mapped_src)
                    tu_ctx["match_info"] = match_info
                    tu_ctx["entry_found"] = bool(entry)
                    clang_flags: List[str] = []
                    if entry:
                        clang_flags = self.compile_commands_parser.get_clang_flags_for_entry(entry, normalize_paths=True)

                    # Proxy fallback if the module isn't compiled under this profile (common in SelfContained subsets).
                    # Default OFF: when the compile_commands closure is incomplete, treat it as an input issue and report it.
                    enable_proxy = os.environ.get("C2R_ENABLE_PROXY_TU_FALLBACK", "0").strip().lower() in ("1", "true", "yes")
                    if enable_proxy and (not clang_flags) and self._ohos_project_rel and len(self._ohos_project_rel.parts) >= 2:
                        max_parts = min(5, len(self._ohos_project_rel.parts))
                        proxy_file: Optional[Path] = None
                        proxy_key: Optional[str] = None
                        for n in range(max_parts, 1, -1):
                            candidate_key = str(Path(*self._ohos_project_rel.parts[:n]))
                            candidate_file = self.compile_commands_parser.find_first_source_file_containing(candidate_key)
                            if candidate_file:
                                proxy_key = candidate_key
                                proxy_file = candidate_file
                                break
                        if proxy_file and proxy_key:
                            tu_ctx["proxy_key"] = proxy_key
                            tu_ctx["proxy_file"] = str(proxy_file)
                            p_entry, p_match_info = self.compile_commands_parser.get_entry_for_file_with_reason(proxy_file)
                            tu_ctx["proxy_match_info"] = p_match_info
                            tu_ctx["proxy_entry_found"] = bool(p_entry)
                            if p_entry:
                                clang_flags = self.compile_commands_parser.get_clang_flags_for_entry(p_entry, normalize_paths=True)
                                tu_ctx["used_proxy"] = True

                    if clang_flags:
                        context_flags.extend(clang_flags)
                        # Track include dirs already present (avoid duplicates).
                        j = 0
                        while j < len(clang_flags):
                            flag = clang_flags[j]
                            if flag == "-I" and j + 1 < len(clang_flags):
                                added_dirs.add(clang_flags[j + 1])
                                j += 2
                                continue
                            if flag == "-isystem" and j + 1 < len(clang_flags):
                                added_dirs.add(clang_flags[j + 1])
                                j += 2
                                continue
                            if flag.startswith("-I") and flag != "-I":
                                added_dirs.add(flag[2:])
                            j += 1
                except Exception as e:
                    tu_ctx["error"] = str(e)[:300]

            # Add discovered include dirs as a supplement (do not disturb ordering of TU flags).
            for inc_dir in sorted(include_dirs or set(), key=lambda p: str(p)):
                inc_dir_str = str(inc_dir)
                if inc_dir_str not in added_dirs:
                    context_flags.extend(["-I", inc_dir_str])
                    added_dirs.add(inc_dir_str)

            # Add header dirs as a last-resort fallback.
            for h in sorted(header_files, key=lambda p: str(p)):
                h_dir_str = str(Path(h).parent)
                if h_dir_str not in added_dirs:
                    context_flags.extend(["-I", h_dir_str])
                    added_dirs.add(h_dir_str)

            def _make_include_diag(dirs: Set[Path]) -> Dict[str, Any]:
                include_dirs_list = sorted(str(p) for p in (dirs or set()))
                nonexistent_dirs = [p for p in include_dirs_list if p and not Path(p).exists()]
                out_gen_dirs = [p for p in include_dirs_list if "/out/" in p.replace("\\", "/") and "/gen" in p.replace("\\", "/")]
                return {
                    "include_dirs_count": len(include_dirs_list),
                    "nonexistent_dir_count": len(nonexistent_dirs),
                    "nonexistent_dir_sample": nonexistent_dirs[:20],
                    "out_gen_dir_count": len(out_gen_dirs),
                    "out_gen_dir_existing_count": sum(1 for p in out_gen_dirs if Path(p).exists()),
                }

            def _extract_missing_headers(stderr_text: str) -> List[str]:
                if not stderr_text:
                    return []
                missing = re.findall(r"'([^']+)' file not found", stderr_text)
                missing += re.findall(r"fatal error:\s*([^\s:]+)\s*file not found", stderr_text)
                if not missing:
                    return []
                seen = set()
                out: List[str] = []
                for f in missing:
                    f = (f or "").strip().strip('"').strip("'").strip("<>").strip()
                    if f and f not in seen:
                        seen.add(f)
                        out.append(f)
                return out

            # Hint subpaths (relative to OHOS root) for smarter missing-header resolution.
            preferred_subpaths: Optional[List[str]] = None
            try:
                if self._ohos_project_rel:
                    parts = list(self._ohos_project_rel.parts)
                    max_parts = min(len(parts), 6)
                    preferred_subpaths = [str(Path(*parts[:n])) for n in range(max_parts, 1, -1)]
            except Exception:
                preferred_subpaths = None

            # Build clang -E command (try preferred language mode first, then fallback if needed).
            # If clang -E fails due to missing headers, try to auto-resolve include dirs and retry a few times.
            try:
                max_preprocess_fixups = int(os.environ.get("C2R_CLANG_PREPROCESS_MAX_RETRIES", "5"))
                if max_preprocess_fixups < 0:
                    max_preprocess_fixups = 0
            except Exception:
                max_preprocess_fixups = 5
            # semantics: allow N fixups + 1 final attempt to validate the last added include dir
            max_preprocess_attempts = max_preprocess_fixups + 1

            # Tier-B unknown-type fixups: after preprocessing succeeds, bindgen can still fail on
            # "unknown type name ..." (not a missing file). In that case we can inject additional
            # system headers into the wrapper and redo clang -E + bindgen.
            try:
                max_unknown_fixups = int(os.environ.get("C2R_TIER_B_UNKNOWN_TYPE_FIXUPS", "2"))
                if max_unknown_fixups < 0:
                    max_unknown_fixups = 0
            except Exception:
                max_unknown_fixups = 2

            def _extract_unknown_types(stderr_text: str) -> List[str]:
                if not stderr_text:
                    return []
                names = re.findall(r"unknown type name '([^']+)'", stderr_text)
                # de-dupe in order
                seen = set()
                out: List[str] = []
                for n in names:
                    n = (n or "").strip()
                    if n and n not in seen:
                        seen.add(n)
                        out.append(n)
                return out

            def _extract_incomplete_enum_types(stderr_text: str) -> List[str]:
                if not stderr_text:
                    return []
                # Example: field has incomplete type 'enum dma_data_direction'
                names = re.findall(r"field has incomplete type 'enum\s+([^']+)'", stderr_text)
                # de-dupe in order
                seen = set()
                out: List[str] = []
                for n in names:
                    n = (n or "").strip()
                    if n and n not in seen:
                        seen.add(n)
                        out.append(n)
                return out

            def _ensure_shim_line(line: str):
                if not line:
                    return
                if line not in wrapper_type_shims and line not in wrapper_enum_shims:
                    # Keep ordering stable, just append.
                    wrapper_type_shims.append(line)

            def _add_type_shims(type_names: List[str]) -> bool:
                if not type_names:
                    return False

                added_any = False

                def _add_shim_for(name: str, lines: List[str], kind: str = "type"):
                    nonlocal added_any
                    if name in wrapper_shimmed_type_names:
                        return
                    for ln in lines:
                        if ln:
                            wrapper_type_shims.append(ln)
                    wrapper_shimmed_type_names.add(name)
                    wrapper_fixup_actions.append({
                        "action": "add_type_shim",
                        "type": name,
                        "lines": lines,
                        "reason": "tier_b_unknown_type_name",
                        "kind": kind,
                    })
                    added_any = True

                # Kernel-style integer typedefs (common in linux/uapi and kernel headers).
                for t in type_names:
                    t = (t or "").strip()
                    if not t:
                        continue

                    if t == "wait_queue_head_t":
                        # Prefer including linuxkpi's <linux/wait.h> (LiteOS) to avoid defining a wrong
                        # placeholder that later conflicts with the real typedef.
                        inc = "<linux/wait.h>"
                        try:
                            if self.ohos_root and Path(self.ohos_root).exists():
                                ohos_root = Path(self.ohos_root)
                                linuxkpi_wait = (
                                    ohos_root
                                    / "third_party"
                                    / "FreeBSD"
                                    / "sys"
                                    / "compat"
                                    / "linuxkpi"
                                    / "common"
                                    / "include"
                                    / "linux"
                                    / "wait.h"
                                )
                                if linuxkpi_wait.exists():
                                    inc = f"\"{linuxkpi_wait}\""
                        except Exception:
                            inc = "<linux/wait.h>"

                        if inc and inc not in wrapper_extra_system_includes:
                            wrapper_extra_system_includes.append(inc)
                            wrapper_fixup_actions.append({
                                "action": "add_system_include",
                                "include": inc,
                                "type": t,
                                "reason": "tier_b_unknown_type_name",
                                "kind": "kernel",
                            })
                            added_any = True
                        continue

                    # __u64/__s64/__u32/... and __le64/__be64...
                    m = re.fullmatch(r"__(u|s)(8|16|32|64)", t)
                    if m:
                        sign, bits = m.group(1), int(m.group(2))
                        c_type = {
                            (False, 8): "unsigned char",
                            (False, 16): "unsigned short",
                            (False, 32): "unsigned int",
                            (False, 64): "unsigned long long",
                            (True, 8): "signed char",
                            (True, 16): "short",
                            (True, 32): "int",
                            (True, 64): "long long",
                        }[(sign == "s", bits)]
                        _add_shim_for(t, [f"typedef {c_type} {t};"])
                        continue

                    m = re.fullmatch(r"__([bl]e)(16|32|64)", t)
                    if m:
                        bits = int(m.group(2))
                        c_type = {
                            16: "unsigned short",
                            32: "unsigned int",
                            64: "unsigned long long",
                        }[bits]
                        _add_shim_for(t, [f"typedef {c_type} {t};"])
                        continue

                    # Kernel short aliases: u8/u16/u32/u64 and s8/...
                    m = re.fullmatch(r"(u|s)(8|16|32|64)", t)
                    if m:
                        sign, bits = m.group(1), int(m.group(2))
                        c_type = {
                            (False, 8): "uint8_t",
                            (False, 16): "uint16_t",
                            (False, 32): "uint32_t",
                            (False, 64): "uint64_t",
                            (True, 8): "int8_t",
                            (True, 16): "int16_t",
                            (True, 32): "int32_t",
                            (True, 64): "int64_t",
                        }[(sign == "s", bits)]
                        _add_shim_for(t, [f"typedef {c_type} {t};"])
                        continue

                    if t == "gfp_t":
                        _add_shim_for("gfp_t", ["typedef unsigned int gfp_t;"])
                        continue

                    if t == "refcount_t":
                        # refcount_t is a kernel-internal typedef with heavy transitive includes.
                        # Provide a minimal placeholder and prevent linux/refcount.h from redefining it.
                        _add_shim_for(
                            "refcount_t",
                            [
                                "#ifndef _LINUX_REFCOUNT_H",
                                "#define _LINUX_REFCOUNT_H 1",
                                "#endif",
                                "typedef struct refcount_struct { int __c2r_dummy; } refcount_t;",
                            ],
                            kind="kernel",
                        )
                        continue

                    if t == "poll_table":
                        _add_shim_for(
                            "poll_table",
                            ["typedef struct poll_table_struct { int __c2r_dummy; } poll_table;"],
                            kind="kernel",
                        )
                        continue

                if added_any:
                    _write_wrapper_for_clang()
                return added_any

            def _add_enum_shims(enum_names: List[str]) -> bool:
                if not enum_names:
                    return False
                added_any = False

                for e in enum_names:
                    e = (e or "").strip()
                    if not e:
                        continue
                    if e in wrapper_shimmed_enum_names:
                        continue
                    if e == "dma_data_direction":
                        lines = [
                            "enum dma_data_direction {",
                            "  DMA_BIDIRECTIONAL = 0,",
                            "  DMA_TO_DEVICE = 1,",
                            "  DMA_FROM_DEVICE = 2,",
                            "  DMA_NONE = 3,",
                            "};",
                        ]
                        wrapper_enum_shims.extend(lines)
                        wrapper_shimmed_enum_names.add(e)
                        wrapper_fixup_actions.append({
                            "action": "add_enum_shim",
                            "enum": e,
                            "lines": lines,
                            "reason": "tier_b_incomplete_enum",
                            "kind": "kernel",
                        })
                        added_any = True

                if added_any:
                    _write_wrapper_for_clang()
                return added_any

            def _maybe_enable_dprintf_rename(stderr_text: str) -> bool:
                nonlocal wrapper_rename_dprintf
                if wrapper_rename_dprintf:
                    return False
                if "conflicting types for 'dprintf'" not in (stderr_text or ""):
                    return False
                wrapper_rename_dprintf = True
                wrapper_fixup_actions.append({
                    "action": "rename_conflicting_symbol",
                    "symbol": "dprintf",
                    "rename_to": "c2r_liteos_dprintf",
                    "reason": "tier_b_conflicting_types",
                })
                _write_wrapper_for_clang()
                return True

            # Resolve bindgen binary once.
            bindgen_path = shutil.which("bindgen")
            if not bindgen_path:
                cargo_bin = Path.home() / ".cargo" / "bin" / "bindgen"
                if cargo_bin.exists():
                    bindgen_path = str(cargo_bin)
            if not bindgen_path:
                logger.error("bindgen æœªå®‰è£…")
                report["attempts"].append({
                    "tier": "B",
                    "step": "bindgen_on_preprocessed",
                    "success": False,
                    "error": "bindgen not installed",
                    "debug": include_diag,
                })
                return False

            # Since the input is already preprocessed, keep only the minimal flags that influence target ABI.
            minimal_flags: List[str] = []
            i = 0
            while i < len(context_flags):
                f = context_flags[i]
                if isinstance(f, str) and (f.startswith("--target=") or f.startswith("--sysroot=") or f in {"-mthumb", "-marm"}):
                    minimal_flags.append(f)
                    i += 1
                    continue
                if f == "-target" and i + 1 < len(context_flags):
                    minimal_flags.extend([f, context_flags[i + 1]])
                    i += 2
                    continue
                if f == "-isysroot" and i + 1 < len(context_flags):
                    minimal_flags.extend([f, context_flags[i + 1]])
                    i += 2
                    continue
                if isinstance(f, str) and f.startswith((
                    "-march=", "-mcpu=", "-mfpu=", "-mfloat-abi=", "-mtune=", "-mabi=",
                    "-mno-", "-mno_", "-msoft-float", "-mhard-float",
                )):
                    minimal_flags.append(f)
                    i += 1
                    continue
                i += 1

            clang_common_flags = [
                "-Wno-error",
                "-Wno-error=register",
                "-Wno-incompatible-library-redeclaration",
                "-Wno-shift-op-parentheses",
                "-Wno-unused-function",
                "-Wno-unused-variable",
                "-Wno-macro-redefined",
                "-Wno-builtin-macro-redefined",
                "-Wno-pragma-once-outside-header",
                "-Wno-ignored-attributes",
            ]

            unresolvable_headers: Set[str] = set()

            for unknown_round in range(0, max_unknown_fixups + 1):
                # Make sure wrapper reflects the current extra includes.
                if unknown_round > 0:
                    _write_wrapper_for_clang()

                preprocess_result = None
                preprocess_lang = None
                preprocess_cmd = None
                include_diag = _make_include_diag(include_dirs or set())
                last_auto_resolve: Optional[Dict[str, Any]] = None

                for preprocess_round in range(1, max_preprocess_attempts + 1):
                    modes = ["c++", "c"] if prefer_cxx else ["c", "c++"]
                    preprocess_result = None
                    preprocess_lang = None
                    preprocess_cmd = None

                    for idx, lang in enumerate(modes, start=1):
                        lang_flags = ["-x", "c++", "-std=c++17"] if lang == "c++" else ["-x", "c"]
                        cmd = [clang_bin, "-E", "-P"] + lang_flags + context_flags + [str(wrapper_path)]

                        logger.info(
                            f"è¿è¡Œ clang -E[{idx}/{len(modes)}] (round {preprocess_round}/{max_preprocess_attempts}): "
                            f"lang={lang} clang={clang_bin} "
                            f"(include dirs={include_diag['include_dirs_count']}, missing dirs={include_diag['nonexistent_dir_count']}, out/gen dirs={include_diag['out_gen_dir_count']})"
                        )
                        r = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
                        preprocess_cmd = cmd
                        preprocess_result = r
                        preprocess_lang = lang
                        if r.returncode == 0:
                            break
                        # If we started from C and the error doesn't look C++-related, don't try C++ (save time).
                        if idx == 1 and not prefer_cxx:
                            cxx_signals = ["shared_mutex", "namespace ", "class ", "template<", "expected unqualified-id", "C++"]
                            if not any(s in (r.stderr or "") for s in cxx_signals):
                                break

                    if preprocess_result and preprocess_result.returncode == 0:
                        break

                    stderr = preprocess_result.stderr if preprocess_result else ""
                    missing = _extract_missing_headers(stderr)
                    if not missing:
                        break

                    # Only retry when we can actually add include dirs.
                    if not self.compile_commands_parser:
                        break

                    new_missing = [h for h in missing if h and h not in unresolvable_headers]
                    if not new_missing:
                        break

                    try:
                        new_includes, still_missing, resolved_map = self.compile_commands_parser.get_resolved_includes_for_bindgen(
                            new_missing,
                            include_dirs or set(),
                            preferred_subpaths=preferred_subpaths,
                        )
                    except Exception as e:
                        logger.warning(f"clang -E auto-resolve failed: {e}")
                        break

                    added_count = len(new_includes) - len(include_dirs or set())
                    unresolvable_headers.update(still_missing)
                    try:
                        last_auto_resolve = {
                            "resolved": {k: v for k, v in (resolved_map or {}).items() if v},
                            "unresolved": list(still_missing),
                            "include_dirs_added": int(added_count),
                        }
                    except Exception:
                        last_auto_resolve = None

                    # If this is the last attempt, do not waste time collecting more include dirs we won't validate.
                    if preprocess_round >= max_preprocess_attempts:
                        break

                    if added_count <= 0:
                        break

                    # Update include dirs + context_flags for next round.
                    include_dirs = new_includes
                    for inc_dir in sorted(include_dirs or set(), key=lambda p: str(p)):
                        inc_dir_str = str(inc_dir)
                        if inc_dir_str not in added_dirs:
                            context_flags.extend(["-I", inc_dir_str])
                            added_dirs.add(inc_dir_str)

                    include_diag = _make_include_diag(include_dirs or set())
                    logger.info(f"clang -E auto-resolved {added_count} include dirs; retrying...")

                if not preprocess_result or preprocess_result.returncode != 0:
                    stderr = preprocess_result.stderr if preprocess_result else ""
                    stderr_lines = (stderr or "").splitlines()
                    report["attempts"].append({
                        "tier": "B",
                        "step": "clang_preprocess",
                        "success": False,
                        "error": ("\n".join(stderr_lines[:80]) if stderr_lines else "unknown error"),
                        "debug": {
                            **include_diag,
                            "clang": clang_bin,
                            "lang": preprocess_lang,
                            "tu_context": tu_ctx,
                            "auto_resolve": last_auto_resolve,
                            "wrapper_extra_system_includes": list(wrapper_extra_system_includes),
                            "wrapper_fixup_actions": list(wrapper_fixup_actions),
                            "stderr_tail": ("\n".join(stderr_lines[-80:]) if len(stderr_lines) > 80 else ""),
                            "cmd_head": (preprocess_cmd or [])[:25],
                            "cmd_len": len(preprocess_cmd or []),
                        },
                    })
                    logger.warning(f"clang -E å¤±è´¥: {(stderr or '')[:300]}")
                    return False

                preprocessed_content = preprocess_result.stdout

                if not preprocessed_content.strip():
                    report["attempts"].append({
                        "tier": "B",
                        "step": "clang_preprocess",
                        "success": False,
                        "error": "empty output"
                    })
                    return False

                # å†™å…¥é¢„å¤„ç†åçš„å†…å®¹
                preprocessed_path = self.output_dir / "preprocessed_header.h"
                with open(preprocessed_path, 'w', encoding='utf-8') as f:
                    f.write(preprocessed_content)

                report["attempts"].append({
                    "tier": "B",
                    "step": "clang_preprocess",
                    "success": True,
                    "output_size": len(preprocessed_content),
                    "debug": {
                        **include_diag,
                        "clang": clang_bin,
                        "lang": preprocess_lang,
                        "tu_context": tu_ctx,
                        "auto_resolve": last_auto_resolve,
                        "wrapper_extra_system_includes": list(wrapper_extra_system_includes),
                        "wrapper_fixup_actions": list(wrapper_fixup_actions),
                        "cmd_head": (preprocess_cmd or [])[:25],
                        "cmd_len": len(preprocess_cmd or []),
                    },
                })

                bindgen_cmd = [
                    bindgen_path,
                    str(preprocessed_path),
                    "-o", str(output_path),
                    "--no-layout-tests",
                    "--no-doc-comments",
                    "--use-core",
                    "--default-enum-style=consts",
                    "--no-prepend-enum-name",
                    "--ignore-functions",
                    "--no-size_t-is-usize",
                    "--",
                    "-x", "c++" if preprocess_lang == "c++" else "c",
                ]
                if preprocess_lang == "c++":
                    bindgen_cmd.append("-std=c++17")
                bindgen_cmd.extend(clang_common_flags)
                bindgen_cmd.extend(minimal_flags)

                bindgen_result = subprocess.run(
                    bindgen_cmd,
                    capture_output=True,
                    text=True,
                    timeout=60
                )

                if bindgen_result.returncode == 0 and output_path.exists():
                    # åå¤„ç†
                    self._postprocess_bindgen_output(output_path)
                    report["attempts"].append({
                        "tier": "B",
                        "step": "bindgen_on_preprocessed",
                        "success": True,
                        "debug": {
                            **include_diag,
                            "returncode": bindgen_result.returncode,
                            "wrapper_extra_system_includes": list(wrapper_extra_system_includes),
                            "wrapper_fixup_actions": list(wrapper_fixup_actions),
                            "cmd_head": bindgen_cmd[:25],
                            "cmd_len": len(bindgen_cmd),
                        },
                    })
                    logger.info("Tier B: clang -E + bindgen æˆåŠŸ")
                    return True

                stderr = bindgen_result.stderr or ""
                stderr_lines = stderr.splitlines()
                report["attempts"].append({
                    "tier": "B",
                    "step": "bindgen_on_preprocessed",
                    "success": False,
                    "error": ("\n".join(stderr_lines[:80]) if stderr_lines else "unknown error"),
                    "debug": {
                        **include_diag,
                        "returncode": bindgen_result.returncode,
                        "wrapper_extra_system_includes": list(wrapper_extra_system_includes),
                        "wrapper_fixup_actions": list(wrapper_fixup_actions),
                        "stderr_tail": ("\n".join(stderr_lines[-80:]) if len(stderr_lines) > 80 else ""),
                        "cmd_head": bindgen_cmd[:25],
                        "cmd_len": len(bindgen_cmd),
                    },
                })

                unknown_types = _extract_unknown_types(stderr)
                incomplete_enums = _extract_incomplete_enum_types(stderr)

                fixups_applied = False
                if unknown_round < max_unknown_fixups:
                    # 1) Resolve known symbol prototype conflicts (e.g., dprintf: musl vs LiteOS).
                    fixups_applied = _maybe_enable_dprintf_rename(stderr) or fixups_applied
                    # 2) Add lightweight shims for unknown types (prefer shims over heavy kernel includes).
                    if unknown_types:
                        fixups_applied = _add_type_shims(unknown_types) or fixups_applied
                    # 3) Define missing enums when only forward-declared.
                    if incomplete_enums:
                        fixups_applied = _add_enum_shims(incomplete_enums) or fixups_applied

                if unknown_round < max_unknown_fixups and fixups_applied:
                    logger.info(
                        f"Tier B fixup round {unknown_round + 1}/{max_unknown_fixups}: "
                        f"applied (unknown_types={unknown_types}, incomplete_enums={incomplete_enums}, dprintf_renamed={wrapper_rename_dprintf}); retrying..."
                    )
                    continue

                logger.warning(f"Tier B bindgen å¤±è´¥: {stderr[:300]}")
                return False

        except subprocess.TimeoutExpired:
            report["attempts"].append({
                "tier": "B",
                "success": False,
                "error": "timeout"
            })
            logger.warning("Tier B è¶…æ—¶")
            return False
        except Exception as e:
            report["attempts"].append({
                "tier": "B",
                "success": False,
                "error": str(e)
            })
            logger.warning(f"Tier B å¼‚å¸¸: {e}")
            return False
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if not self._env_flag("C2R_BINDGEN_DEBUG_KEEP_FILES"):
                for tmp_file in [self.output_dir / "wrapper_for_clang.h",
                               self.output_dir / "preprocessed_header.h"]:
                    if tmp_file.exists():
                        try:
                            tmp_file.unlink()
                        except:
                            pass

    def _generate_stub_types_rs(self, output_path: Path, header_files: List[Path] = None):
        """
        Tier C: ç”Ÿæˆä¿è¯ç¼–è¯‘é€šè¿‡çš„ stub types.rs

        è¿™æ˜¯æœ€ç»ˆå…œåº•æ–¹æ¡ˆï¼Œç”Ÿæˆçš„ types.rs ä¸€å®šèƒ½é€šè¿‡ cargo check

        åŒ…å«ï¼š
        - æ‰€æœ‰åŸºç¡€ C ç±»å‹æ˜ å°„
        - å¸¸ç”¨ç³»ç»Ÿç±»å‹çš„ opaque å®šä¹‰
        - ä»å¤´æ–‡ä»¶ä¸­æ‰«æåˆ°çš„ç±»å‹çš„ opaque å ä½ç¬¦

        Args:
            output_path: è¾“å‡ºè·¯å¾„
            header_files: å¤´æ–‡ä»¶åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œç”¨äºæ‰«æç±»å‹åï¼‰
        """
        lines = []

        # æ–‡ä»¶å¤´
        lines.append('''//! Auto-generated stub type definitions
//!
//! This is a STUB file generated as a fallback when bindgen failed.
//! All custom types are declared as opaque structs to ensure compilation.
//!
//! Generation mode: Tier C (guaranteed compilation)

#![allow(non_camel_case_types)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(dead_code)]
#![allow(unused)]

// ============================================================
// Core C Type Mappings (guaranteed correct)
// ============================================================

pub type c_void = core::ffi::c_void;
pub type c_char = i8;
pub type c_schar = i8;
pub type c_uchar = u8;
pub type c_short = i16;
pub type c_ushort = u16;
pub type c_int = i32;
pub type c_uint = u32;
pub type c_long = i64;
pub type c_ulong = u64;
pub type c_longlong = i64;
pub type c_ulonglong = u64;
pub type c_float = f32;
pub type c_double = f64;

// Fixed-width integer types
pub type int8_t = i8;
pub type int16_t = i16;
pub type int32_t = i32;
pub type int64_t = i64;
pub type uint8_t = u8;
pub type uint16_t = u16;
pub type uint32_t = u32;
pub type uint64_t = u64;

// Size types
pub type size_t = usize;
pub type ssize_t = isize;
pub type ptrdiff_t = isize;
pub type intptr_t = isize;
pub type uintptr_t = usize;

// POSIX types
pub type off_t = i64;
pub type pid_t = i32;
pub type uid_t = u32;
pub type gid_t = u32;
pub type mode_t = u32;
pub type time_t = i64;

// Boolean type
pub type BOOL = i32;
pub const TRUE: i32 = 1;
pub const FALSE: i32 = 0;

// ============================================================
// Common System Types (opaque definitions)
// ============================================================

#[repr(C)]
#[derive(Debug, Copy, Clone)]
pub struct FILE { _opaque: [u8; 0] }

#[repr(C)]
pub struct pthread_mutex_t { _opaque: [u8; 40] }

#[repr(C)]
pub struct pthread_cond_t { _opaque: [u8; 48] }

#[repr(C)]
pub struct pthread_attr_t { _opaque: [u8; 56] }

pub type pthread_t = usize;

// PTHREAD initializers
pub const PTHREAD_MUTEX_INITIALIZER: pthread_mutex_t = unsafe { ::core::mem::zeroed() };
pub const PTHREAD_COND_INITIALIZER: pthread_cond_t = unsafe { ::core::mem::zeroed() };

// ============================================================
// Common Error Codes
// ============================================================

pub const EINVAL: i32 = 22;
pub const ENOMEM: i32 = 12;
pub const ENOENT: i32 = 2;
pub const EEXIST: i32 = 17;
pub const EAGAIN: i32 = 11;
pub const ETIMEDOUT: i32 = 110;
pub const EBUSY: i32 = 16;
pub const EPERM: i32 = 1;
pub const EFAULT: i32 = 14;

// ============================================================
// Framework-specific Constants (OpenHarmony/HDF/LiteOS)
// ============================================================

// SoftBus
pub const SOFTBUS_OK: i32 = 0;
pub const SOFTBUS_ERR: i32 = -1;
pub const SOFTBUS_INVALID_PARAM: i32 = -3;

// HDF
pub const HDF_SUCCESS: i32 = 0;
pub const HDF_FAILURE: i32 = -1;
pub const HDF_ERR_INVALID_PARAM: i32 = -3;

// LiteOS
pub const LOS_OK: u32 = 0;
pub const LOS_NOK: u32 = 1;
pub const LOS_ERRNO_TSK_ID_INVALID: u32 = 0x02000207;
''')

        # å¦‚æœæœ‰å¤´æ–‡ä»¶ï¼Œæ‰«æå…¶ä¸­çš„ç±»å‹åå¹¶ç”Ÿæˆ opaque å ä½ç¬¦
        scanned_types = set()
        # æ–°å¢ï¼šæ‰«æç®€å• typedef å¹¶è®°å½•å…¶å¯¹åº”çš„ Rust ç±»å‹
        simple_typedefs: Dict[str, str] = {}

        # C ç±»å‹åˆ° Rust ç±»å‹çš„æ˜ å°„ï¼ˆç”¨äºç®€å• typedefï¼‰
        c_to_rust_type_map = {
            'int': 'i32',
            'unsigned int': 'u32',
            'signed int': 'i32',
            'char': 'i8',
            'signed char': 'i8',
            'unsigned char': 'u8',
            'short': 'i16',
            'short int': 'i16',
            'signed short': 'i16',
            'signed short int': 'i16',
            'unsigned short': 'u16',
            'unsigned short int': 'u16',
            'long': 'i64',
            'long int': 'i64',
            'signed long': 'i64',
            'signed long int': 'i64',
            'unsigned long': 'u64',
            'unsigned long int': 'u64',
            'long long': 'i64',
            'long long int': 'i64',
            'signed long long': 'i64',
            'unsigned long long': 'u64',
            'float': 'f32',
            'double': 'f64',
            'long double': 'f64',
            'void': 'c_void',
            '_Bool': 'bool',
        }

        if header_files:
            for h in header_files:
                if h.exists():
                    try:
                        with open(h, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read()

                        # æ–°å¢ï¼šæå–ç®€å• typedefï¼ˆå¦‚ typedef int Int32;ï¼‰
                        # åŒ¹é…æ¨¡å¼ï¼štypedef <c_type> <name>;
                        simple_typedef_pattern = r'typedef\s+((?:(?:signed|unsigned|long|short|const|volatile)\s+)*(?:char|int|short|long|float|double|void|_Bool))\s+(\w+)\s*;'
                        for match in re.finditer(simple_typedef_pattern, content):
                            c_type = match.group(1).strip()
                            type_name = match.group(2).strip()
                            # è§„èŒƒåŒ– C ç±»å‹ï¼ˆå»é™¤å¤šä½™ç©ºæ ¼ï¼‰
                            c_type_normalized = ' '.join(c_type.split())
                            if c_type_normalized in c_to_rust_type_map:
                                rust_type = c_to_rust_type_map[c_type_normalized]
                                simple_typedefs[type_name] = rust_type

                        # æå– typedef struct xxx
                        typedef_structs = re.findall(r'typedef\s+struct\s+\w*\s*\{[^}]*\}\s*(\w+)\s*;', content, re.DOTALL)
                        scanned_types.update(typedef_structs)

                        # æå– struct xxx {
                        struct_names = re.findall(r'struct\s+(\w+)\s*\{', content)
                        scanned_types.update(struct_names)

                        # æå– enum xxx {
                        enum_names = re.findall(r'enum\s+(\w+)\s*\{', content)
                        scanned_types.update(enum_names)

                    except Exception as e:
                        logger.debug(f"æ‰«æå¤´æ–‡ä»¶ {h} å¤±è´¥: {e}")

        # è¿‡æ»¤æ‰å·²å®šä¹‰çš„ç±»å‹å’Œæ— æ•ˆåç§°
        already_defined = {
            'FILE', 'pthread_mutex_t', 'pthread_cond_t', 'pthread_attr_t',
            'c_void', 'c_char', 'c_int', 'c_uint', 'c_long', 'c_ulong',
            'int8_t', 'int16_t', 'int32_t', 'int64_t',
            'uint8_t', 'uint16_t', 'uint32_t', 'uint64_t',
            'size_t', 'ssize_t', 'BOOL', 'off_t', 'pid_t', 'uid_t', 'gid_t', 'mode_t', 'time_t'
        }

        # è¿‡æ»¤ç®€å• typedefï¼Œæ’é™¤å·²å®šä¹‰çš„ç±»å‹
        valid_simple_typedefs = {
            name: rust_type for name, rust_type in simple_typedefs.items()
            if name not in already_defined and re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*$', name)
        }

        valid_scanned = set()
        for t in scanned_types:
            if t and t not in already_defined and t not in valid_simple_typedefs and re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*$', t):
                valid_scanned.add(t)

        # æ–°å¢ï¼šå…ˆè¾“å‡ºç®€å• typedef çš„ç±»å‹åˆ«å
        if valid_simple_typedefs:
            lines.append("\n// ============================================================")
            lines.append("// Project-specific Type Aliases (scanned from headers)")
            lines.append("// ============================================================\n")

            for type_name in sorted(valid_simple_typedefs.keys()):
                rust_type = valid_simple_typedefs[type_name]
                lines.append(f"/// Type alias for `{type_name}` (from C typedef)")
                lines.append(f"pub type {type_name} = {rust_type};")
                lines.append("")

        # ç„¶åè¾“å‡º opaque structsï¼ˆä»…ç”¨äºå¤æ‚ç±»å‹ï¼‰
        if valid_scanned:
            lines.append("\n// ============================================================")
            lines.append("// Project-specific Types (scanned from headers, opaque)")
            lines.append("// ============================================================\n")

            for type_name in sorted(valid_scanned):
                lines.append(f"/// Opaque placeholder for external type `{type_name}`")
                lines.append("#[repr(C)]")
                lines.append("#[derive(Debug, Copy, Clone)]")
                lines.append(f"pub struct {type_name} {{ _opaque: [u8; 0] }}")
                lines.append("")

        # å†™å…¥æ–‡ä»¶
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))

        logger.info(f"Stub types.rs å·²ç”Ÿæˆ: {len(valid_simple_typedefs)} ä¸ªç±»å‹åˆ«å, {len(valid_scanned)} ä¸ª opaque ç±»å‹")

    def _env_flag(self, name: str, default: str = "0") -> bool:
        """Parse a boolean-ish environment flag safely (1/true/yes/on)."""
        v = os.environ.get(name, default)
        return str(v).strip().lower() in {"1", "true", "yes", "y", "on"}

    def _write_types_generation_report(self, report: dict):
        """
        å†™å…¥ types ç”ŸæˆæŠ¥å‘Š

        Args:
            report: æŠ¥å‘Šæ•°æ®
        """
        import json

        report_path = self.output_dir / "types_generation_report.json"

        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)
            logger.debug(f"Types ç”ŸæˆæŠ¥å‘Šå·²å†™å…¥: {report_path}")
            if self._env_flag("C2R_BINDGEN_DEBUG") or report.get("mode") == "stub" or not report.get("success", False):
                print(f"  ğŸ“„ types_generation_report.json: {report_path}")
        except Exception as e:
            logger.warning(f"å†™å…¥ types ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
    
    def _attempt_bindgen(
        self, 
        header_files: List[Path], 
        output_file: str,
        include_dirs: Set[Path] = None,
        source_files: List[Path] = None,
    ) -> Tuple[bool, str, List[str], Dict[str, Any]]:
        """
        å°è¯•è¿è¡Œ bindgen
        
        Args:
            header_files: å¤´æ–‡ä»¶åˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶å
            include_dirs: è¦ä½¿ç”¨çš„ include è·¯å¾„é›†åˆï¼ˆå¦‚æœä¸º Noneï¼Œä½¿ç”¨ self.include_dirsï¼‰
        
        Returns:
            (æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯, ç¼ºå¤±çš„å¤´æ–‡ä»¶åˆ—è¡¨, è°ƒè¯•ä¿¡æ¯)
        """
        attempt_debug: Dict[str, Any] = {
            "bindgen_debug": self._env_flag("C2R_BINDGEN_DEBUG"),
            "bindgen_debug_keep_files": self._env_flag("C2R_BINDGEN_DEBUG_KEEP_FILES"),
            "compile_commands_loaded": bool(self.compile_commands_parser),
            "compile_commands_path": str(self.compile_commands_parser.compile_db_path) if self.compile_commands_parser else None,
        }
        bindgen_debug = bool(attempt_debug["bindgen_debug"])
        keep_files = bool(attempt_debug["bindgen_debug_keep_files"])

        # ä½¿ç”¨ä¼ å…¥çš„ include_dirs æˆ–é»˜è®¤çš„
        if include_dirs is None:
            include_dirs = set(self.include_dirs)
        attempt_debug["include_dirs_input_count"] = len(include_dirs)
        attempt_debug["self_include_dirs_count"] = len(getattr(self, "include_dirs", []) or [])
        
        # åˆ›å»ºä¸´æ—¶ wrapper.h åŒ…å«æ‰€æœ‰å¤´æ–‡ä»¶
        included_headers = [h for h in header_files if h.exists()]
        attempt_debug["header_files_count"] = len(header_files)
        attempt_debug["header_files_included_count"] = len(included_headers)
        attempt_debug["header_files_included_sample"] = [str(h) for h in included_headers[:10]]

        wrapper_path = self.output_dir / "wrapper.h"

        # Wrapper-level fixups that can be applied based on bindgen diagnostics.
        wrapper_extra_system_includes: List[str] = []
        wrapper_header_order: List[Path] = list(header_files)
        wrapper_fixup_actions: List[Dict[str, Any]] = []

        def _write_wrapper(
            force_need_struct_sched_param: bool,
            *,
            extra_system_includes: Optional[List[str]] = None,
            ordered_headers: Optional[List[Path]] = None,
        ):
            wrapper_content: List[str] = []
            wrapper_content.append("// Auto-generated wrapper header for bindgen")
            wrapper_content.append("")

            # musl's bits/alltypes.h uses __NEED_* gating; missing some __NEED_* may cause incomplete types.
            # For sched_param, prefer including <sched.h> on-demand (defining __NEED_struct_sched_param can
            # conflict with <sched.h> and trigger redefinition errors).
            if force_need_struct_sched_param:
                wrapper_content.append("#include <sched.h>")
                wrapper_content.append("")
            wrapper_content.append("#ifndef __NEED_struct_cpu_set_t")
            wrapper_content.append("#define __NEED_struct_cpu_set_t 1")
            wrapper_content.append("#endif")
            wrapper_content.append("")

            # Linux/UAPI-style annotation macros: make them parseable outside full kernel build context.
            wrapper_content.append("#ifndef __must_check")
            wrapper_content.append("#define __must_check __attribute__((warn_unused_result))")
            wrapper_content.append("#endif")
            wrapper_content.append("#ifndef __packed")
            wrapper_content.append("#define __packed __attribute__((packed))")
            wrapper_content.append("#endif")
            wrapper_content.append("#ifndef __aligned")
            wrapper_content.append("#define __aligned(x) __attribute__((aligned(x)))")
            wrapper_content.append("#endif")
            wrapper_content.append("#ifndef __user")
            wrapper_content.append("#define __user")
            wrapper_content.append("#endif")
            wrapper_content.append("#ifndef __force")
            wrapper_content.append("#define __force")
            wrapper_content.append("#endif")
            wrapper_content.append("#ifndef __iomem")
            wrapper_content.append("#define __iomem")
            wrapper_content.append("#endif")
            wrapper_content.append("")

            # Provide common fundamental typedefs early.
            # Some OpenHarmony headers assume these are already available (via transitive includes in real TUs).
            wrapper_content.append("#include <stddef.h>")
            wrapper_content.append("#include <stdint.h>")
            wrapper_content.append("#include <stdbool.h>")
            if extra_system_includes:
                for inc in extra_system_includes:
                    inc = (inc or "").strip()
                    if not inc:
                        continue
                    wrapper_content.append(f"#include {inc}")
            wrapper_content.append("")

            for h in (ordered_headers or header_files):
                if h.exists():
                    wrapper_content.append(f'#include "{h}"')

            wrapper_content.append("")

            with open(wrapper_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(wrapper_content))
            attempt_debug["wrapper_need_struct_sched_param"] = bool(force_need_struct_sched_param)
            attempt_debug["wrapper_extra_system_includes"] = list(extra_system_includes or [])
            try:
                hdrs = list(ordered_headers or header_files)
                attempt_debug["wrapper_headers_head"] = [str(p) for p in hdrs[:30]]
            except Exception:
                pass
            attempt_debug["wrapper_fixup_actions"] = list(wrapper_fixup_actions)

        def _extract_unknown_type_records(stderr_text: str) -> List[Tuple[str, str]]:
            if not stderr_text:
                return []
            pat = re.compile(
                r"^(?P<file>[^:\n]+):\d+:\d+:\s+error:\s+unknown type name\s+'(?P<type>[^']+)'",
                re.MULTILINE,
            )
            out: List[Tuple[str, str]] = []
            for m in pat.finditer(stderr_text):
                f = (m.group("file") or "").strip()
                t = (m.group("type") or "").strip()
                if f and t:
                    out.append((f, t))
            return out

        def _header_defines_typedef_like(h: Path, type_name: str) -> bool:
            try:
                content = h.read_text(encoding="utf-8", errors="ignore")
            except Exception:
                return False
            if type_name not in content:
                return False
            typedef_pat = re.compile(rf"\btypedef\s+(?:struct|enum|union)\b[^;]*\b{re.escape(type_name)}\b\s*;", re.MULTILINE)
            if typedef_pat.search(content):
                return True
            struct_pat = re.compile(rf"\bstruct\s+{re.escape(type_name)}\s*\{{", re.MULTILINE)
            if struct_pat.search(content):
                return True
            return False

        def _find_defining_header_for_type(type_name: str, headers: List[Path]) -> Optional[Path]:
            known = {
                "IpcObjectStub": "ipc_skeleton.h",
            }
            target_basename = known.get(type_name)
            if target_basename:
                for h in headers:
                    if h.name == target_basename:
                        return h
            for h in headers:
                if not h.exists():
                    continue
                if _header_defines_typedef_like(h, type_name):
                    return h
            return None

        def _move_header_before(headers: List[Path], header_to_move: Path, before_header: Path) -> Tuple[List[Path], bool]:
            if header_to_move == before_header:
                return headers, False
            try:
                i_move = next(i for i, p in enumerate(headers) if p == header_to_move)
                i_before = next(i for i, p in enumerate(headers) if p == before_header)
            except StopIteration:
                return headers, False
            if i_move < i_before:
                return headers, False
            new_headers = [p for i, p in enumerate(headers) if i != i_move]
            try:
                j_before = next(i for i, p in enumerate(new_headers) if p == before_header)
            except StopIteration:
                return headers, False
            new_headers.insert(j_before, header_to_move)
            return new_headers, True

        # First try without forcing sched_param (avoids <sched.h> redefinition); enable on-demand on specific errors.
        _write_wrapper(
            force_need_struct_sched_param=False,
            extra_system_includes=wrapper_extra_system_includes,
            ordered_headers=wrapper_header_order,
        )
        attempt_debug["wrapper_path"] = str(wrapper_path)
        attempt_debug["wrapper_has_extern_c_guard"] = False
        
        output_path = self.output_dir / "src" / output_file
        missing_files = []
        attempt_debug["output_path"] = str(output_path)

        def _extract_include_args(argv: List[str]) -> List[Tuple[str, str]]:
            """Extract include directory args (-I/-isystem) from clang argv in order."""
            res: List[Tuple[str, str]] = []
            i = 0
            while i < len(argv):
                a = argv[i]
                if a == "-I" and i + 1 < len(argv):
                    res.append(("-I", argv[i + 1]))
                    i += 2
                    continue
                if a.startswith("-I") and a != "-I":
                    res.append(("-I", a[len("-I"):]))
                    i += 1
                    continue
                if a == "-isystem" and i + 1 < len(argv):
                    res.append(("-isystem", argv[i + 1]))
                    i += 2
                    continue
                if a.startswith("-isystem") and a != "-isystem":
                    res.append(("-isystem", a[len("-isystem"):]))
                    i += 1
                    continue
                i += 1
            return res

        def _is_out_gen_path(p: str) -> bool:
            norm = (p or "").replace("\\", "/")
            return "/out/" in norm and "/gen" in norm

        def _summarize_clang_flags(flags: List[str]) -> Dict[str, int]:
            return {
                "total": len(flags),
                "D": sum(1 for f in flags if isinstance(f, str) and f.startswith("-D")),
                "U": sum(1 for f in flags if isinstance(f, str) and f.startswith("-U")),
                "I": sum(1 for f, _p in _extract_include_args(flags) if f == "-I"),
                "isystem": sum(1 for f, _p in _extract_include_args(flags) if f == "-isystem"),
                "include": sum(1 for f in flags if f == "-include"),
                "imacros": sum(1 for f in flags if f == "-imacros"),
                "sysroot": sum(1 for f in flags if isinstance(f, str) and (f.startswith("--sysroot=") or f == "--sysroot" or f == "-isysroot")),
                "target": sum(1 for f in flags if isinstance(f, str) and f.startswith("--target=")),
            }
        
        try:
            # æ£€æŸ¥ bindgen æ˜¯å¦å¯ç”¨
            bindgen_path = shutil.which("bindgen")
            if not bindgen_path:
                # å°è¯• cargo å®‰è£…ç›®å½•
                cargo_bin = Path.home() / ".cargo" / "bin" / "bindgen"
                if cargo_bin.exists():
                    bindgen_path = str(cargo_bin)
                else:
                    logger.error("bindgen æœªå®‰è£…ï¼Œæ— æ³•ç”Ÿæˆç±»å‹éª¨æ¶")
                    return False, "bindgen not installed", [], attempt_debug
            attempt_debug["bindgen_path"] = str(bindgen_path)
            
            # æ„å»º bindgen å‘½ä»¤ï¼ˆclang å‚æ•°åœ¨ `--` ä¹‹åï¼‰
            bindgen_cmd_prefix = [
                bindgen_path,
                str(wrapper_path),
                "-o", str(output_path),
                "--no-layout-tests",
                "--no-doc-comments",
                "--use-core",
                "--default-enum-style=consts",
                "--no-prepend-enum-name",
                "--ignore-functions",
                "--no-size_t-is-usize",
                "--",
            ]

            # ========== musl å…¼å®¹æ€§ clang å‚æ•°ï¼ˆé€šç”¨ï¼‰ ==========
            clang_common_flags = [
                # Do not fail the whole bindgen run due to warnings (some headers trigger noisy warnings).
                "-Wno-error",
                "-Wno-error=register",
                "-Wno-incompatible-library-redeclaration",
                "-Wno-shift-op-parentheses",
                "-Wno-unused-function",
                "-Wno-unused-variable",
                "-Wno-macro-redefined",
                "-Wno-builtin-macro-redefined",
                "-Wno-pragma-once-outside-header",
                "-Wno-ignored-attributes",
            ]

            # Decide language mode: prefer the representative TU's language (C vs C++).
            rep_src_suffix = ""
            try:
                rep_src_suffix = str(Path(source_files[0]).suffix).lower() if source_files else ""
            except Exception:
                rep_src_suffix = ""
            prefer_cxx = rep_src_suffix in {".cc", ".cpp", ".cxx", ".c++"}
            attempt_debug["clang_mode"] = {
                "rep_src_suffix": rep_src_suffix,
                "preferred": "c++" if prefer_cxx else "c",
                "attempts": [],
            }

            def _build_cpp_stdlib_flags() -> Tuple[List[str], Dict[str, Any]]:
                """
                Best-effort: add C++ standard library headers.
                Prefer OpenHarmony prebuilts' libc++ when available; otherwise fall back to host.
                """
                cpp_flags: List[str] = []
                meta: Dict[str, Any] = {"added": False, "mode": None, "paths": [], "paths_count": 0, "clang_resource": None}

                def _find_ohos_clang_resource_include() -> Optional[Path]:
                    """
                    Prefer OpenHarmony prebuilts' clang resource headers:
                      prebuilts/clang/ohos/linux-x86_64/llvm/lib/clang/<ver>/include
                    These provide fundamental headers like <stddef.h> with nullptr_t support.
                    """
                    if not self.ohos_root:
                        return None
                    base = (
                        self.ohos_root
                        / "prebuilts"
                        / "clang"
                        / "ohos"
                        / "linux-x86_64"
                        / "llvm"
                        / "lib"
                        / "clang"
                    )
                    if not base.exists():
                        return None
                    # Prefer "current" if present; otherwise pick the lexicographically largest version dir.
                    current = base / "current" / "include"
                    if current.exists():
                        return current
                    versions: List[Path] = []
                    try:
                        for p in base.iterdir():
                            inc = p / "include"
                            if inc.exists():
                                versions.append(inc)
                    except Exception:
                        versions = []
                    if not versions:
                        return None
                    versions.sort(key=lambda p: str(p))
                    return versions[-1]

                # Prefer OpenHarmony prebuilts (avoid host libstdc++ mismatches).
                if self.ohos_root:
                    ohos_prebuilts_base = self.ohos_root / "prebuilts" / "clang" / "ohos" / "linux-x86_64"
                    ohos_llvm_roots = [
                        ohos_prebuilts_base / "llvm_ndk",  # OpenHarmony NDK layout
                        ohos_prebuilts_base / "llvm",      # legacy layout
                    ]
                    for ohos_llvm in ohos_llvm_roots:
                        ohos_cpp_candidates = [
                            ohos_llvm / "include" / "libcxx-ohos" / "include" / "c++" / "v1",
                            ohos_llvm / "include" / "c++" / "v1",
                            ohos_llvm / "include" / "x86_64-unknown-linux-gnu" / "c++" / "v1",
                        ]
                        existing_ohos_cpp = [p for p in ohos_cpp_candidates if p.exists()]
                        if existing_ohos_cpp:
                            cpp_flags.append("-nostdinc++")
                            resource_inc = _find_ohos_clang_resource_include()
                            if resource_inc:
                                cpp_flags.extend(["-isystem", str(resource_inc)])
                                meta["clang_resource"] = str(resource_inc)
                            for p in existing_ohos_cpp:
                                cpp_flags.extend(["-isystem", str(p)])
                            meta.update({
                                "added": True,
                                "mode": "ohos_prebuilts",
                                "paths": [str(p) for p in existing_ohos_cpp[:10]],
                                "paths_count": len(existing_ohos_cpp),
                            })
                            return cpp_flags, meta

                # Host fallback
                host_cpp_candidates = [
                    "/usr/include/x86_64-linux-gnu/c++/11",
                    "/usr/include/c++/11",
                    "/usr/include/c++/v1",
                    "/usr/lib/llvm-14/include/c++/v1",
                    "/usr/lib/llvm-13/include/c++/v1",
                ]
                for cpp_path in host_cpp_candidates:
                    if Path(cpp_path).exists():
                        cpp_flags.extend(["-isystem", cpp_path])
                        meta.setdefault("paths", []).append(cpp_path)
                if meta.get("paths"):
                    meta["added"] = True
                    meta["mode"] = "host"
                    meta["paths_count"] = len(meta["paths"])
                return cpp_flags, meta

            # Build language-mode attempts: try preferred mode first, then fallback.
            mode_attempts: List[Dict[str, Any]] = []
            modes = ["c++", "c"] if prefer_cxx else ["c", "c++"]
            for lang in modes:
                mode_flags: List[str] = ["-x", "c++", "-std=c++17"] if lang == "c++" else ["-x", "c"]
                cpp_flags: List[str] = []
                cpp_meta: Dict[str, Any] = {"added": False}
                if lang == "c++":
                    cpp_flags, cpp_meta = _build_cpp_stdlib_flags()
                mode_attempts.append({
                    "lang": lang,
                    "clang_flags": mode_flags + clang_common_flags + cpp_flags,
                    "cpp_stdlib": cpp_meta,
                })
            
            # ========== â˜…â˜…â˜… å…³é”®ä¼˜åŒ–ï¼šä½¿ç”¨â€œå•ä¸ª TU çš„çœŸå®ç¼–è¯‘ä¸Šä¸‹æ–‡ï¼ˆä¿åºï¼‰â€è€Œä¸æ˜¯å…¨å±€ include å¹¶é›† â˜…â˜…â˜… ==========
            # èƒŒæ™¯ï¼šå…¨å±€ include å¹¶é›† + set å»é‡ä¼šæ‰“ä¹± -I é¡ºåºï¼Œå¯¼è‡´ clang é€‰é”™åŒåå¤´æ–‡ä»¶ï¼ˆå¦‚ los_config.hï¼‰ï¼Œ
            # è¿›è€Œè§¦å‘ target_config.h/soc.h ç­‰çº§è”ç¼ºå¤±ï¼Œæœ€åé€¼è¿«å›é€€åˆ° stub types.rsã€‚
            #
            # è¿™é‡Œå…ˆæ„å»ºä¸€ä¸ªâ€œä¸Šä¸‹æ–‡ clang flagsâ€åˆ—è¡¨ï¼ˆä¸å«è¯­è¨€æ¨¡å¼ï¼‰ï¼Œåç»­æ¯ç§è¯­è¨€æ¨¡å¼å°è¯•éƒ½ä¼šå¤ç”¨å®ƒã€‚
            context_flags: List[str] = []
            added_dirs: Set[str] = set()
            cc_context_used = False

            # 1) ä¼˜å…ˆä» compile_commands.json å–â€œä»£è¡¨æ€§æºæ–‡ä»¶â€çš„ clang flagsï¼ˆåŒ…å« -I/-isystem/-D ç­‰ï¼Œå¹¶ä¿åºï¼‰
            if self.compile_commands_parser and source_files:
                rep_src: Optional[Path] = None
                for src in source_files:
                    p = Path(src)
                    if p.exists():
                        rep_src = p
                        break

                if rep_src:
                    mapped_src = self._map_to_ohos_path(rep_src)
                    try:
                        tu_debug: Dict[str, Any] = {
                            "rep_src": str(rep_src),
                            "mapped_src": str(mapped_src),
                            "used_proxy": False,
                        }
                        # Prefer stage1-selected TU context (pins flags/macros/include order).
                        entry: Optional[Dict[str, Any]] = None
                        match_info: Dict[str, Any] = {}
                        try:
                            safe_name = self._get_safe_module_name(rep_src)
                            rec = self._tu_context_files.get(safe_name) if getattr(self, "_tu_context_files", None) else None
                            if isinstance(rec, dict) and isinstance(rec.get("compile_commands_entry"), dict):
                                entry = rec.get("compile_commands_entry")
                                match_info = {
                                    "reason": "tu_context_map",
                                    "tu_context_map": str(getattr(self, "_tu_context_map_path", "")) if getattr(self, "_tu_context_map_path", None) else None,
                                    "entry_hash": rec.get("entry_hash"),
                                }
                                tu_debug["tu_context_map_used"] = True
                                tu_debug["tu_context_safe_name"] = safe_name
                        except Exception:
                            entry = None
                            match_info = {}

                        if not entry:
                            entry, match_info = self.compile_commands_parser.get_entry_for_file_with_reason(mapped_src)
                        tu_debug["match_info"] = match_info
                        tu_debug["entry_found"] = bool(entry)

                        clang_flags_raw: List[str] = []
                        clang_flags: List[str] = []
                        if entry:
                            clang_flags_raw = self.compile_commands_parser.get_clang_flags_for_entry(entry, normalize_paths=False)
                            clang_flags = self.compile_commands_parser.get_clang_flags_for_entry(entry, normalize_paths=True)
                            tu_debug["entry_file"] = entry.get("file")
                            tu_debug["entry_directory"] = entry.get("directory")

                        # å¦‚æœè¯¥æ¨¡å—æœ¬èº«æ²¡æœ‰å‡ºç°åœ¨ compile_commands ä¸­ï¼ˆå¸¸è§äº SelfContained å­é›†ï¼‰ï¼Œ
                        # å¯é€‰ï¼šé€€åŒ–ä¸ºé€‰æ‹©åŒä¸€å­ç³»ç»Ÿï¼ˆä¾‹å¦‚ kernel/liteos_aï¼‰çš„ä»»æ„ä¸€ä¸ªå·²ç¼–è¯‘ TU ä½œä¸ºâ€œä¸Šä¸‹æ–‡ä»£ç†â€ã€‚
                        # Default OFF: when the compile_commands closure is incomplete, treat it as an input issue and report it.
                        enable_proxy = os.environ.get("C2R_ENABLE_PROXY_TU_FALLBACK", "0").strip().lower() in ("1", "true", "yes")
                        if enable_proxy and (not clang_flags) and self._ohos_project_rel and len(self._ohos_project_rel.parts) >= 2:
                            # Prefer a *nearby* proxy TU: try longer prefixes first (more specific), then fall back.
                            max_parts = min(5, len(self._ohos_project_rel.parts))
                            proxy_file: Optional[Path] = None
                            proxy_key: Optional[str] = None
                            for n in range(max_parts, 1, -1):
                                candidate_key = str(Path(*self._ohos_project_rel.parts[:n]))
                                candidate_file = self.compile_commands_parser.find_first_source_file_containing(candidate_key)
                                if candidate_file:
                                    proxy_key = candidate_key
                                    proxy_file = candidate_file
                                    break

                            if proxy_file and proxy_key:
                                tu_debug["proxy_key"] = proxy_key
                                tu_debug["proxy_file"] = str(proxy_file)
                                p_entry, p_match_info = self.compile_commands_parser.get_entry_for_file_with_reason(proxy_file)
                                tu_debug["proxy_match_info"] = p_match_info
                                tu_debug["proxy_entry_found"] = bool(p_entry)
                                if p_entry:
                                    clang_flags_raw = self.compile_commands_parser.get_clang_flags_for_entry(p_entry, normalize_paths=False)
                                    clang_flags = self.compile_commands_parser.get_clang_flags_for_entry(p_entry, normalize_paths=True)
                                    tu_debug["used_proxy"] = True
                                if clang_flags:
                                    logger.info(f"ä½¿ç”¨ä»£ç† TU çš„ clang flags: {proxy_file} (key={proxy_key})")

                        raw_inc = set(p for _f, p in _extract_include_args(clang_flags_raw))
                        norm_inc = set(p for _f, p in _extract_include_args(clang_flags))
                        dropped_inc = sorted(raw_inc - norm_inc)
                        tu_debug["clang_flags_summary"] = _summarize_clang_flags(clang_flags)
                        tu_debug["clang_flags_raw_summary"] = _summarize_clang_flags(clang_flags_raw)
                        tu_debug["include_dirs_raw_count"] = len(raw_inc)
                        tu_debug["include_dirs_norm_count"] = len(norm_inc)
                        tu_debug["include_dirs_dropped_count"] = len(dropped_inc)
                        tu_debug["include_dirs_dropped_sample"] = dropped_inc[:20]
                        tu_debug["include_dirs_dropped_out_gen_count"] = sum(1 for p in dropped_inc if _is_out_gen_path(p))
                        attempt_debug["tu_context"] = tu_debug

                        if clang_flags:
                            cc_context_used = True
                            context_flags.extend(clang_flags)
                            # è®°å½•å·²æ·»åŠ çš„ include ç›®å½•ï¼Œé¿å…åç»­é‡å¤
                            j = 0
                            while j < len(clang_flags):
                                flag = clang_flags[j]
                                if flag == "-I" and j + 1 < len(clang_flags):
                                    added_dirs.add(clang_flags[j + 1])
                                    j += 2
                                    continue
                                if flag == "-isystem" and j + 1 < len(clang_flags):
                                    added_dirs.add(clang_flags[j + 1])
                                    j += 2
                                    continue
                                if flag.startswith("-I") and flag != "-I":
                                    added_dirs.add(flag[2:])
                                j += 1
                            logger.info(f"ä½¿ç”¨ compile_commands çš„ clang flags: {mapped_src} (args={len(clang_flags)})")
                    except Exception as e:
                        logger.warning(f"ä» compile_commands.json è·å– clang flags å¤±è´¥: {e}")
                        attempt_debug["tu_context_error"] = str(e)[:300]

            # 2) æ·»åŠ æ™ºèƒ½å¯»è·¯å‘ç°çš„ include è·¯å¾„ï¼ˆä»…ä½œä¸ºè¡¥å……ï¼‰
            for inc_dir in sorted(include_dirs, key=lambda p: str(p)):
                inc_dir_str = str(inc_dir)
                if inc_dir_str not in added_dirs:
                    context_flags.extend(["-I", inc_dir_str])
                    added_dirs.add(inc_dir_str)

            # 3) æ·»åŠ å¤´æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆé¡¹ç›®å†…ç›¸å¯¹ include çš„å…œåº•ï¼‰
            for h in sorted(header_files, key=lambda p: str(p)):
                h_dir_str = str(Path(h).parent)
                if h_dir_str not in added_dirs:
                    context_flags.extend(["-I", h_dir_str])
                    added_dirs.add(h_dir_str)

            # 4) æ·»åŠ æ‰€æœ‰æ”¶é›†åˆ°çš„å¤´æ–‡ä»¶æœç´¢è·¯å¾„ï¼ˆæœ€åå…œåº•ï¼Œé¿å…è¦†ç›– TU çš„ä¼˜å…ˆçº§ï¼‰
            # ä»…åœ¨æ²¡æœ‰ compile_commands ä¸Šä¸‹æ–‡æ—¶å¯ç”¨ï¼š
            # å¦åˆ™â€œå…¨å±€ include å¹¶é›†â€å®¹æ˜“æŠŠ libc/ç³»ç»Ÿå¤´æ–‡ä»¶è§£æåˆ°é”™è¯¯å®ç°ï¼ˆåŒåç¢°æ’ï¼‰ã€‚
            if not cc_context_used:
                for inc_dir in sorted(self.include_dirs, key=lambda p: str(p)):
                    inc_str = str(inc_dir)
                    if inc_str not in added_dirs:
                        context_flags.extend(["-I", inc_str])
                        added_dirs.add(inc_str)

            # ------------------------------------------------------------------
            # Execute bindgen with one or two language-mode attempts.
            # ------------------------------------------------------------------
            def _extract_missing_headers(stderr_text: str) -> List[str]:
                if not stderr_text:
                    return []
                missing = re.findall(r"'([^']+)' file not found", stderr_text)
                # Some clang variants omit quotes: "fatal error: foo/bar.h file not found"
                missing += re.findall(r"fatal error:\s*([^\s:]+)\s*file not found", stderr_text)
                if not missing:
                    return []
                seen = set()
                unique_missing: List[str] = []
                for f in missing:
                    f = (f or "").strip().strip('"').strip("'").strip("<>").strip()
                    if f and f not in seen:
                        seen.add(f)
                        unique_missing.append(f)
                return unique_missing

            def _needs_sched_param_fixup(stderr_text: str) -> bool:
                if not stderr_text:
                    return False
                return (
                    "field has incomplete type 'struct sched_param'" in stderr_text
                    or "unknown type name 'struct sched_param'" in stderr_text
                )

            def _needs_target_cpu_fixup(stderr_text: str) -> bool:
                if not stderr_text:
                    return False
                low = stderr_text.lower()
                return "unknown target cpu" in low

            def _strip_arch_flags(flags: List[str]) -> List[str]:
                """Drop -mcpu/-march/-mtune/... flags when host clang cannot understand the target CPU."""
                out: List[str] = []
                i = 0
                while i < len(flags):
                    f = flags[i]
                    if not isinstance(f, str):
                        out.append(f)
                        i += 1
                        continue
                    # Two-token forms
                    if f in {"-mcpu", "-march", "-mtune", "-mabi", "-mfpu", "-mfloat-abi"}:
                        i += 2
                        continue
                    # One-token forms / prefixes
                    if f.startswith((
                        "-mcpu=",
                        "-march=",
                        "-mtune=",
                        "-mabi=",
                        "-mfpu=",
                        "-mfloat-abi=",
                        "-mno-",
                        "-mno_",
                        "-msoft-float",
                        "-mhard-float",
                    )):
                        i += 1
                        continue
                    # Clang cc1 target-cpu forms: -Xclang -target-cpu -Xclang ck802
                    if f == "-Xclang" and i + 1 < len(flags):
                        nxt = flags[i + 1]
                        if nxt in {"-target-cpu", "-target-feature"}:
                            # Skip the pair plus the following -Xclang <value> if present
                            i += 2
                            if i + 1 < len(flags) and flags[i] == "-Xclang":
                                i += 2
                            continue
                    out.append(f)
                    i += 1
                return out

            # Some LiteOS/musl headers can fail with incomplete struct sched_param depending on include order.
            # Retry once by injecting <sched.h> early (safer than defining __NEED_struct_sched_param, which can
            # conflict with <sched.h> and trigger redefinition errors).
            unknown_fixup_rounds = 0
            max_unknown_fixup_rounds = 2
            arch_flags_stripped = False
            gen_ensure_tried = False

            for wrapper_round, force_sched_param in enumerate([False, True], start=1):
                if force_sched_param:
                    _write_wrapper(
                        force_need_struct_sched_param=True,
                        extra_system_includes=wrapper_extra_system_includes,
                        ordered_headers=wrapper_header_order,
                    )

                need_sched_param_retry = False
                while True:
                    best_failure: Optional[Dict[str, Any]] = None

                    for idx, m in enumerate(mode_attempts, start=1):
                        lang = m.get("lang")
                        clang_mode_flags = m.get("clang_flags") or []
                        cmd = bindgen_cmd_prefix + clang_mode_flags + context_flags

                        # include ç›®å½•è¯Šæ–­ï¼ˆç”¨äºå®šä½ out/.../gen ç¼ºå¤±ã€è·¯å¾„è¢« normalize ä¸¢å¼ƒç­‰ï¼‰
                        clang_argv = cmd[cmd.index("--") + 1:] if "--" in cmd else []
                        include_args = _extract_include_args(clang_argv)
                        unique_include_dirs = sorted({p for _f, p in include_args})
                        nonexistent_dirs = [p for p in unique_include_dirs if p and not Path(p).exists()]
                        out_gen_dirs = [p for p in unique_include_dirs if _is_out_gen_path(p)]

                        logger.info(
                            f"è¿è¡Œ bindgen[{idx}/{len(mode_attempts)}]: lang={lang} wrapper_round={wrapper_round} "
                            f"(include dirs={len(unique_include_dirs)}, missing dirs={len(nonexistent_dirs)}, out/gen dirs={len(out_gen_dirs)})"
                        )

                        result = subprocess.run(
                            cmd,
                            capture_output=True,
                            text=True,
                            timeout=60
                        )

                        attempt_entry: Dict[str, Any] = {
                            "lang": lang,
                            "wrapper_round": wrapper_round,
                            "wrapper_need_struct_sched_param": bool(force_sched_param),
                            "returncode": result.returncode,
                            "cpp_stdlib": m.get("cpp_stdlib"),
                        }
                        if result.stderr:
                            stderr_lines = result.stderr.splitlines()
                            attempt_entry["stderr_head"] = "\n".join(stderr_lines[:50])
                            attempt_entry["stderr_tail"] = "\n".join(stderr_lines[-50:])

                        attempt_entry["include_dirs"] = {
                            "unique_dir_count": len(unique_include_dirs),
                            "nonexistent_dir_count": len(nonexistent_dirs),
                            "nonexistent_dir_sample": nonexistent_dirs[:20],
                            "out_gen_dir_count": len(out_gen_dirs),
                            "out_gen_dir_existing_count": sum(1 for p in out_gen_dirs if Path(p).exists()),
                            "include_order_sample": include_args[:30],
                        }
                        attempt_debug["clang_mode"]["attempts"].append(attempt_entry)

                        if result.returncode == 0 and output_path.exists():
                            attempt_debug["bindgen_cmd_len"] = len(cmd)
                            attempt_debug["bindgen_cmd_head"] = cmd[:25]
                            attempt_debug["bindgen_returncode"] = result.returncode
                            if bindgen_debug:
                                attempt_debug["bindgen_cmd"] = cmd
                            if result.stderr:
                                attempt_debug["bindgen_stderr_head"] = attempt_entry.get("stderr_head")
                                attempt_debug["bindgen_stderr_tail"] = attempt_entry.get("stderr_tail")

                            self._postprocess_bindgen_output(output_path)
                            logger.info(f"bindgen æˆåŠŸç”Ÿæˆç±»å‹éª¨æ¶: {output_path} (lang={lang})")
                            return True, "", [], attempt_debug

                        error_msg = result.stderr if result.stderr else "Unknown error"
                        missing_files = _extract_missing_headers(error_msg)

                        failure = {
                            "cmd": cmd,
                            "lang": lang,
                            "error_msg": error_msg,
                            "missing_files": missing_files,
                            "nonexistent_dir_count": len(nonexistent_dirs),
                        }
                        if missing_files and (best_failure is None or not best_failure.get("missing_files")):
                            best_failure = failure
                        elif best_failure is None:
                            best_failure = failure

                        # Heuristic: if preferred mode is C and we see clear C++-only signals, try the C++ fallback.
                        if idx == 1 and not prefer_cxx:
                            cxx_signals = [
                                "_LIBCPP_BEGIN_NAMESPACE_STD",
                                "_LIBCPP_END_NAMESPACE_STD",
                                "std::",
                                "namespace ",
                                "class ",
                                "template<",
                                "expected unqualified-id",
                                "nullptr",
                                "operator new",
                                "C++",
                            ]

                            # Missing header with *no extension* is often a C++ standard header (e.g. <codecvt>, <map>, <memory>).
                            saw_probable_cxx_header = any(
                                ("/" not in h and "." not in h) for h in (missing_files or [])
                            )

                            if not any(s in error_msg for s in cxx_signals) and not saw_probable_cxx_header:
                                break

                    assert best_failure is not None
                    error_msg = best_failure.get("error_msg") or "Unknown error"
                    missing_files = best_failure.get("missing_files") or []

                    # Retry with sched_param fixup only when we saw that exact error and there are no missing headers.
                    if not force_sched_param and not missing_files and _needs_sched_param_fixup(error_msg):
                        need_sched_param_retry = True
                        break

                    # Some profiles (e.g. csky mini targets) export -mcpu=ck802 but miss a matching --target=,
                    # causing host libclang to reject the CPU. As a fallback, strip arch flags and retry.
                    if (not missing_files) and (not arch_flags_stripped) and _needs_target_cpu_fixup(error_msg):
                        has_target = any(
                            isinstance(f, str) and (f.startswith("--target=") or f == "-target")
                            for f in (context_flags or [])
                        )
                        if not has_target:
                            context_flags = _strip_arch_flags(context_flags)
                            arch_flags_stripped = True
                            wrapper_fixup_actions.append({
                                "action": "strip_arch_flags",
                                "reason": "unknown_target_cpu",
                            })
                            try:
                                attempt_debug["arch_flags_stripped"] = True
                            except Exception:
                                pass
                            continue

                    # Auto-fix: unknown type name usually means missing transitive includes or wrong include order.
                    if (not missing_files) and (unknown_fixup_rounds < max_unknown_fixup_rounds):
                        unknown_records = _extract_unknown_type_records(error_msg)
                        if unknown_records:
                            def _pick_best_pthread_include() -> str:
                                """
                                Pick a pthread.h that matches the current include context.

                                OpenHarmony ships multiple musl variants (porting/*) where <pthread.h> must be
                                consistent with <bits/alltypes.h>. If we accidentally include the generic
                                third_party/musl/include/pthread.h together with a porting/* alltypes.h, clang
                                will report many "unknown type name pthread_*" errors.
                                """
                                try:
                                    candidates: List[Path] = []
                                    # Prefer headers that already exist in current include dirs (most accurate).
                                    for d in (include_dirs or set()):
                                        try:
                                            ds = str(d).replace("\\", "/").lower()
                                        except Exception:
                                            continue
                                        if "pthread" not in ds and "musl" not in ds and "/usr/include" not in ds:
                                            continue
                                        cand = Path(d) / "pthread.h"
                                        if cand.exists():
                                            candidates.append(cand)

                                    # Fallback: well-known source-tree locations.
                                    if not candidates and self.ohos_root:
                                        ohos_root = Path(self.ohos_root)
                                        for cand in [
                                            ohos_root / "third_party" / "musl" / "porting" / "liteos_a" / "kernel" / "include" / "pthread.h",
                                            ohos_root / "third_party" / "musl" / "porting" / "liteos_a_newlib" / "kernel" / "include" / "pthread.h",
                                            ohos_root / "third_party" / "musl" / "porting" / "liteos_m" / "kernel" / "include" / "pthread.h",
                                            ohos_root / "third_party" / "musl" / "porting" / "liteos_m" / "user" / "include" / "pthread.h",
                                            ohos_root / "third_party" / "musl" / "porting" / "liteos_m_iccarm" / "kernel" / "include" / "pthread.h",
                                            ohos_root / "third_party" / "musl" / "porting" / "uniproton" / "kernel" / "include" / "pthread.h",
                                            ohos_root / "third_party" / "musl" / "porting" / "linux" / "user" / "include" / "pthread.h",
                                            ohos_root / "third_party" / "musl" / "include" / "pthread.h",
                                        ]:
                                            if cand.exists():
                                                candidates.append(cand)

                                    if not candidates:
                                        return "<pthread.h>"

                                    def _score(p: Path) -> int:
                                        s = str(p).replace("\\", "/").lower()
                                        score = 0
                                        if "/porting/" in s:
                                            score += 10_000
                                        if "/liteos_a/" in s:
                                            score += 800
                                        if "/liteos_m" in s:
                                            score += 600
                                        if "/uniproton" in s:
                                            score += 500
                                        if "/kernel/" in s:
                                            score += 120
                                        if "/user/" in s:
                                            score += 80
                                        if "/usr/include" in s:
                                            score += 40
                                        if s.endswith("/pthread.h"):
                                            score += 5
                                        return score

                                    best = max(candidates, key=_score)
                                    return f"\"{best}\""
                                except Exception:
                                    return "<pthread.h>"

                            pthread_inc = _pick_best_pthread_include()
                            sys_map = {
                                # Prefer a matching pthread.h (see _pick_best_pthread_include above).
                                "pthread_mutex_t": pthread_inc,
                                "pthread_mutexattr_t": pthread_inc,
                                "pthread_cond_t": pthread_inc,
                                "pthread_condattr_t": pthread_inc,
                                "pthread_attr_t": pthread_inc,
                                "pthread_rwlock_t": pthread_inc,
                                "pthread_rwlockattr_t": pthread_inc,
                                "pthread_barrier_t": pthread_inc,
                                "pthread_barrierattr_t": pthread_inc,
                                "pthread_spinlock_t": pthread_inc,
                                "pthread_key_t": pthread_inc,
                                "pthread_once_t": pthread_inc,
                                # Kernel-style types (often missing in partial build contexts)
                                "wait_queue_head_t": "<linux/wait.h>",
                                "poll_table": "<linux/poll.h>",
                                "gfp_t": "<linux/types.h>",
                                "refcount_t": "<linux/refcount.h>",
                                # LwIP (network stack) common typedefs
                                "u8_t": "<lwip/arch.h>",
                                "u16_t": "<lwip/arch.h>",
                                "u32_t": "<lwip/arch.h>",
                                "u64_t": "<lwip/arch.h>",
                                "s8_t": "<lwip/arch.h>",
                                "s16_t": "<lwip/arch.h>",
                                "s32_t": "<lwip/arch.h>",
                                "s64_t": "<lwip/arch.h>",
                                "err_t": "<lwip/err.h>",
                                "ip_addr_t": "<lwip/ip_addr.h>",
                                # Some projects use STATIC as a macro-like storage specifier.
                                # Define it via wrapper macros (handled in _write_wrapper).
                            }

                            added_any = False
                            for _f, t in unknown_records:
                                inc = sys_map.get(t)
                                if not inc and isinstance(t, str) and t.startswith("pthread_"):
                                    inc = pthread_inc
                                # Prefer absolute includes from the OpenHarmony tree to avoid sysroot/uapi collisions.
                                # Example: sysroot's <linux/wait.h> is UAPI and may not define wait_queue_head_t,
                                # while the kernel headers do.
                                if self.ohos_root:
                                    try:
                                        ohos_root = Path(self.ohos_root)
                                        if t == "wait_queue_head_t":
                                            for cand in [
                                                ohos_root / "kernel" / "linux" / "linux-5.10" / "include" / "linux" / "wait.h",
                                                ohos_root / "kernel" / "linux" / "linux-6.6" / "include" / "linux" / "wait.h",
                                            ]:
                                                if cand.exists():
                                                    inc = f"\"{cand}\""
                                                    break
                                        elif t == "gfp_t":
                                            for cand in [
                                                ohos_root / "kernel" / "linux" / "linux-5.10" / "include" / "linux" / "types.h",
                                                ohos_root / "kernel" / "linux" / "linux-6.6" / "include" / "linux" / "types.h",
                                            ]:
                                                if cand.exists():
                                                    inc = f"\"{cand}\""
                                                    break
                                        elif t == "poll_table":
                                            for cand in [
                                                ohos_root / "kernel" / "linux" / "linux-5.10" / "include" / "linux" / "poll.h",
                                                ohos_root / "kernel" / "linux" / "linux-6.6" / "include" / "linux" / "poll.h",
                                            ]:
                                                if cand.exists():
                                                    inc = f"\"{cand}\""
                                                    break
                                        elif t == "refcount_t":
                                            for cand in [
                                                ohos_root / "kernel" / "linux" / "linux-5.10" / "include" / "linux" / "refcount.h",
                                                ohos_root / "kernel" / "linux" / "linux-6.6" / "include" / "linux" / "refcount.h",
                                            ]:
                                                if cand.exists():
                                                    inc = f"\"{cand}\""
                                                    break
                                        elif t in {"u8_t", "u16_t", "u32_t", "u64_t", "s8_t", "s16_t", "s32_t", "s64_t"}:
                                            cand = ohos_root / "third_party" / "lwip" / "src" / "include" / "lwip" / "arch.h"
                                            if cand.exists():
                                                inc = f"\"{cand}\""
                                        elif t == "err_t":
                                            cand = ohos_root / "third_party" / "lwip" / "src" / "include" / "lwip" / "err.h"
                                            if cand.exists():
                                                inc = f"\"{cand}\""
                                        elif t == "ip_addr_t":
                                            cand = ohos_root / "third_party" / "lwip" / "src" / "include" / "lwip" / "ip_addr.h"
                                            if cand.exists():
                                                inc = f"\"{cand}\""
                                    except Exception:
                                        pass
                                if inc and inc not in wrapper_extra_system_includes:
                                    wrapper_extra_system_includes.append(inc)
                                    wrapper_fixup_actions.append({
                                        "action": "add_system_include",
                                        "include": inc,
                                        "type": t,
                                        "reason": "unknown_type_name",
                                    })
                                    added_any = True

                            current_headers = list(wrapper_header_order)
                            for f, t in unknown_records:
                                failing_basename = ""
                                try:
                                    failing_basename = Path(f).name
                                except Exception:
                                    failing_basename = ""
                                failing_header = None
                                if failing_basename:
                                    for h in current_headers:
                                        if h.name == failing_basename:
                                            failing_header = h
                                            break
                                defining_header = _find_defining_header_for_type(t, current_headers)
                                if defining_header and failing_header:
                                    current_headers, moved = _move_header_before(current_headers, defining_header, failing_header)
                                    if moved:
                                        wrapper_fixup_actions.append({
                                            "action": "reorder_headers",
                                            "move": str(defining_header),
                                            "before": str(failing_header),
                                            "type": t,
                                            "reason": "unknown_type_name",
                                        })
                                        added_any = True

                            if added_any:
                                wrapper_header_order = current_headers
                                unknown_fixup_rounds += 1
                                try:
                                    last_actions = wrapper_fixup_actions[-10:]
                                    logger.info(
                                        "Bindgen wrapper fixup applied "
                                        f"(round={unknown_fixup_rounds}, sys_includes={wrapper_extra_system_includes}): "
                                        f"{last_actions}"
                                    )
                                except Exception:
                                    pass
                                _write_wrapper(
                                    force_need_struct_sched_param=bool(force_sched_param),
                                    extra_system_includes=wrapper_extra_system_includes,
                                    ordered_headers=wrapper_header_order,
                                )
                                continue

                    # Store the most relevant failure attempt for downstream retries and reports.
                    attempt_debug["bindgen_cmd_len"] = len(best_failure.get("cmd") or [])
                    attempt_debug["bindgen_cmd_head"] = (best_failure.get("cmd") or [])[:25]
                    if bindgen_debug:
                        attempt_debug["bindgen_cmd"] = best_failure.get("cmd") or []

                    if missing_files:
                        # If headers are missing under out/.../gen/..., try to materialize generated artifacts via ninja once.
                        if (not gen_ensure_tried) and self._maybe_generate_ohos_out_gen_artifacts(attempt_debug):
                            gen_ensure_tried = True
                            try:
                                logger.info("å·²å°è¯•é€šè¿‡ ninja ç”Ÿæˆ out/.../gen/... ç”Ÿæˆç‰©ï¼Œé‡è¯• bindgen...")
                            except Exception:
                                pass
                            continue
                        logger.warning(f"bindgen å¤±è´¥: ç¼ºå°‘å¤–éƒ¨å¤´æ–‡ä»¶ {missing_files[:5]} (lang={best_failure.get('lang')})")
                        print(f"  ç¼ºå°‘çš„å¤´æ–‡ä»¶: {', '.join(missing_files[:10])}")
                        attempt_debug["missing_headers"] = list(missing_files)
                        attempt_debug["missing_headers_count"] = len(missing_files)
                        if not bindgen_debug:
                            tu_ctx = attempt_debug.get("tu_context") or {}
                            match_reason = (tu_ctx.get("match_info") or {}).get("reason") if isinstance(tu_ctx.get("match_info"), dict) else None
                            first_inc = (attempt_debug.get("clang_mode") or {}).get("attempts", [{}])[0].get("include_dirs", {})
                            print(
                                f"  [BindgenDiag] cc_loaded={bool(self.compile_commands_parser)} "
                                f"match={match_reason} include_dirs={first_inc.get('unique_dir_count')} "
                                f"missing_include_dirs={first_inc.get('nonexistent_dir_count')} out_gen_dirs={first_inc.get('out_gen_dir_count')}"
                            )
                        return False, error_msg, missing_files, attempt_debug

                    # Non-missing-header failures are very common (wrong TU context, sysroot not generated, C vs C++ mismatch).
                    # Emit a compact one-line diagnostic to make log triage easier.
                    if not bindgen_debug:
                        tu_ctx = attempt_debug.get("tu_context") or {}
                        match_reason = (tu_ctx.get("match_info") or {}).get("reason") if isinstance(tu_ctx.get("match_info"), dict) else None
                        clang_sum = (tu_ctx.get("clang_flags_summary") or {}) if isinstance(tu_ctx.get("clang_flags_summary"), dict) else {}
                        dropped = tu_ctx.get("include_dirs_dropped_count")
                        dropped_out_gen = tu_ctx.get("include_dirs_dropped_out_gen_count")
                        print(
                            f"  [BindgenDiag] cc_loaded={bool(self.compile_commands_parser)} match={match_reason} "
                            f"lang={best_failure.get('lang')} sysroot={clang_sum.get('sysroot')} target={clang_sum.get('target')} "
                            f"I={clang_sum.get('I')} isystem={clang_sum.get('isystem')} dropped_includes={dropped} "
                            f"dropped_out_gen={dropped_out_gen} host_suspect={bool(tu_ctx.get('used_proxy'))}"
                        )

                    logger.warning(f"bindgen å¤±è´¥: {error_msg[:300]}")
                    return False, error_msg, [], attempt_debug

                if need_sched_param_retry:
                    continue
                
        except subprocess.TimeoutExpired:
            logger.warning("bindgen è¶…æ—¶")
            attempt_debug["bindgen_timeout"] = True
            return False, "Timeout", [], attempt_debug
        except Exception as e:
            logger.error(f"bindgen å¼‚å¸¸: {e}")
            attempt_debug["bindgen_exception"] = str(e)[:500]
            return False, str(e), [], attempt_debug
        finally:
            # æ¸…ç† wrapper.h
            if wrapper_path.exists() and not keep_files:
                wrapper_path.unlink()
    
    def _postprocess_bindgen_output(self, types_file: Path):
        """åå¤„ç† bindgen è¾“å‡ºï¼Œæ¸…ç†ä¸å¿…è¦çš„å†…å®¹"""
        # Truth-mode: keep bindgen output untouched (no regex deletion, no enum const aliases).
        # This makes `types.rs` a pure bindgen artifact, and lets compile errors expose TU/input-closure gaps.
        if self._env_flag("C2R_TRUTH_MODE", "0") or (not self._env_flag("C2R_ENABLE_BINDGEN_POSTPROCESS", "1")):
            logger.debug("bindgen types.rs postprocess skipped (truth-mode or disabled)")
            return

        if not types_file.exists():
            return
        
        with open(types_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ç§»é™¤ç©ºçš„ extern "C" å—
        content = re.sub(r'extern\s+"C"\s*\{\s*\}', '', content)
        
        # ç§»é™¤ä¸å¿…è¦çš„ç³»ç»Ÿå¸¸é‡å®šä¹‰ï¼ˆè¿™äº›é€šå¸¸æ˜¯ä»ç³»ç»Ÿå¤´æ–‡ä»¶å¼•å…¥çš„ï¼‰
        # ä¾‹å¦‚ï¼špub const _STDINT_H: u32 = 1; ç­‰
        system_const_patterns = [
            r'pub const _\w+_H: u32 = \d+;',  # _STDINT_H, _FEATURES_H ç­‰
            r'pub const __\w+: u32 = \d+;',   # __GLIBC__, __WORDSIZE ç­‰
            r'pub const _\w+SOURCE\w*: u32 = \d+;',  # _POSIX_SOURCE ç­‰
            r'pub const __USE_\w+: u32 = \d+;',  # __USE_POSIX ç­‰
            r'pub const __GLIBC_USE_\w+: u32 = \d+;',  # __GLIBC_USE_xxx
            r'pub const __STDC_\w+: u32 = \d+;',  # __STDC_xxx
            r'pub const __GNU_\w+: u32 = \d+;',  # __GNU_xxx
            r'pub const __HAVE_\w+: u32 = \d+;',  # __HAVE_xxx
            r'pub const __LDOUBLE_\w+: u32 = \d+;',
            r'pub const __OFF_\w+: u32 = \d+;',
            r'pub const __INO_\w+: u32 = \d+;',
            r'pub const __RLIM_\w+: u32 = \d+;',
            r'pub const __STATFS_\w+: u32 = \d+;',
            r'pub const __KERNEL_\w+: u32 = \d+;',
            r'pub const __FD_SETSIZE: u32 = \d+;',
            r'pub const __TIMESIZE: u32 = \d+;',
            r'pub const __SYSCALL_\w+: u32 = \d+;',
            r'pub const __WORDSIZE\w*: u32 = \d+;',
            r'pub const __glibc_\w+: u32 = \d+;',
        ]
        for pattern in system_const_patterns:
            content = re.sub(pattern + r'\n?', '', content)
        
        # ç§»é™¤ä¸å¿…è¦çš„ç³»ç»Ÿç±»å‹åˆ«åï¼ˆä»¥ __ å¼€å¤´çš„å†…éƒ¨ç±»å‹ï¼‰
        # ä½†ä¿ç•™å¯èƒ½æœ‰ç”¨çš„ç±»å‹ï¼ˆå¦‚ __fsid_t ç»“æ„ä½“ï¼‰
        system_type_patterns = [
            r'pub type __u_char = [^;]+;\n?',
            r'pub type __u_short = [^;]+;\n?',
            r'pub type __u_int = [^;]+;\n?',
            r'pub type __u_long = [^;]+;\n?',
            r'pub type __int\d+_t = [^;]+;\n?',
            r'pub type __uint\d+_t = [^;]+;\n?',
            r'pub type __int_least\d+_t = [^;]+;\n?',
            r'pub type __uint_least\d+_t = [^;]+;\n?',
            r'pub type __quad_t = [^;]+;\n?',
            r'pub type __u_quad_t = [^;]+;\n?',
            r'pub type __intmax_t = [^;]+;\n?',
            r'pub type __uintmax_t = [^;]+;\n?',
            r'pub type __dev_t = [^;]+;\n?',
            r'pub type __uid_t = [^;]+;\n?',
            r'pub type __gid_t = [^;]+;\n?',
            r'pub type __ino\d*_t = [^;]+;\n?',
            r'pub type __mode_t = [^;]+;\n?',
            r'pub type __nlink_t = [^;]+;\n?',
            r'pub type __off\d*_t = [^;]+;\n?',
            r'pub type __pid_t = [^;]+;\n?',
            r'pub type __clock_t = [^;]+;\n?',
            r'pub type __rlim\d*_t = [^;]+;\n?',
            r'pub type __id_t = [^;]+;\n?',
            r'pub type __time_t = [^;]+;\n?',
            r'pub type __useconds_t = [^;]+;\n?',
            r'pub type __suseconds\d*_t = [^;]+;\n?',
            r'pub type __daddr_t = [^;]+;\n?',
            r'pub type __key_t = [^;]+;\n?',
            r'pub type __clockid_t = [^;]+;\n?',
            r'pub type __timer_t = [^;]+;\n?',
            r'pub type __blksize_t = [^;]+;\n?',
            r'pub type __blkcnt\d*_t = [^;]+;\n?',
            r'pub type __fsblkcnt\d*_t = [^;]+;\n?',
            r'pub type __fsfilcnt\d*_t = [^;]+;\n?',
            r'pub type __fsword_t = [^;]+;\n?',
            r'pub type __ssize_t = [^;]+;\n?',
            r'pub type __syscall_\w+_t = [^;]+;\n?',
            r'pub type __loff_t = [^;]+;\n?',
            r'pub type __caddr_t = [^;]+;\n?',
            r'pub type __intptr_t = [^;]+;\n?',
            r'pub type __socklen_t = [^;]+;\n?',
            r'pub type __sig_atomic_t = [^;]+;\n?',
        ]
        for pattern in system_type_patterns:
            content = re.sub(pattern, '', content)
        
        # ç§»é™¤é‡å¤çš„ #![allow(...)]
        seen_allows = set()
        lines = content.split('\n')
        filtered_lines = []
        for line in lines:
            if line.strip().startswith('#![allow'):
                if line.strip() not in seen_allows:
                    seen_allows.add(line.strip())
                    filtered_lines.append(line)
            else:
                filtered_lines.append(line)
        content = '\n'.join(filtered_lines)
        
        # ç¡®ä¿æ–‡ä»¶å¼€å¤´æœ‰å¿…è¦çš„ allow å±æ€§
        required_allows = [
            '#![allow(non_camel_case_types)]',
            '#![allow(non_snake_case)]',
            '#![allow(non_upper_case_globals)]',
            '#![allow(dead_code)]',
            '#![allow(unused)]',
        ]
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰è¿™äº›å±æ€§
        existing_allows = set()
        for line in content.split('\n'):
            if line.strip().startswith('#![allow'):
                existing_allows.add(line.strip())
        
        # æ·»åŠ ç¼ºå¤±çš„å±æ€§
        missing_allows = []
        for allow in required_allows:
            if allow not in existing_allows:
                missing_allows.append(allow)
        
        if missing_allows:
            # åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ ç¼ºå¤±çš„ allow å±æ€§
            # æ‰¾åˆ° bindgen çš„æ³¨é‡Šè¡Œä¹‹åæ’å…¥
            insert_pos = 0
            lines = content.split('\n')
            for i, line in enumerate(lines):
                if line.strip().startswith('/*') or line.strip().startswith('//'):
                    insert_pos = i + 1
                elif line.strip() and not line.strip().startswith('#'):
                    break
            
            for allow in reversed(missing_allows):
                lines.insert(insert_pos, allow)
            
            content = '\n'.join(lines)
        
        # ========== å¢å¼ºï¼šä¸ºæšä¸¾å˜ä½“ç”Ÿæˆå¸¸é‡åˆ«å ==========
        # C ä»£ç ä¸­æšä¸¾å€¼å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼ˆå¦‚ SOFTBUS_OKï¼‰ï¼Œä½† Rust éœ€è¦æšä¸¾å‰ç¼€ï¼ˆå¦‚ SoftBusErrNo::SOFTBUS_OKï¼‰
        # è¿™é‡Œæå–æšä¸¾å˜ä½“å¹¶ç”Ÿæˆå¸¸é‡åˆ«åï¼Œä½¿ç¿»è¯‘åçš„ä»£ç æ›´æ¥è¿‘ C çš„ä½¿ç”¨æ–¹å¼
        enum_aliases = self._generate_enum_const_aliases(content)
        if enum_aliases:
            # åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ æšä¸¾å¸¸é‡åˆ«å
            content = content.rstrip() + "\n\n" + "// ========== æšä¸¾å¸¸é‡åˆ«åï¼ˆæ–¹ä¾¿ C é£æ ¼çš„ç›´æ¥ä½¿ç”¨ï¼‰==========\n"
            content += enum_aliases
            print(f"  [åå¤„ç†] ç”Ÿæˆäº† {enum_aliases.count('pub const')} ä¸ªæšä¸¾å¸¸é‡åˆ«å")
        
        # æ¸…ç†å¤šä½™ç©ºè¡Œ
        content = re.sub(r'\n{3,}', '\n\n', content)
        
        with open(types_file, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def _generate_enum_const_aliases(self, content: str) -> str:
        """
        ä¸ºæšä¸¾å˜ä½“ç”Ÿæˆå¸¸é‡åˆ«å
        
        C ä»£ç ä¸­æšä¸¾å€¼å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼ˆå¦‚ SOFTBUS_OKï¼‰ï¼Œä½† Rust éœ€è¦æšä¸¾å‰ç¼€ã€‚
        è¿™ä¸ªå‡½æ•°æå–æšä¸¾å®šä¹‰ï¼Œå¹¶ä¸ºæ¯ä¸ªå˜ä½“ç”Ÿæˆå¯¹åº”çš„å¸¸é‡åˆ«åã€‚
        
        ä¾‹å¦‚ï¼š
        - enum SoftBusErrNo { SOFTBUS_OK = 0, ... }
        - ç”Ÿæˆ: pub const SOFTBUS_OK: i32 = SoftBusErrNo::SOFTBUS_OK as i32;
        
        Args:
            content: types.rs çš„å†…å®¹
        
        Returns:
            å¸¸é‡åˆ«åå®šä¹‰å­—ç¬¦ä¸²
        """
        aliases = []
        
        # åŒ¹é…æšä¸¾å®šä¹‰
        # pub enum EnumName { ... }
        enum_pattern = re.compile(
            r'pub\s+enum\s+(\w+)\s*\{([^}]+)\}',
            re.DOTALL
        )
        
        # åŒ¹é…æšä¸¾å˜ä½“
        # VARIANT_NAME = value, æˆ– VARIANT_NAME,
        variant_pattern = re.compile(
            r'(\w+)\s*(?:=\s*(-?\d+))?',
        )
        
        for enum_match in enum_pattern.finditer(content):
            enum_name = enum_match.group(1)
            enum_body = enum_match.group(2)
            
            # è·³è¿‡æŸäº›ç³»ç»Ÿæšä¸¾
            if enum_name.startswith('_') or enum_name.startswith('__'):
                continue
            
            # æå–å˜ä½“
            for variant_match in variant_pattern.finditer(enum_body):
                variant_name = variant_match.group(1)
                
                # è·³è¿‡ç©ºç™½åŒ¹é…å’Œæ— æ•ˆåç§°
                if not variant_name or variant_name in ('pub', 'impl', 'fn', 'struct'):
                    continue
                
                # åªä¸ºå…¨å¤§å†™çš„å˜ä½“ç”Ÿæˆåˆ«åï¼ˆè¿™é€šå¸¸æ˜¯ C é£æ ¼çš„å¸¸é‡å‘½åï¼‰
                if not variant_name.isupper() and '_' not in variant_name:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰åŒåçš„å¸¸é‡å®šä¹‰
                existing_const = re.search(rf'pub\s+const\s+{variant_name}\s*:', content)
                if existing_const:
                    continue
                
                # ç”Ÿæˆå¸¸é‡åˆ«å
                alias = f"pub const {variant_name}: i32 = {enum_name}::{variant_name} as i32;"
                aliases.append(alias)
        
        return '\n'.join(aliases)
    
    def _try_llm_bindgen_fallback(self, header_files: List[Path], output_path: Path) -> bool:
        """
        bindgen å¤±è´¥æ—¶çš„ LLM å…œåº•
        
        å°è¯•ä½¿ç”¨ LLM ä»å¤´æ–‡ä»¶ç”Ÿæˆ Rust ç±»å‹å®šä¹‰ã€‚
        ç»™ LLM æä¾›å®Œæ•´çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ä»¥ç¡®ä¿ç”Ÿæˆæ­£ç¡®çš„ FFI ç±»å‹ã€‚
        
        Args:
            header_files: å¤´æ–‡ä»¶åˆ—è¡¨
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        import os

        # æ£€æŸ¥æ˜¯å¦é…ç½®äº† LLM - å¤ç”¨ generation.py çš„é…ç½®
        llm_client = None
        try:
            from generate.generation import (
                USE_VLLM, VLLM_BASE_URL, VLLM_API_KEY, VLLM_MODEL_NAME, VLLM_REQUEST_TIMEOUT,
                EXTERNAL_API_BASE_URL, EXTERNAL_API_KEY, EXTERNAL_API_MODEL, EXTERNAL_API_TIMEOUT
            )
            if USE_VLLM:
                llm_model = VLLM_MODEL_NAME
                api_base = VLLM_BASE_URL
                api_key = VLLM_API_KEY
                timeout = VLLM_REQUEST_TIMEOUT
            else:
                llm_model = EXTERNAL_API_MODEL
                api_base = EXTERNAL_API_BASE_URL
                api_key = EXTERNAL_API_KEY
                timeout = EXTERNAL_API_TIMEOUT
        except ImportError:
            llm_model = os.environ.get("LLM_NAME", "qwen3_coder")
            api_base = os.environ.get("OPENAI_API_BASE", "http://localhost:8000/v1")
            api_key = "dummy"
            timeout = 600.0

        try:
            from openai import OpenAI
            llm_client = OpenAI(base_url=api_base, api_key=api_key, timeout=timeout)
            # æµ‹è¯•è¿æ¥
            llm_client.models.list()
        except Exception as e:
            logger.warning(f"LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼Œè·³è¿‡ LLM å…œåº•: {e}")
            return False
        
        try:
            from llm_signature_extractor import LLMBindgenFallback
            
            # è¯»å–æ‰€æœ‰å¤´æ–‡ä»¶å†…å®¹
            header_content = []
            for hf in header_files:
                try:
                    with open(hf, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                        header_content.append(f"// ========== {hf.name} ==========\n{content}")
                except Exception as e:
                    logger.warning(f"æ— æ³•è¯»å–å¤´æ–‡ä»¶ {hf}: {e}")
            
            if not header_content:
                logger.warning("æ²¡æœ‰å¯è¯»å–çš„å¤´æ–‡ä»¶ï¼Œè·³è¿‡ LLM å…œåº•")
                return False
            
            combined_headers = '\n\n'.join(header_content)
            
            # è°ƒç”¨ LLM ç”Ÿæˆç±»å‹å®šä¹‰
            print(f"  ğŸ¤– è°ƒç”¨ LLM ç”Ÿæˆç±»å‹å®šä¹‰ï¼ˆ{len(header_files)} ä¸ªå¤´æ–‡ä»¶ï¼‰...")
            fallback = LLMBindgenFallback(llm_client, llm_model)
            rust_types = fallback.generate_types(combined_headers)
            
            if rust_types and len(rust_types) > 100:  # ç¡®ä¿ç”Ÿæˆäº†æœ‰æ„ä¹‰çš„å†…å®¹
                # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                output_path.parent.mkdir(parents=True, exist_ok=True)
                
                # å†™å…¥ç”Ÿæˆçš„ç±»å‹å®šä¹‰
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(rust_types)
                
                logger.info(f"LLM bindgen å…œåº•æˆåŠŸï¼Œç”Ÿæˆäº† {len(rust_types)} å­—èŠ‚åˆ° {output_path}")
                return True
            else:
                logger.warning("LLM è¿”å›çš„ç±»å‹å®šä¹‰å†…å®¹ä¸è¶³")
                return False
                
        except ImportError as e:
            logger.warning(f"æ— æ³•å¯¼å…¥ LLM æ¨¡å—: {e}")
            return False
        except Exception as e:
            logger.error(f"LLM bindgen å…œåº•å¼‚å¸¸: {e}")
            return False
    
    def _create_placeholder_types(self, output_path: Path):
        """åˆ›å»ºå ä½ç±»å‹æ–‡ä»¶ï¼ˆä½¿ç”¨å¯é…ç½®çš„é¢„å®šä¹‰ï¼‰"""
        
        # åŸºç¡€å¤´éƒ¨
        header = '''//! Auto-generated type definitions
//! 
//! Note: bindgen failed to generate types. These are placeholder definitions.
//! External library types are declared as opaque types for compilation.
//! 
//! Source: config/predefines.py (self-adaptive learning enabled)

#![allow(non_camel_case_types)]
#![allow(non_snake_case)]
#![allow(non_upper_case_globals)]
#![allow(dead_code)]
#![allow(unused)]

use std::os::raw::*;

// Common C type aliases
pub type c_void = std::ffi::c_void;
pub type size_t = usize;
pub type ssize_t = isize;
pub type c_int = i32;
pub type c_uint = u32;
pub type c_long = i64;
pub type c_ulong = u64;
pub type c_char = i8;
pub type c_uchar = u8;
pub type c_short = i16;
pub type c_ushort = u16;

// Common integer types
pub type int8_t = i8;
pub type int16_t = i16;
pub type int32_t = i32;
pub type int64_t = i64;
pub type uint8_t = u8;
pub type uint16_t = u16;
pub type uint32_t = u32;
pub type uint64_t = u64;

// Boolean type
pub type BOOL = i32;
pub const TRUE: i32 = 1;
pub const FALSE: i32 = 0;
pub const NULL: *mut c_void = std::ptr::null_mut();

'''
        lines = [header]
        
        # ä»é…ç½®è·å–ç±»å‹å’Œå¸¸é‡
        if PREDEFINES_AVAILABLE:
            manager = get_predefine_manager(enable_ohos=True)
            
            # æ·»åŠ ç±»å‹å®šä¹‰
            lines.append("// ============================================================")
            lines.append("// Type Definitions (from config/predefines.py)")
            lines.append("// ============================================================")
            lines.append("")
            
            for name, definition in sorted(manager.get_all_types().items()):
                lines.append(definition)
                lines.append("")
            
            # æ·»åŠ å¸¸é‡å®šä¹‰
            lines.append("// ============================================================")
            lines.append("// Constants (from config/predefines.py)")
            lines.append("// ============================================================")
            lines.append("")
            
            # è·³è¿‡å·²åœ¨ header ä¸­å®šä¹‰çš„å¸¸é‡ï¼Œé¿å…é‡å¤å®šä¹‰
            header_defined_constants = {"TRUE", "FALSE", "NULL"}
            
            for name, rust_type, value in sorted(manager.get_all_constants(), key=lambda x: x[0]):
                if name not in header_defined_constants:
                    lines.append(f"pub const {name}: {rust_type} = {value};")
            
            lines.append("")
        else:
            # å›é€€åˆ°ç¡¬ç¼–ç ï¼ˆå…¼å®¹æ€§ï¼‰
            lines.append(self._get_fallback_placeholder_content())
        
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
    
    def _get_fallback_placeholder_content(self) -> str:
        """è·å–å›é€€çš„å ä½å†…å®¹ï¼ˆå½“é…ç½®æ¨¡å—ä¸å¯ç”¨æ—¶ï¼‰"""
        return '''
// ============================================================
// POSIX Error Codes
// ============================================================
pub const EINVAL: i32 = 22;
pub const ENOMEM: i32 = 12;
pub const ENOENT: i32 = 2;
pub const EEXIST: i32 = 17;
pub const EAGAIN: i32 = 11;
pub const ETIMEDOUT: i32 = 110;

// ============================================================
// POSIX/System Types
// ============================================================
#[repr(C)]
pub struct pthread_mutex_t { _opaque: [u8; 40] }
#[repr(C)]
pub struct pthread_cond_t { _opaque: [u8; 48] }
pub type pthread_t = usize;
pub type atomic_bool = u8;
pub type atomic_int = i32;

#[repr(C)]
pub struct file { _opaque: [u8; 0] }
#[repr(C)]
pub struct FILE { _opaque: [u8; 0] }
pub type time_t = i64;
pub type off_t = i64;
pub type mode_t = u32;

'''
    
    def detect_and_generate_missing_symbols(
        self,
        source_files: List[Path],
        types_file: Path
    ):
        """
        æ£€æµ‹æºä»£ç ä¸­ä½¿ç”¨ä½†éª¨æ¶ä¸­æœªå®šä¹‰çš„å¤–éƒ¨ç¬¦å·ï¼Œå¹¶ç”Ÿæˆå ä½å£°æ˜
        
        åˆ†æ C æºä»£ç ä¸­çš„ï¼š
        1. å‡½æ•°è°ƒç”¨ - ç”Ÿæˆ extern "C" å ä½
        2. å®å¸¸é‡ä½¿ç”¨ - ç”Ÿæˆ pub const å ä½
        
        Args:
            source_files: C æºæ–‡ä»¶åˆ—è¡¨
            types_file: types.rs æ–‡ä»¶è·¯å¾„
        """
        # 1. è¯»å–ç°æœ‰çš„ types.rsï¼Œæå–å·²å®šä¹‰çš„ç¬¦å·
        existing_symbols = set()
        if types_file.exists():
            with open(types_file, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            # æå–å·²å®šä¹‰çš„ç±»å‹ã€å¸¸é‡ã€å‡½æ•°
            existing_symbols.update(re.findall(r'pub\s+(?:type|struct|enum|const|fn)\s+(\w+)', content))
            existing_symbols.update(re.findall(r'type\s+(\w+)\s*=', content))
        
        # 2. åˆ†ææºä»£ç ï¼Œæ”¶é›†ä½¿ç”¨çš„ç¬¦å·
        used_functions = set()
        used_constants = set()

        for src_file in source_files:
            try:
                # ä¿®å¤ï¼šä½¿ç”¨é¢„å¤„ç†åçš„ä»£ç ï¼ˆä¸é˜¶æ®µ B/C ä¿æŒä¸€è‡´ï¼‰
                # å¦‚æœ .c æ–‡ä»¶åªæœ‰ #include "xxx.h"ï¼ŒåŸå§‹æ–‡ä»¶å‡ ä¹ä¸ºç©º
                source_code = None
                try:
                    safe_name = self._get_safe_module_name(src_file)
                    rec = (getattr(self, "_tu_context_files", {}) or {}).get(safe_name)
                    pre_path = (rec or {}).get("preprocessed_file") if isinstance(rec, dict) else None
                    if pre_path:
                        p = Path(str(pre_path)).expanduser()
                        if p.exists():
                            source_code = p.read_text(encoding="utf-8", errors="ignore")
                except Exception:
                    source_code = None

                if not source_code:
                    source_code = self.preprocess_source(src_file)

                # æå–å‡½æ•°è°ƒç”¨ï¼ˆç®€å•å¯å‘å¼ï¼‰
                # åŒ¹é…æ¨¡å¼ï¼šidentifier( ä½†ä¸æ˜¯å…³é”®å­—
                func_calls = re.findall(r'\b([A-Z][A-Za-z0-9_]*)\s*\(', source_code)
                func_calls += re.findall(r'\b([a-z][A-Za-z0-9_]*_[A-Za-z0-9_]*)\s*\(', source_code)  # è›‡å½¢å‘½å
                used_functions.update(func_calls)

                # æå–å¯èƒ½çš„å¸¸é‡ä½¿ç”¨ï¼ˆå¤§å†™å­—æ¯å‘½åï¼‰
                # åŒ¹é…æ¨¡å¼ï¼šå…¨å¤§å†™æˆ–å¤§å†™å¼€å¤´çš„æ ‡è¯†ç¬¦
                constants = re.findall(r'\b([A-Z][A-Z0-9_]{2,})\b', source_code)
                used_constants.update(constants)

            except Exception as e:
                logger.warning(f"åˆ†ææºæ–‡ä»¶ {src_file.name} å¤±è´¥: {e}")
        
        # 3. è¿‡æ»¤æ‰å·²å­˜åœ¨çš„å’Œæ˜æ˜¾çš„ç³»ç»Ÿç¬¦å·
        c_keywords = {'NULL', 'TRUE', 'FALSE', 'EOF', 'SEEK_SET', 'SEEK_CUR', 'SEEK_END'}
        existing_constants = existing_symbols | c_keywords
        
        # è¿‡æ»¤å¤–éƒ¨å‡½æ•°
        external_functions = used_functions - existing_symbols
        # C æ ‡å‡†åº“å‡½æ•°çš„æ­£ç¡® FFI ç­¾åï¼ˆç”¨äºè‡ªåŠ¨ç”Ÿæˆï¼‰
        # è¿™äº›å‡½æ•°åœ¨ C ä»£ç ä¸­ç»å¸¸ä½¿ç”¨ï¼Œéœ€è¦åœ¨ Rust ä¸­æœ‰æ­£ç¡®çš„ FFI å£°æ˜
        c_stdlib_signatures = {
            # å†…å­˜ç®¡ç†
            'malloc': 'pub fn malloc(size: usize) -> *mut core::ffi::c_void',
            'free': 'pub fn free(ptr: *mut core::ffi::c_void)',
            'calloc': 'pub fn calloc(nmemb: usize, size: usize) -> *mut core::ffi::c_void',
            'realloc': 'pub fn realloc(ptr: *mut core::ffi::c_void, size: usize) -> *mut core::ffi::c_void',
            # å†…å­˜æ“ä½œ
            'memcpy': 'pub fn memcpy(dest: *mut core::ffi::c_void, src: *const core::ffi::c_void, n: usize) -> *mut core::ffi::c_void',
            'memset': 'pub fn memset(s: *mut core::ffi::c_void, c: i32, n: usize) -> *mut core::ffi::c_void',
            'memmove': 'pub fn memmove(dest: *mut core::ffi::c_void, src: *const core::ffi::c_void, n: usize) -> *mut core::ffi::c_void',
            'memcmp': 'pub fn memcmp(s1: *const core::ffi::c_void, s2: *const core::ffi::c_void, n: usize) -> i32',
            # å­—ç¬¦ä¸²æ“ä½œ
            'strcpy': 'pub fn strcpy(dest: *mut i8, src: *const i8) -> *mut i8',
            'strncpy': 'pub fn strncpy(dest: *mut i8, src: *const i8, n: usize) -> *mut i8',
            'strcmp': 'pub fn strcmp(s1: *const i8, s2: *const i8) -> i32',
            'strncmp': 'pub fn strncmp(s1: *const i8, s2: *const i8, n: usize) -> i32',
            'strlen': 'pub fn strlen(s: *const i8) -> usize',
            'strcat': 'pub fn strcat(dest: *mut i8, src: *const i8) -> *mut i8',
            'strncat': 'pub fn strncat(dest: *mut i8, src: *const i8, n: usize) -> *mut i8',
            'strdup': 'pub fn strdup(s: *const i8) -> *mut i8',
            'strstr': 'pub fn strstr(haystack: *const i8, needle: *const i8) -> *mut i8',
            'strchr': 'pub fn strchr(s: *const i8, c: i32) -> *mut i8',
            'strrchr': 'pub fn strrchr(s: *const i8, c: i32) -> *mut i8',
            # I/O
            'printf': 'pub fn printf(format: *const i8, ...) -> i32',
            'sprintf': 'pub fn sprintf(str: *mut i8, format: *const i8, ...) -> i32',
            'snprintf': 'pub fn snprintf(str: *mut i8, size: usize, format: *const i8, ...) -> i32',
            'fprintf': 'pub fn fprintf(stream: *mut core::ffi::c_void, format: *const i8, ...) -> i32',
            'sscanf': 'pub fn sscanf(str: *const i8, format: *const i8, ...) -> i32',
            # æ•°å€¼è½¬æ¢
            'atoi': 'pub fn atoi(nptr: *const i8) -> i32',
            'atol': 'pub fn atol(nptr: *const i8) -> i64',
            'atof': 'pub fn atof(nptr: *const i8) -> f64',
            'strtol': 'pub fn strtol(nptr: *const i8, endptr: *mut *mut i8, base: i32) -> i64',
            'strtoul': 'pub fn strtoul(nptr: *const i8, endptr: *mut *mut i8, base: i32) -> u64',
            # å…¶ä»–
            'abs': 'pub fn abs(x: i32) -> i32',
            'exit': 'pub fn exit(status: i32) -> !',
            'abort': 'pub fn abort() -> !',
            'sleep': 'pub fn sleep(seconds: u32) -> u32',
            'usleep': 'pub fn usleep(usec: u32) -> i32',
        }
        
        # æ£€æµ‹ä½¿ç”¨äº†å“ªäº› C æ ‡å‡†åº“å‡½æ•°ï¼ˆéœ€è¦æ·»åŠ åˆ° types.rsï¼‰
        used_stdlib_funcs = used_functions & set(c_stdlib_signatures.keys())
        
        # è¿‡æ»¤æ‰å·²ç»æœ‰æ­£ç¡®ç­¾åçš„æ ‡å‡†åº“å‡½æ•°ï¼Œå› ä¸ºå®ƒä»¬ä¼šå•ç‹¬å¤„ç†
        external_functions = external_functions - set(c_stdlib_signatures.keys())
        
        # è¿‡æ»¤å¤–éƒ¨å¸¸é‡
        external_constants = used_constants - existing_constants
        # æ’é™¤æ˜æ˜¾ä¸æ˜¯å¸¸é‡çš„ï¼ˆå¦‚ç±»å‹åï¼‰
        external_constants = {c for c in external_constants 
                            if len(c) >= 3 and not c.startswith('_')}
        
        # 4. ç”Ÿæˆå ä½å£°æ˜å¹¶è¿½åŠ åˆ° types.rs
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•éœ€è¦æ·»åŠ çš„å†…å®¹
        has_content_to_add = external_functions or external_constants or used_stdlib_funcs
        
        if has_content_to_add:
            additions = [
                "",
                "// ============================================================",
                "// Auto-detected External Symbols",
                "// These symbols were detected in C source code.",
                "// ============================================================",
                "",
            ]
            
            # ç”Ÿæˆå¸¸é‡å ä½
            if external_constants:
                additions.append("// --- External Constants (detected from source) ---")
                # å¸¸è§çš„ OpenHarmony/HDF å¸¸é‡å‰ç¼€æ˜ å°„
                const_prefixes = {
                    'HDF_': ('i32', '0'),
                    'LOS_': ('u32', '0'),
                    'SOFTBUS_': ('i32', '0'),
                    'AUDIO_': ('i32', '0'),
                    'HNP_': ('i32', '0'),
                    'E': ('i32', '0'),  # EINVAL, ENOMEM ç­‰
                    'O_': ('u32', '0'),  # O_RDONLY ç­‰
                    'S_': ('u32', '0'),  # S_IRUSR ç­‰
                }
                
                for const in sorted(external_constants)[:50]:  # é™åˆ¶æ•°é‡
                    const_type = 'i32'
                    const_val = '0'
                    for prefix, (ctype, cval) in const_prefixes.items():
                        if const.startswith(prefix):
                            const_type = ctype
                            const_val = cval
                            break
                    # è·³è¿‡å·²åœ¨å ä½ä¸­å®šä¹‰çš„å¸¸é‡
                    if const not in existing_symbols:
                        additions.append(f"pub const {const}: {const_type} = {const_val};  // placeholder")
                additions.append("")
            
            # ç”Ÿæˆ C æ ‡å‡†åº“å‡½æ•°çš„æ­£ç¡® FFI å£°æ˜
            if used_stdlib_funcs:
                # è¿‡æ»¤æ‰å·²ç»å­˜åœ¨äº types.rs ä¸­çš„å‡½æ•°
                stdlib_to_add = {f for f in used_stdlib_funcs if f not in existing_symbols}
                if stdlib_to_add:
                    additions.append("// --- C Standard Library Functions (with correct signatures) ---")
                    additions.append("extern \"C\" {")
                    for func in sorted(stdlib_to_add):
                        if func in c_stdlib_signatures:
                            additions.append(f"    {c_stdlib_signatures[func]};")
                    additions.append("}")
                    additions.append("")
            
            # ç”Ÿæˆå…¶ä»–å¤–éƒ¨å‡½æ•°å ä½ï¼ˆextern "C" å—ï¼‰
            if external_functions:
                additions.append("// --- Project-specific External Functions (placeholders) ---")
                additions.append("// NOTE: These are declared as extern \"C\" for FFI compatibility.")
                additions.append("// The actual signatures may need to be corrected manually.")
                additions.append("extern \"C\" {")
                
                for func in sorted(external_functions)[:30]:  # é™åˆ¶æ•°é‡
                    # ç®€å•çš„å‡½æ•°ç­¾åå ä½ï¼ˆè¿”å› i32ï¼Œæ— å‚æ•°ï¼‰
                    additions.append(f"    pub fn {func}() -> i32;  // placeholder - actual signature may differ")
                
                additions.append("}")
                additions.append("")
            
            # è¿½åŠ åˆ° types.rs
            with open(types_file, 'a', encoding='utf-8') as f:
                f.write('\n'.join(additions))
            
            stdlib_count = len(used_stdlib_funcs) if used_stdlib_funcs else 0
            logger.info(f"è‡ªåŠ¨æ£€æµ‹å¹¶ç”Ÿæˆ {len(external_constants)} ä¸ªå¸¸é‡ + {stdlib_count} ä¸ªæ ‡å‡†åº“å‡½æ•° + {len(external_functions)} ä¸ªå¤–éƒ¨å‡½æ•°å ä½")
    
    # =========================================================================
    # é˜¶æ®µ B: å…¨å±€çŠ¶æ€å±‚ (The State Layer)
    # =========================================================================
    
    def extract_variables_with_treesitter(
        self, 
        source_code: str, 
        file_name: str = ""
    ) -> List[VariableInfo]:
        """
        ä½¿ç”¨ Tree-sitter ç²¾ç¡®æå–å…¨å±€å˜é‡å’Œå‡½æ•°å†… static å˜é‡
        
        å‚è€ƒ PTRMAPPER çš„å…¨å±€æŒ‡é’ˆåˆ†æå’Œ EvoC2Rust çš„å˜é‡å°è£…
        
        Args:
            source_code: C/C++ æºä»£ç 
            file_name: æ–‡ä»¶åï¼ˆç”¨äºç”Ÿæˆå”¯ä¸€å˜é‡åï¼‰
        
        Returns:
            å˜é‡ä¿¡æ¯åˆ—è¡¨
        """
        variables = []
        seen_names = set()
        
        try:
            tree = cpp_parser.parse(bytes(source_code, 'utf-8'))
            root = tree.root_node
            
            # å…³é”®æ£€æŸ¥ï¼šç»Ÿè®¡ ERROR èŠ‚ç‚¹æ•°é‡
            # å‚è€ƒ EvoC2Rust: å¦‚æœæœ‰å¤ªå¤š ERRORï¼Œè¯´æ˜è§£æä¸å¯é 
            error_count = self._count_parse_errors(root)
            total_nodes = len(source_code) // 50  # ç²—ç•¥ä¼°è®¡èŠ‚ç‚¹æ•°
            error_rate = error_count / max(total_nodes, 1)
            
            if error_count > 10 or error_rate > 0.1:
                logger.warning(
                    f"Tree-sitter è§£æè´¨é‡å·®: {file_name} æœ‰ {error_count} ä¸ª ERROR èŠ‚ç‚¹ "
                    f"(é”™è¯¯ç‡ {error_rate:.1%})ï¼Œè·³è¿‡æ­¤æ–‡ä»¶çš„å˜é‡æå–"
                )
                # å½“è§£æè´¨é‡å·®æ—¶ï¼Œç›´æ¥è¿”å›ç©ºåˆ—è¡¨ï¼Œä¸è¦æå–åƒåœ¾æ•°æ®
                return []
            
            # 1. æå–é¡¶å±‚å…¨å±€å˜é‡å£°æ˜
            global_vars = self._extract_global_declarations(root, source_code)
            for var in global_vars:
                if not getattr(var, "origin_file", None):
                    var.origin_file = file_name or None
                # éªŒè¯å˜é‡åæ˜¯æœ‰æ•ˆçš„ C æ ‡è¯†ç¬¦
                if var.name and self._is_valid_c_identifier(var.name) and var.name not in seen_names:
                    variables.append(var)
                    seen_names.add(var.name)
            
            # 2. æ·±å…¥å‡½æ•°ä½“æå– static å˜é‡å¹¶è¿›è¡Œ"å˜é‡æå‡"
            lifted_vars = self._lift_function_static_vars(root, source_code, file_name)
            for var in lifted_vars:
                if not getattr(var, "origin_file", None):
                    var.origin_file = file_name or None
                if var.name and self._is_valid_c_identifier(var.name) and var.name not in seen_names:
                    variables.append(var)
                    seen_names.add(var.name)
            
        except Exception as e:
            logger.warning(f"Tree-sitter è§£æå¤±è´¥: {e}ï¼Œå›é€€åˆ°æ­£åˆ™åŒ¹é…")
            # å›é€€åˆ°æ­£åˆ™åŒ¹é…
            regex_vars = self._extract_variables_with_regex(source_code)
            for var in regex_vars:
                if not getattr(var, "origin_file", None):
                    var.origin_file = file_name or None
                if var.name and self._is_valid_c_identifier(var.name) and var.name not in seen_names:
                    variables.append(var)
                    seen_names.add(var.name)
        
        return variables
    
    def _is_valid_c_identifier(self, name: str) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ C æ ‡è¯†ç¬¦
        
        æœ‰æ•ˆæ ‡è¯†ç¬¦ï¼šä»¥å­—æ¯æˆ–ä¸‹åˆ’çº¿å¼€å¤´ï¼ŒåªåŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿
        """
        import re
        if not name or len(name) > 200:
            return False
        # å¿…é¡»æ˜¯ ASCII å­—ç¬¦
        if not all(ord(c) < 128 for c in name):
            return False
        # å¿…é¡»åŒ¹é… C æ ‡è¯†ç¬¦è§„åˆ™
        return bool(re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*$', name))
    
    def _escape_rust_keyword(self, name: str) -> str:
        """
        è½¬ä¹‰ Rust ä¿ç•™å­—
        
        æ³¨æ„ï¼šself, Self, super, crate æ˜¯ç‰¹æ®Šå…³é”®å­—ï¼Œä¸èƒ½ç”¨ r# è½¬ä¹‰
        """
        # ç‰¹æ®Šå…³é”®å­—ï¼šä¸èƒ½ç”¨ r# è½¬ä¹‰ï¼Œéœ€è¦é‡å‘½å
        special_keywords = {'self', 'Self', 'super', 'crate'}
        if name in special_keywords:
            return f"{name}_"
        
        # æ™®é€šä¿ç•™å­—ï¼šå¯ä»¥ç”¨ r# è½¬ä¹‰
        rust_keywords = {
            'type', 'match', 'fn', 'mod', 'use', 'impl', 'trait', 'struct', 'enum',
            'in', 'ref', 'mut', 'const', 'static', 'priv', 'pub', 'let', 'loop',
            'while', 'for', 'if', 'else', 'return', 'break', 'continue', 'as',
            'where', 'async', 'await', 'dyn', 'move', 'box', 'extern', 'unsafe',
            'true', 'false', 'abstract', 'become', 'do', 'final', 'macro',
            'override', 'typeof', 'unsized', 'virtual', 'yield', 'try'
        }
        if name in rust_keywords:
            return f"r#{name}"
        
        return name
    
    def _extract_global_declarations(self, root_node, source_code: str) -> List[VariableInfo]:
        """æå–é¡¶å±‚å…¨å±€å˜é‡å£°æ˜"""
        variables = []
        
        # éå†é¡¶å±‚èŠ‚ç‚¹
        for child in root_node.children:
            if child.type == 'declaration':
                var_info = self._parse_declaration(child, source_code)
                if var_info:
                    variables.extend(var_info)
        
        return variables
    
    def _parse_declaration(self, node, source_code: str) -> List[VariableInfo]:
        """è§£æå£°æ˜èŠ‚ç‚¹

        å¢å¼ºåŠŸèƒ½ï¼ˆ2025-12-23ï¼‰ï¼š
        - æ”¯æŒ extern å˜é‡è¯†åˆ«
        - extern å˜é‡ä¼šç”Ÿæˆ extern "C" å—å£°æ˜è€Œé static mut
        """
        variables = []

        try:
            decl_text = source_code[node.start_byte:node.end_byte]
            decl_tokens = decl_text.split('=')[0].split() if '=' in decl_text else decl_text.split()

            # æ£€æŸ¥æ˜¯å¦æ˜¯ static å£°æ˜
            is_static = 'static' in decl_tokens[:3]

            # â˜… æ£€æŸ¥æ˜¯å¦æ˜¯ extern å£°æ˜
            is_extern = 'extern' in decl_tokens[:3]

            # è·³è¿‡ extern å‡½æ•°å£°æ˜ï¼ˆæ²¡æœ‰å‡½æ•°ä½“çš„å‡½æ•°åŸå‹ï¼‰
            # å‡½æ•°å£°æ˜ä¼šåœ¨å…¶ä»–åœ°æ–¹å¤„ç†
            if is_extern and '(' in decl_text:
                return variables

            # æå–ç±»å‹å’Œå˜é‡å
            # ä½¿ç”¨ Tree-sitter æŸ¥æ‰¾ declarator
            for child in node.children:
                if child.type in ['init_declarator', 'declarator', 'pointer_declarator', 'array_declarator']:
                    var_name = self._extract_declarator_name(child, source_code)
                    if var_name:
                        c_type = self._extract_type(node, source_code)
                        is_pointer = '*' in decl_text.split(var_name)[0] if var_name in decl_text else False
                        is_array = '[' in decl_text

                        # æ”¶é›†ç±»å‹ï¼ˆç”¨äºåç»­ç”Ÿæˆç¼ºå¤±çš„ä¸é€æ˜ç»“æ„ä½“ï¼‰
                        if TYPE_UTILS_AVAILABLE:
                            base_type = extract_base_type(c_type)
                            # è¿‡æ»¤æ‰åŸºç¡€ç±»å‹
                            if base_type and base_type not in ['int', 'char', 'void', 'float', 'double', 'long', 'short', '_Bool', 'bool', 'unsigned', 'signed', 'size_t', 'ssize_t', 'ptrdiff_t', 'intptr_t', 'uintptr_t', 'uint8_t', 'uint16_t', 'uint32_t', 'uint64_t', 'int8_t', 'int16_t', 'int32_t', 'int64_t']:
                                self.collected_custom_types.add(base_type)

                        rust_type = self._c_type_to_rust(c_type, is_pointer, is_array)

                        # â˜… ä¸º extern å˜é‡ç”Ÿæˆä¸åŒçš„å£°æ˜
                        if is_extern:
                            rust_decl = self._generate_extern_variable_declaration(var_name, rust_type, is_pointer)
                        else:
                            rust_decl = self._generate_rust_static_declaration(var_name, rust_type, is_pointer, is_array)

                        variables.append(VariableInfo(
                            name=var_name,
                            c_type=c_type,
                            rust_type=rust_type,
                            rust_declaration=rust_decl,
                            is_static=is_static,
                            is_extern=is_extern,
                            is_pointer=is_pointer,
                            is_array=is_array
                        ))
        except Exception as e:
            logger.debug(f"è§£æå£°æ˜å¤±è´¥: {e}")

        return variables

    def _generate_extern_variable_declaration(self, name: str, rust_type: str, is_pointer: bool) -> str:
        """ä¸º extern å˜é‡ç”Ÿæˆ Rust å£°æ˜

        extern å˜é‡åº”æ”¾åœ¨ extern "C" å—ä¸­ï¼Œè€Œéæ™®é€šçš„ static mutã€‚

        Args:
            name: å˜é‡å
            rust_type: Rust ç±»å‹
            is_pointer: æ˜¯å¦ä¸ºæŒ‡é’ˆ

        Returns:
            extern "C" å—å£°æ˜å­—ç¬¦ä¸²
        """
        safe_name = self._escape_rust_keyword(name)

        # extern å˜é‡ä¸éœ€è¦åˆå§‹åŒ–å™¨ï¼Œä½¿ç”¨ extern "C" å—
        return f'extern "C" {{ pub static mut {safe_name}: {rust_type}; }}'
    
    def _extract_declarator_name(self, node, source_code: str) -> Optional[str]:
        """ä» declarator èŠ‚ç‚¹æå–å˜é‡å"""
        if node.type == 'identifier':
            return source_code[node.start_byte:node.end_byte]
        
        for child in node.children:
            name = self._extract_declarator_name(child, source_code)
            if name:
                return name
        
        return None
    
    def _extract_type(self, decl_node, source_code: str) -> str:
        """æå–ç±»å‹"""
        type_parts = []
        for child in decl_node.children:
            if child.type in ['type_identifier', 'primitive_type', 'sized_type_specifier']:
                type_text = source_code[child.start_byte:child.end_byte]
                # éªŒè¯ç±»å‹åæ˜¯æœ‰æ•ˆçš„ï¼ˆåªåŒ…å« ASCII å­—ç¬¦ï¼‰
                if type_text and all(ord(c) < 128 for c in type_text):
                    # è¿‡æ»¤æ˜æ˜¾çš„åƒåœ¾
                    if not any(bad in type_text for bad in ['\n', '\r', '/*', '*/', '//', ';']):
                        type_parts.append(type_text)
            elif child.type in ['struct_specifier', 'enum_specifier', 'union_specifier']:
                # å¤„ç†ç±»ä¼¼ `struct Foo bar;` è¿™ç±»å£°æ˜ï¼šç±»å‹åä¸åœ¨ type_identifier é¡¶å±‚ï¼Œè€Œåœ¨ *_specifier å†…éƒ¨
                # ä¸å¤„ç†åŒ¿å struct/enum/unionï¼ˆæ—  nameï¼‰ï¼Œè¿™ç±»é€šå¸¸éœ€è¦ bindgen æ‰èƒ½å®Œæ•´è¿˜åŸ
                name_node = None
                try:
                    name_node = child.child_by_field_name("name")
                except Exception:
                    name_node = None

                if name_node is None:
                    # å…œåº•ï¼šåœ¨å­èŠ‚ç‚¹é‡Œæ‰¾ç±»å‹å
                    for sub in getattr(child, "children", []) or []:
                        if sub.type in ("type_identifier", "identifier", "field_identifier"):
                            name_node = sub
                            break

                if name_node is not None:
                    type_text = source_code[name_node.start_byte:name_node.end_byte]
                    if type_text and all(ord(c) < 128 for c in type_text):
                        if not any(bad in type_text for bad in ['\n', '\r', '/*', '*/', '//', ';', '{', '}']):
                            type_parts.append(type_text)
            elif child.type == 'storage_class_specifier':
                # è·³è¿‡ static, extern ç­‰
                continue
            elif child.type == 'type_qualifier':
                # const, volatile ç­‰
                qual_text = source_code[child.start_byte:child.end_byte]
                if qual_text in ['const', 'volatile', 'restrict']:
                    type_parts.append(qual_text)
        
        result = ' '.join(type_parts) if type_parts else 'unknown'
        
        # æœ€ç»ˆéªŒè¯ï¼šç±»å‹åä¸åº”è¯¥åŒ…å«ä¸­æ–‡æˆ–å…¶ä»–åƒåœ¾
        if not all(ord(c) < 128 for c in result):
            logger.warning(f"âš ï¸ Warning: Invalid type name '{result[:30]}', fallback to void*")
            return 'unknown'
        
        return result
    
    def _lift_function_static_vars(
        self, 
        root_node, 
        source_code: str, 
        file_name: str
    ) -> List[VariableInfo]:
        """
        æå–å‡½æ•°å†…çš„ static å˜é‡å¹¶è¿›è¡Œ"å˜é‡æå‡"
        
        å°† static int count; é‡å‘½åä¸º static int {func_name}_count;
        è¿™ç§"å˜é‡æå‡"ç­–ç•¥èƒ½è§£å†³ Rust ä¸æ”¯æŒå‡½æ•°çº§ static çš„é—®é¢˜
        """
        lifted_vars = []
        
        # æŸ¥è¯¢å‡½æ•°å®šä¹‰
        query = CPP_LANGUAGE.query("""
            (function_definition
                declarator: (function_declarator
                    declarator: (identifier) @func_name)
                body: (compound_statement) @body
            )
        """)
        
        captures = query.captures(root_node)
        
        func_name = None
        for node, name in captures:
            if name == 'func_name':
                func_name = source_code[node.start_byte:node.end_byte]
            elif name == 'body' and func_name:
                # åœ¨å‡½æ•°ä½“å†…æŸ¥æ‰¾ static å£°æ˜
                static_vars = self._find_static_in_compound(node, source_code, func_name, file_name)
                lifted_vars.extend(static_vars)
                func_name = None
        
        return lifted_vars
    
    def _find_static_in_compound(
        self, 
        compound_node, 
        source_code: str, 
        func_name: str,
        file_name: str
    ) -> List[VariableInfo]:
        """åœ¨å¤åˆè¯­å¥ä¸­æŸ¥æ‰¾ static å£°æ˜"""
        variables = []
        
        for child in compound_node.children:
            if child.type == 'declaration':
                decl_text = source_code[child.start_byte:child.end_byte]
                if decl_text.strip().startswith('static'):
                    # è§£æ static å£°æ˜
                    var_infos = self._parse_declaration(child, source_code)
                    for var in var_infos:
                        # é‡å‘½åï¼šæ·»åŠ å‡½æ•°åå‰ç¼€ä»¥ç¡®ä¿å”¯ä¸€æ€§
                        lifted_name = f"{func_name}_{var.name}"
                        var.name = lifted_name
                        var.from_function = func_name
                        var.rust_declaration = self._generate_rust_static_declaration(
                            lifted_name, var.rust_type, var.is_pointer, var.is_array
                        )
                        variables.append(var)
        
        return variables
    
    def _extract_variables_with_regex(self, source_code: str) -> List[VariableInfo]:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å˜é‡ï¼ˆå›é€€æ–¹æ¡ˆï¼‰"""
        variables = []
        
        # åŒ¹é… static å˜é‡
        static_patterns = [
            # static Type *var = value;
            r'static\s+(?:const\s+)?([\w:]+)\s*\*\s*(\w+)\s*(?:=\s*[^;]+)?\s*;',
            # static Type var = value;
            r'static\s+(?:const\s+)?([\w:]+)\s+(\w+)\s*(?:=\s*[^;]+)?\s*;',
            # static Type var[SIZE];
            r'static\s+(?:const\s+)?([\w:]+)\s+(\w+)\s*\[([^\]]*)\]\s*;',
        ]
        
        for pattern in static_patterns:
            for match in re.finditer(pattern, source_code, re.MULTILINE):
                c_type = match.group(1).strip()
                var_name = match.group(2).strip()
                is_pointer = '*' in match.group(0)
                is_array = '[' in match.group(0)
                
                rust_type = self._c_type_to_rust(c_type, is_pointer, is_array)
                rust_decl = self._generate_rust_static_declaration(var_name, rust_type, is_pointer, is_array)
                
                variables.append(VariableInfo(
                    name=var_name,
                    c_type=c_type,
                    rust_type=rust_type,
                    rust_declaration=rust_decl,
                    is_static=True,
                    is_pointer=is_pointer,
                    is_array=is_array
                ))
        
        # åŒ¹é… g_xxx æˆ– G_XXX å…¨å±€å˜é‡
        global_patterns = [
            r'^[\t ]*([\w:]+)\s*\*?\s*(g_\w+|G_[A-Z_]+)\s*(?:=\s*[^;]+)?\s*;',
        ]
        
        for pattern in global_patterns:
            for match in re.finditer(pattern, source_code, re.MULTILINE):
                c_type = match.group(1).strip()
                var_name = match.group(2).strip()
                is_pointer = '*' in match.group(0)
                
                rust_type = self._c_type_to_rust(c_type, is_pointer, False)
                rust_decl = self._generate_rust_static_declaration(var_name, rust_type, is_pointer, False)
                
                variables.append(VariableInfo(
                    name=var_name,
                    c_type=c_type,
                    rust_type=rust_type,
                    rust_declaration=rust_decl,
                    is_static=False,
                    is_pointer=is_pointer,
                    is_array=False
                ))
        
        return variables
    
    def _c_type_to_rust(self, c_type: str, is_pointer: bool, is_array: bool) -> str:
        """
        å°† C ç±»å‹è½¬æ¢ä¸º Rust ç±»å‹
        
        åŸºäº EvoC2Rust å’Œ LLMigrate çš„ç±»å‹æ˜ å°„è§„åˆ™
        
        æ³¨æ„ï¼šå¦‚æœ TypeMapper å¯ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨ TypeMapper
        """
        # ä¼˜å…ˆä½¿ç”¨ TypeMapperï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if TYPE_MAPPER_AVAILABLE:
            return TypeMapper.map_c_type(c_type, is_pointer, False)
        
        # å›é€€åˆ°æ—§çš„æ˜ å°„æ–¹æ³•
        type_mapping = {
            # åŸºç¡€æ•´æ•°ç±»å‹
            'int': 'i32',
            'unsigned int': 'u32',
            'unsigned': 'u32',
            'long': 'i64',
            'unsigned long': 'u64',
            'long long': 'i64',
            'long long int': 'i64',
            'unsigned long long': 'u64',
            'unsigned long long int': 'u64',
            'short': 'i16',
            'short int': 'i16',
            'unsigned short': 'u16',
            'unsigned short int': 'u16',
            'char': 'i8',
            'unsigned char': 'u8',
            'signed char': 'i8',
            'signed': 'i32',
            
            # æµ®ç‚¹ç±»å‹
            'float': 'f32',
            'double': 'f64',
            'long double': 'f64',
            
            # ç‰¹æ®Šç±»å‹
            'void': 'std::ffi::c_void',
            'bool': 'bool',
            '_Bool': 'bool',
            
            # å›ºå®šå®½åº¦æ•´æ•°ç±»å‹ (stdint.h)
            'size_t': 'usize',
            'ssize_t': 'isize',
            'ptrdiff_t': 'isize',
            'intptr_t': 'isize',
            'uintptr_t': 'usize',
            'uint8_t': 'u8',
            'uint16_t': 'u16',
            'uint32_t': 'u32',
            'uint64_t': 'u64',
            'int8_t': 'i8',
            'int16_t': 'i16',
            'int32_t': 'i32',
            'int64_t': 'i64',
            
            # å¸¸è§çš„ POSIX ç±»å‹
            'off_t': 'i64',
            'pid_t': 'i32',
            'uid_t': 'u32',
            'gid_t': 'u32',
            'mode_t': 'u32',
            'time_t': 'i64',
            'clock_t': 'i64',
            'socklen_t': 'u32',
            
            # C æ ‡å‡†åº“ç±»å‹
            'FILE': 'std::ffi::c_void',  # FILE* ä½œä¸ºä¸é€æ˜ç±»å‹
            'wchar_t': 'i32',
            
            # C++ æ ‡å‡†åº“ç±»å‹ï¼ˆç®€åŒ–å¤„ç†ï¼‰
            'std::string': 'String',
            'string': 'String',
        }
        
        # æ¸…ç†ç±»å‹å
        clean_type = c_type.replace('const', '').replace('volatile', '').replace('struct', '').replace('enum', '').replace('union', '').strip()
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        clean_type = ' '.join(clean_type.split())
        
        # æŸ¥æ‰¾æ˜ å°„
        rust_type = type_mapping.get(clean_type)
        
        if rust_type is None:
            # æœªçŸ¥ç±»å‹ï¼Œä¿ç•™åŸåï¼ˆå¯èƒ½æ˜¯è‡ªå®šä¹‰ç±»å‹ï¼Œåœ¨ types.rs ä¸­å®šä¹‰ï¼‰
            # æ¸…ç†ç±»å‹åä½¿å…¶æˆä¸ºæœ‰æ•ˆçš„ Rust æ ‡è¯†ç¬¦
            rust_type = clean_type.replace('::', '_').replace(' ', '_')
            if rust_type and not rust_type[0].isalpha() and rust_type[0] != '_':
                rust_type = '_' + rust_type
        
        if is_pointer:
            if clean_type == 'void':
                rust_type = '*mut std::ffi::c_void'
            elif clean_type == 'char':
                rust_type = '*mut i8'  # char* é€šå¸¸æ˜¯ C å­—ç¬¦ä¸²
            else:
                rust_type = f'*mut {rust_type}'
        
        if is_array and not is_pointer:
            # æ•°ç»„ç±»å‹ï¼Œä½†æ²¡æœ‰æŒ‡å®šå¤§å°æ—¶ä½¿ç”¨åˆ‡ç‰‡æˆ–æŒ‡é’ˆ
            rust_type = f'*mut {rust_type}'
        
        return rust_type
    
    def _generate_rust_static_declaration(
        self, 
        name: str, 
        rust_type: str, 
        is_pointer: bool, 
        is_array: bool
    ) -> str:
        """ç”Ÿæˆ Rust static mut å£°æ˜"""
        # å¤„ç† Rust ä¿ç•™å­—ä½œä¸ºå˜é‡å
        safe_name = self._escape_rust_keyword(name)
        
        if is_pointer:
            return f'pub static mut {safe_name}: {rust_type} = std::ptr::null_mut();'
        elif is_array:
            return f'pub static mut {safe_name}: [{rust_type}; 0] = [];  // TODO: Set correct array size'
        elif rust_type in ['i32', 'u32', 'i64', 'u64', 'i16', 'u16', 'i8', 'u8', 'usize', 'isize']:
            return f'pub static mut {safe_name}: {rust_type} = 0;'
        elif rust_type in ['f32', 'f64']:
            return f'pub static mut {safe_name}: {rust_type} = 0.0;'
        elif rust_type == 'bool':
            return f'pub static mut {safe_name}: bool = false;'
        else:
            # å¤æ‚ç±»å‹ä½¿ç”¨ MaybeUninit
            return f'pub static mut {safe_name}: std::mem::MaybeUninit<{rust_type}> = std::mem::MaybeUninit::uninit();'

    # =========================================================================
    # Globals generation: Scheme A (bindgen-truth static storage)
    # =========================================================================

    @staticmethod
    def _find_bindgen_binary_for_globals() -> Optional[str]:
        """Locate `bindgen` CLI (best-effort)."""
        p = shutil.which("bindgen")
        if p:
            return p
        cargo_bin = Path.home() / ".cargo" / "bin" / "bindgen"
        if cargo_bin.exists():
            return str(cargo_bin)
        return None

    @staticmethod
    def _parse_defined_type_names_from_types_rs_text(types_rs: str) -> Set[str]:
        """Extract `pub (struct|enum|union|type) Name` items from types.rs (best-effort)."""
        if not types_rs:
            return set()
        return set(re.findall(r"\bpub\s+(?:struct|enum|union|type)\s+([A-Za-z_]\w*)\b", types_rs))

    @staticmethod
    def _prefix_types_in_rust_type_expr(type_expr: str, type_names: Set[str]) -> str:
        """
        Prefix standalone identifiers in a Rust type expression with `crate::types::`,
        if they are known type names from types.rs.
        """
        if not type_expr or not type_names:
            return type_expr or ""

        s = type_expr
        res: List[str] = []
        i = 0
        last_token = ""
        while i < len(s):
            if s.startswith("::", i):
                res.append("::")
                i += 2
                last_token = "::"
                continue
            m = re.match(r"[A-Za-z_][A-Za-z0-9_]*", s[i:])
            if m:
                ident = m.group(0)
                if ident in type_names and last_token != "::":
                    res.append(f"crate::types::{ident}")
                else:
                    res.append(ident)
                i += len(ident)
                last_token = ident
                continue
            res.append(s[i])
            i += 1
        return "".join(res).strip()

    @staticmethod
    def _parse_bindgen_extern_vars(bindgen_rs: str) -> Dict[str, Dict[str, str]]:
        """
        Parse bindgen output and extract variable type info (best-effort).

        Returns:
          {VarRustName: {"ty": TypeExpr, "init": OptionalInitExpr}}

        Notes:
        - bindgen may emit `pub const NAME: Ty = <const-expr>;` for var definitions with constant initializers.
        - bindgen may wrap variable decls in either `extern "C" { ... }` or `unsafe extern "C" { ... }`.
        """
        if not bindgen_rs:
            return {}

        lines = bindgen_rs.splitlines()
        i = 0
        in_extern = False
        vars_map: Dict[str, Dict[str, str]] = {}

        def _normalize_sig(sig_lines: List[str]) -> str:
            sig = " ".join((ln or "").strip() for ln in sig_lines if (ln or "").strip())
            return re.sub(r"\s+", " ", sig).strip()

        # Pass 1: capture top-level `pub const` (constified var definitions).
        for line in lines:
            s = (line or "").strip()
            if not s.startswith("pub const "):
                continue
            m = re.match(
                r"^pub\s+const\s+([A-Za-z_]\w*|r#[A-Za-z_]\w*)\s*:\s*(.+?)\s*=\s*(.+);$",
                s,
            )
            if not m:
                continue
            name = m.group(1).strip()
            ty = m.group(2).strip()
            init = m.group(3).strip()
            if name and ty:
                vars_map[name] = {"ty": ty, "init": init}

        # Pass 2: capture `pub static` from extern blocks.
        while i < len(lines):
            line = lines[i]
            s = (line or "").strip()
            if s in {'extern "C" {', 'unsafe extern "C" {'}:
                in_extern = True
                i += 1
                continue
            if in_extern and s == "}":
                in_extern = False
                i += 1
                continue
            if not in_extern:
                i += 1
                continue
            if not s:
                i += 1
                continue
            if s.startswith("#["):
                # ignore attrs for globals storage
                i += 1
                continue

            if s.startswith("pub static "):
                sig_lines = [line]
                i += 1
                while i < len(lines) and not (sig_lines[-1] or "").strip().endswith(";"):
                    sig_lines.append(lines[i])
                    i += 1
                sig = _normalize_sig(sig_lines)
                m = re.match(
                    r"^pub\s+static(?:\s+mut)?\s+([A-Za-z_]\w*|r#[A-Za-z_]\w*)\s*:\s*(.+);$",
                    sig,
                )
                if m:
                    name = m.group(1).strip()
                    ty = m.group(2).strip()
                    if name and ty:
                        vars_map.setdefault(name, {})
                        vars_map[name]["ty"] = ty
                continue

            i += 1

        # Normalize to always have `ty`.
        vars_map = {n: v for n, v in vars_map.items() if isinstance(v, dict) and v.get("ty")}
        return vars_map

    @staticmethod
    def _extract_c_array_initializer(c_source_files: List[Path], var_name: str) -> Optional[str]:
        """
        Extract array initializer from C source files for a given variable name.

        Looks for patterns like:
            Type VAR_NAME[SIZE] = { val1, val2, ... };
            Type VAR_NAME[] = { val1, val2, ... };

        Args:
            c_source_files: List of C source file paths to search
            var_name: Name of the variable to find

        Returns:
            Rust array literal (e.g., "[619, 720, 127, ...]") or None if not found
        """
        if not var_name or not c_source_files:
            return None

        # Pattern to match array definition with initializer
        # Captures: type, name, optional size, initializer content
        pattern = rf'\b{re.escape(var_name)}\s*\[[^\]]*\]\s*=\s*\{{\s*'

        for src_path in c_source_files:
            try:
                if not src_path.exists():
                    continue
                content = src_path.read_text(encoding="utf-8", errors="ignore")

                # Find the variable definition
                match = re.search(pattern, content, re.MULTILINE)
                if not match:
                    continue

                # Find the opening brace position within the matched text
                # The pattern ends with `\{\s*` so we need to find the { position
                matched_text = match.group(0)
                brace_offset = matched_text.rfind('{')
                if brace_offset < 0:
                    continue
                start_pos = match.start() + brace_offset  # Position of opening {

                # Extract the initializer block using brace matching
                brace_depth = 0
                end_pos = start_pos

                for i in range(start_pos, len(content)):
                    ch = content[i]
                    if ch == '{':
                        brace_depth += 1
                    elif ch == '}':
                        brace_depth -= 1
                        if brace_depth == 0:
                            end_pos = i + 1
                            break

                if end_pos <= start_pos:
                    continue

                # Extract the full initializer block
                initializer = content[start_pos:end_pos]

                # Convert C initializer to Rust array literal
                # { val1, val2, ... } -> [ val1, val2, ... ]
                rust_init = initializer.strip()
                if rust_init.startswith('{') and rust_init.endswith('}'):
                    # Replace outer braces with brackets
                    inner = rust_init[1:-1].strip()

                    # Handle nested initializers for structs (convert {} to {})
                    # But for simple numeric arrays, just replace outer braces

                    # Clean up whitespace and newlines
                    inner = re.sub(r'\s+', ' ', inner)

                    # Check if it's a simple numeric array (most common case)
                    # For complex nested initializers, we'd need more sophisticated handling
                    if not re.search(r'\{', inner):  # No nested braces
                        return f"[{inner}]"
                    else:
                        # Nested initializers - return None for now (complex case)
                        # Future enhancement: handle struct array initializers
                        return None

            except Exception as e:
                logger.debug(f"Failed to extract initializer from {src_path}: {e}")
                continue

        return None

    def _get_project_source_files(self) -> List[Path]:
        """Get list of C source files for the current project."""
        source_files: List[Path] = []
        c_exts = {'.c', '.cc', '.cpp', '.cxx'}

        # Try to get source files from TU context (most accurate)
        if hasattr(self, '_tu_context_files') and self._tu_context_files:
            for safe_name, rec in self._tu_context_files.items():
                if isinstance(rec, dict):
                    src = rec.get("source_file_abs") or rec.get("source_for_cc_abs")
                    if src:
                        try:
                            p = Path(str(src))
                            if p.exists() and p.suffix.lower() in c_exts:
                                source_files.append(p)
                        except Exception:
                            pass

        # Also try project_root if available
        if hasattr(self, 'project_root') and self.project_root:
            project_root = Path(self.project_root)
            try:
                for ext in ['*.c', '*.cc', '*.cpp']:
                    source_files.extend(project_root.rglob(ext))
            except Exception:
                pass

            # Also check the src/ subdirectory specifically
            src_dir = project_root / "src"
            if src_dir.exists():
                try:
                    for ext in ['*.c', '*.cc', '*.cpp']:
                        source_files.extend(src_dir.rglob(ext))
                except Exception:
                    pass

        # Fallback: check ComparisonMethod directory structure
        # This handles the case where project sources are in ComparisonMethod/Our/projects/{project_name}/
        if hasattr(self, 'output_dir') and self.output_dir:
            try:
                output_path = Path(self.output_dir)
                # Look for project name from output path
                # e.g., .../intermediate/bzip2/workspace/... -> bzip2
                project_name = None
                # Detect from intermediate directory structure (generic approach)
                if 'intermediate' in output_path.parts:
                    try:
                        idx = output_path.parts.index('intermediate')
                        if idx + 1 < len(output_path.parts):
                            project_name = output_path.parts[idx + 1]
                    except (ValueError, IndexError):
                        pass

                if project_name:
                    # Look for ComparisonMethod/Our/projects/{project_name}/
                    framework_root = Path(__file__).parent
                    comparison_paths = [
                        framework_root / "ComparisonMethod" / "Our" / "projects" / project_name,
                        framework_root / "ComparisonMethod" / "Our" / "projects" / project_name / "src",
                    ]
                    for comp_path in comparison_paths:
                        if comp_path.exists():
                            for ext in ['*.c', '*.cc', '*.cpp']:
                                source_files.extend(comp_path.rglob(ext))
            except Exception:
                pass

        unique_files = list(set(source_files))
        if unique_files:
            logger.debug(f"æ‰¾åˆ° {len(unique_files)} ä¸ª C æºæ–‡ä»¶ç”¨äºåˆå§‹åŒ–å€¼æå–")
        return unique_files

    @staticmethod
    def _split_top_level_commas(src: str) -> List[str]:
        """Split a Rust-like param list by commas, ignoring nested (), [], <>."""
        s = src or ""
        out: List[str] = []
        buf: List[str] = []
        depth_paren = 0
        depth_angle = 0
        depth_brack = 0
        i = 0
        while i < len(s):
            ch = s[i]
            if ch == "(":
                depth_paren += 1
            elif ch == ")":
                depth_paren = max(0, depth_paren - 1)
            elif ch == "<":
                depth_angle += 1
            elif ch == ">":
                depth_angle = max(0, depth_angle - 1)
            elif ch == "[":
                depth_brack += 1
            elif ch == "]":
                depth_brack = max(0, depth_brack - 1)
            if ch == "," and depth_paren == 0 and depth_angle == 0 and depth_brack == 0:
                chunk = "".join(buf).strip()
                if chunk:
                    out.append(chunk)
                buf = []
                i += 1
                continue
            buf.append(ch)
            i += 1
        tail = "".join(buf).strip()
        if tail:
            out.append(tail)
        return out

    @staticmethod
    def _parse_bindgen_extern_fns(bindgen_rs: str) -> Dict[str, Dict[str, str]]:
        """
        Parse bindgen output and extract function signatures (best-effort).

        Returns:
          {FnName: {"params": "...", "ret": "..."}}

        Notes:
        - bindgen may wrap decls in either `extern "C" { ... }` or `unsafe extern "C" { ... }`.
        - We only capture `pub fn` items inside the extern block; types/consts are ignored here.
        """
        if not bindgen_rs:
            return {}

        lines = bindgen_rs.splitlines()
        i = 0
        in_extern = False
        out: Dict[str, Dict[str, str]] = {}

        def _normalize(sig_lines: List[str]) -> str:
            sig = " ".join((ln or "").strip() for ln in sig_lines if (ln or "").strip())
            sig = re.sub(r"\s+", " ", sig).strip()
            return sig

        def _parse_one(sig: str) -> Optional[Tuple[str, str, str]]:
            s = (sig or "").strip()
            if not s.endswith(";"):
                return None
            s = s[:-1].strip()
            # Find `fn name(`
            m = re.search(r"\bfn\s+([A-Za-z_]\w*|r#[A-Za-z_]\w*)\s*\(", s)
            if not m:
                return None
            name = m.group(1).strip()
            # Find params span (balanced parentheses) starting at the `(` after the name.
            start = s.find("(", m.end(1))
            if start == -1:
                return None
            depth = 0
            end = None
            for j in range(start, len(s)):
                ch = s[j]
                if ch == "(":
                    depth += 1
                elif ch == ")":
                    depth -= 1
                    if depth == 0:
                        end = j
                        break
            if end is None:
                return None
            params = s[start + 1 : end].strip()
            rest = s[end + 1 :].strip()
            ret = ""
            if rest.startswith("->"):
                ret = rest[2:].strip()
            # Strip trailing where-clause-like fragments (bindgen usually doesn't emit them for extern fns)
            return name, params, ret

        while i < len(lines):
            line = lines[i]
            s = (line or "").strip()
            if s in {'extern "C" {', 'unsafe extern "C" {'}:
                in_extern = True
                i += 1
                continue
            if in_extern and s == "}":
                in_extern = False
                i += 1
                continue
            if not in_extern:
                i += 1
                continue
            if not s:
                i += 1
                continue
            if s.startswith("#["):
                i += 1
                continue
            if s.startswith("pub ") and " fn " in s:
                sig_lines = [line]
                i += 1
                while i < len(lines) and not (sig_lines[-1] or "").strip().endswith(";"):
                    sig_lines.append(lines[i])
                    i += 1
                sig = _normalize(sig_lines)
                parsed = _parse_one(sig)
                if parsed:
                    name, params, ret = parsed
                    # Record both raw name and unescaped name (r#foo -> foo) for easier lookup.
                    out[name] = {"params": params, "ret": ret}
                    if name.startswith("r#"):
                        out.setdefault(name[2:], {"params": params, "ret": ret})
                continue
            i += 1

        return out

    def _run_bindgen_allowlist_fns(
        self,
        *,
        preprocessed_path: Path,
        fn_names: Sequence[str],
        lang: str,
        defined_types: Set[str],
        timeout_sec: int,
        tmp_dir: Path,
    ) -> Dict[str, str]:
        """
        Run bindgen on a preprocessed `.i` file and return `{fn_name: rust_signature}` for allowlisted fns.

        The returned signature is a Rust *definition* signature (for stubs), e.g.:
          `pub extern "C" fn foo(arg1: *const c_char) -> i32`
        """
        bindgen_bin = self._find_bindgen_binary_for_globals()
        if not bindgen_bin:
            return {}
        if not preprocessed_path or not preprocessed_path.exists():
            return {}
        if not fn_names:
            return {}

        try:
            tmp_dir.mkdir(parents=True, exist_ok=True)
        except Exception:
            pass

        # Cache by (file, lang, fn-set)
        try:
            import hashlib as _hashlib

            fn_hash = _hashlib.md5("\n".join(sorted(set(fn_names))).encode("utf-8", errors="ignore")).hexdigest()[:10]
            cache_key = f"{str(preprocessed_path)}|{(lang or 'c').lower()}|{fn_hash}"
        except Exception:
            cache_key = ""
        if cache_key and cache_key in self._bindgen_fn_sig_cache:
            return dict(self._bindgen_fn_sig_cache.get(cache_key) or {})

        out_rs = tmp_dir / f"{preprocessed_path.stem}.fns.rs"
        cmd: List[str] = [
            bindgen_bin,
            str(preprocessed_path),
            "-o",
            str(out_rs),
            "--generate",
            "functions",
            "--no-layout-tests",
            "--no-doc-comments",
            "--use-core",
            "--default-enum-style=consts",
            "--no-prepend-enum-name",
            "--no-size_t-is-usize",
        ]
        for name in sorted(set(fn_names)):
            cmd.extend(["--allowlist-function", rf"^{re.escape(name)}$"])
        cmd.append("--")
        if (lang or "c").lower().startswith("c++"):
            cmd.extend(["-x", "c++", "-std=c++17"])
        else:
            cmd.extend(["-x", "c"])
        cmd.extend(
            [
                "-Wno-error",
                "-Wno-macro-redefined",
                "-Wno-builtin-macro-redefined",
                "-Wno-ignored-attributes",
            ]
        )

        try:
            proc = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=max(10, int(timeout_sec or 60)),
            )
        except Exception as e:
            logger.debug(f"bindgen fns å¤±è´¥: {e}")
            return {}
        if proc.returncode != 0 or not out_rs.exists():
            logger.debug(f"bindgen fns å¤±è´¥ rc={proc.returncode}: {(proc.stderr or '')[:200]}")
            return {}

        try:
            bindgen_text = out_rs.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            bindgen_text = ""

        fns_map = self._parse_bindgen_extern_fns(bindgen_text)
        if not fns_map:
            return {}

        out: Dict[str, str] = {}
        for fn_name, info in fns_map.items():
            params_raw = str((info or {}).get("params") or "").strip()
            ret_raw = str((info or {}).get("ret") or "").strip()
            # Reject C-variadic decls (cannot define in stable Rust).
            if "..." in params_raw:
                continue

            params_out: List[str] = []
            for item in self._split_top_level_commas(params_raw):
                if item.strip() == "...":
                    params_out = []
                    break
                if ":" not in item:
                    # unexpected, keep as-is
                    params_out.append(item.strip())
                    continue
                n, ty = item.split(":", 1)
                n = (n or "").strip()
                ty = self._prefix_types_in_rust_type_expr((ty or "").strip(), defined_types)
                params_out.append(f"{n}: {ty}".strip())
            if not params_out and params_raw.strip():
                # Could not parse params reliably, skip this fn.
                continue

            ret = self._prefix_types_in_rust_type_expr(ret_raw, defined_types) if ret_raw else ""
            # Normalize void return
            ret_clause = ""
            if ret and ret != "()":
                ret_clause = f" -> {ret}"
            sig = f'pub extern "C" fn {fn_name}({", ".join(params_out)}){ret_clause}'
            out[fn_name] = sig

        if cache_key:
            try:
                self._bindgen_fn_sig_cache[cache_key] = dict(out)
            except Exception:
                pass
        return out

    def get_bindgen_function_signatures_from_tu(
        self,
        *,
        safe_name: str,
        fn_names: Sequence[str],
        source_file: Optional[Path] = None,
    ) -> Dict[str, str]:
        """
        Deterministic signature source: bindgen allowlist on stage1-pinned preprocessed `.i` (TU truth).

        Fallback (optional): if stage1 TU map is missing/unavailable, try to preprocess `source_file`
        using the loaded compile_commands.json, then run bindgen on the generated `.i`.

        Returns `{c_fn_name: rust_signature}` for functions in this file-group (safe_name).
        """
        if not safe_name or not fn_names:
            return {}
        try:
            require_tu = (os.environ.get("C2R_REQUIRE_TU_CLOSURE", "1") or "1").strip().lower() not in (
                "0",
                "false",
                "no",
            )
        except Exception:
            require_tu = True
        rec = self._tu_context_files.get(str(safe_name)) if getattr(self, "_tu_context_files", None) else None
        pre = rec.get("preprocessed_file") if isinstance(rec, dict) else None
        pre_path: Optional[Path] = None
        if pre:
            try:
                pre_path = Path(str(pre)).expanduser()
            except Exception:
                pre_path = None

        # Best-effort: regenerate preprocessed `.i` if it was not materialized but we have a pinned entry.
        if (not pre_path) or (not pre_path.exists()):
            try:
                entry = rec.get("compile_commands_entry") if isinstance(rec, dict) else None
                if entry and self.compile_commands_parser and self._env_flag("C2R_RETRY_PREPROCESS_MISSING_I", "0"):
                    out_dir = None
                    try:
                        env_dir = os.environ.get("PREPROCESS_OUTPUT_DIR", "").strip()
                        out_dir = Path(env_dir) if env_dir else None
                    except Exception:
                        out_dir = None
                    ctx = self.compile_commands_parser.preprocess_with_context(
                        Path(str(rec.get("source_for_cc_abs") or rec.get("source_file_abs") or "")),
                        entry,
                        output_dir=out_dir,
                        timeout_sec=int(os.environ.get("C2R_PREPROCESS_TIMEOUT_SEC", "60")),
                    )
                    if ctx and getattr(ctx, "preprocessed_file", None):
                        pre_path = Path(ctx.preprocessed_file)
            except Exception:
                pass

        # Fallback: if stage1 map is missing (or `.i` missing) but we do have a source file path,
        # try to derive a preprocessing context directly from compile_commands.json.
        if (not pre_path) or (not pre_path.exists()):
            if require_tu:
                # Strict TU-closure mode: never "re-pick" a TU/profile. Missing stage1 `.i` should be
                # treated as an input/closure issue and handled by the project-level gate.
                return {}
            try:
                enable_fallback = self._env_flag("C2R_BINDGEN_FN_SIG_FALLBACK_PREPROCESS", default="1")
            except Exception:
                enable_fallback = True
            # Truth mode: do NOT "re-pick" a TU. Missing stage1 `.i` should be treated as a data/closure issue.
            # (Override only if you explicitly opt in.)
            try:
                truth_mode = self._env_flag("C2R_TRUTH_MODE", "0")
            except Exception:
                truth_mode = False
            if truth_mode and (not self._env_flag("C2R_TRUTH_ALLOW_FN_SIG_FALLBACK_PREPROCESS", "0")):
                enable_fallback = False
            if enable_fallback and source_file and self.compile_commands_parser:
                try:
                    src_path = Path(source_file)
                    src_for_cc = self._map_to_ohos_path(src_path)
                    from compile_commands_parser import ContextSelectionStrategy  # type: ignore

                    strat_env = (
                        os.environ.get("C2R_PREPROCESSING_STRATEGY", "")
                        or os.environ.get("PREPROCESSING_STRATEGY", "")
                        or ""
                    ).strip().lower()
                    strategy = ContextSelectionStrategy.BEST
                    if strat_env in ("active", "auto"):
                        strategy = ContextSelectionStrategy.ACTIVE
                    elif strat_env == "union":
                        strategy = ContextSelectionStrategy.UNION
                    target_cfg = None
                    if strategy == ContextSelectionStrategy.ACTIVE:
                        target_cfg = (os.environ.get("TARGET_OUT_DIR") or os.environ.get("TARGET_CONFIG") or "").strip() or None

                    out_dir = None
                    try:
                        env_dir = os.environ.get("PREPROCESS_OUTPUT_DIR", "").strip()
                        out_dir = Path(env_dir) if env_dir else (self.output_dir / ".preprocessed_fallback")
                    except Exception:
                        out_dir = self.output_dir / ".preprocessed_fallback"

                    ctx = self.compile_commands_parser.select_preprocessing_context(
                        src_for_cc,
                        strategy=strategy,
                        target_config=target_cfg,
                        output_dir=out_dir,
                    )
                    if ctx and not getattr(ctx, "error", None) and getattr(ctx, "preprocessed_file", None):
                        pre_path = Path(ctx.preprocessed_file)
                        # Provide a minimal lang hint if stage1 record is absent.
                        if not isinstance(rec, dict):
                            rec = {"source_file_abs": str(src_path)}
                except Exception:
                    pass

        if not pre_path or not pre_path.exists():
            return {}

        defined_types: Set[str] = set()
        try:
            types_rs = (self.output_dir / "src" / "types.rs").read_text(encoding="utf-8", errors="ignore")
            defined_types = self._parse_defined_type_names_from_types_rs_text(types_rs)
        except Exception:
            defined_types = set()

        lang = "c"
        try:
            p = rec.get("source_file_abs") or rec.get("source_for_cc_abs") if isinstance(rec, dict) else ""
            if not p and source_file:
                p = str(source_file)
            suf = Path(str(p)).suffix.lower()
            if suf in {".cc", ".cpp", ".cxx", ".c++"}:
                lang = "c++"
        except Exception:
            lang = "c"

        try:
            timeout_sec = int(os.environ.get("C2R_BINDGEN_FN_SIG_TIMEOUT_SEC", "90"))
        except Exception:
            timeout_sec = 90
        tmp_dir = self.output_dir / ".c2r_bindgen_fns"

        return self._run_bindgen_allowlist_fns(
            preprocessed_path=pre_path,
            fn_names=fn_names,
            lang=lang,
            defined_types=defined_types,
            timeout_sec=timeout_sec,
            tmp_dir=tmp_dir,
        )

    def _run_bindgen_allowlist_vars(
        self,
        *,
        preprocessed_path: Path,
        var_names: Sequence[str],
        lang: str,
        defined_types: Set[str],
        timeout_sec: int,
        tmp_dir: Path,
    ) -> Dict[str, Dict[str, str]]:
        """
        Run bindgen on a preprocessed `.i` file and return `{var_name: rust_type_expr}` for allowlisted vars.
        """
        bindgen_bin = self._find_bindgen_binary_for_globals()
        if not bindgen_bin:
            return {}
        if not preprocessed_path or not preprocessed_path.exists():
            return {}
        if not var_names:
            return {}

        try:
            tmp_dir.mkdir(parents=True, exist_ok=True)
        except Exception:
            pass

        out_rs = tmp_dir / f"{preprocessed_path.stem}.globals.rs"
        cmd: List[str] = [
            bindgen_bin,
            str(preprocessed_path),
            "-o",
            str(out_rs),
            "--generate",
            "vars",
            "--no-layout-tests",
            "--no-doc-comments",
            "--use-core",
            "--default-enum-style=consts",
            "--no-prepend-enum-name",
            "--no-size_t-is-usize",
            "--ignore-functions",
        ]
        for name in sorted(set(var_names)):
            # NOTE: bindgen may emit some global var definitions as `pub const` (constified),
            # which are filtered out by `--allowlist-var`. Use `--allowlist-item` to capture both.
            cmd.extend(["--allowlist-item", rf"^{re.escape(name)}$"])
        cmd.append("--")
        if (lang or "c").lower().startswith("c++"):
            cmd.extend(["-x", "c++", "-std=c++17"])
        else:
            cmd.extend(["-x", "c"])
        cmd.extend(
            [
                "-Wno-error",
                "-Wno-macro-redefined",
                "-Wno-builtin-macro-redefined",
                "-Wno-ignored-attributes",
            ]
        )

        try:
            proc = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=max(10, int(timeout_sec or 60)),
            )
        except Exception as e:
            logger.debug(f"bindgen globals å¤±è´¥: {e}")
            return {}
        if proc.returncode != 0 or not out_rs.exists():
            logger.debug(f"bindgen globals å¤±è´¥ rc={proc.returncode}: {(proc.stderr or '')[:200]}")
            return {}

        try:
            bindgen_text = out_rs.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            bindgen_text = ""

        vars_map = self._parse_bindgen_extern_vars(bindgen_text)
        if not vars_map:
            return {}

        out: Dict[str, Dict[str, str]] = {}
        for n, info in vars_map.items():
            ty = self._prefix_types_in_rust_type_expr(str(info.get("ty") or ""), defined_types)
            if not ty:
                continue
            init = str(info.get("init") or "").strip()
            out[n] = {"ty": ty, "init": init}
        return out

    def _run_bindgen_allowlist_types(
        self,
        *,
        preprocessed_path: Path,
        type_names: Sequence[str],
        lang: str,
        timeout_sec: int,
        out_rs: Path,
    ) -> bool:
        """
        Run bindgen on a preprocessed `.i` file and emit Rust type declarations for allowlisted types.

        Notes:
        - Input is a stage1-pinned TU `.i` (macro-expanded + full include context).
        - Output is included via `include!()` (do NOT place it under `src/*.rs` root to avoid main.rs glob).
        """
        bindgen_bin = self._find_bindgen_binary_for_globals()
        if not bindgen_bin:
            return False
        if not preprocessed_path or not preprocessed_path.exists():
            return False
        names = [n for n in sorted(set(type_names or [])) if isinstance(n, str) and n.strip()]
        if not names:
            return False

        try:
            out_rs.parent.mkdir(parents=True, exist_ok=True)
        except Exception:
            pass

        cmd: List[str] = [
            bindgen_bin,
            str(preprocessed_path),
            "-o",
            str(out_rs),
            "--generate",
            "types",
            "--no-layout-tests",
            "--no-doc-comments",
            "--use-core",
            "--default-enum-style=consts",
            "--no-prepend-enum-name",
            "--no-size_t-is-usize",
            "--ignore-functions",
        ]
        for name in names:
            cmd.extend(["--allowlist-type", rf"^{re.escape(name)}$"])
        cmd.append("--")
        if (lang or "c").lower().startswith("c++"):
            cmd.extend(["-x", "c++", "-std=c++17"])
        else:
            cmd.extend(["-x", "c"])
        cmd.extend(
            [
                "-Wno-error",
                "-Wno-macro-redefined",
                "-Wno-builtin-macro-redefined",
                "-Wno-ignored-attributes",
            ]
        )

        try:
            proc = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=max(10, int(timeout_sec or 60)),
            )
        except Exception as e:
            logger.debug(f"bindgen types å¤±è´¥: {e}")
            return False

        if proc.returncode != 0 or not out_rs.exists():
            try:
                logger.debug(f"bindgen types å¤±è´¥ rc={proc.returncode}: {(proc.stderr or '')[:200]}")
            except Exception:
                pass
            try:
                if out_rs.exists():
                    out_rs.unlink()
            except Exception:
                pass
            return False

        return True

    def _extract_defined_type_names_from_bindgen_output(self, rs_path: Path) -> Set[str]:
        """Best-effort: parse bindgen-emitted Rust to find defined type names.

        We only care about top-level `pub {type|struct|enum|union} Name` items so that we don't
        re-export/import names that bindgen didn't actually emit (which would break baseline compile).
        """
        if not rs_path or not rs_path.exists():
            return set()
        try:
            txt = rs_path.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            return set()
        names: Set[str] = set()
        try:
            for m in re.finditer(r"(?m)^[ \t]*pub[ \t]+(?:type|struct|enum|union)[ \t]+([A-Za-z_][A-Za-z0-9_]*)\b", txt):
                n = m.group(1)
                if n:
                    names.add(n)
        except Exception:
            return set()
        return names

    def _get_pinned_preprocessed_path_for_safe_name(self, safe_name: str, *, source_file: Optional[Path] = None) -> Optional[Path]:
        """Return the stage1-pinned `.i` path for `safe_name` (best-effort)."""
        if not safe_name:
            return None
        rec = self._tu_context_files.get(str(safe_name)) if getattr(self, "_tu_context_files", None) else None
        pre = rec.get("preprocessed_file") if isinstance(rec, dict) else None
        pre_path: Optional[Path] = None
        if pre:
            try:
                pre_path = Path(str(pre)).expanduser()
            except Exception:
                pre_path = None
        if pre_path and pre_path.exists():
            return pre_path

        # Best-effort: regenerate missing `.i` from pinned compile_commands entry.
        try:
            entry = rec.get("compile_commands_entry") if isinstance(rec, dict) else None
            if entry and self.compile_commands_parser and self._env_flag("C2R_RETRY_PREPROCESS_MISSING_I", "0"):
                out_dir = None
                try:
                    env_dir = os.environ.get("PREPROCESS_OUTPUT_DIR", "").strip()
                    out_dir = Path(env_dir) if env_dir else None
                except Exception:
                    out_dir = None
                src_for_cc = None
                try:
                    src_for_cc = rec.get("source_for_cc_abs") if isinstance(rec, dict) else None
                except Exception:
                    src_for_cc = None
                if not src_for_cc and source_file:
                    src_for_cc = str(source_file)
                if src_for_cc:
                    ctx = self.compile_commands_parser.preprocess_with_context(
                        Path(str(src_for_cc)),
                        entry,
                        output_dir=out_dir,
                        timeout_sec=int(os.environ.get("C2R_PREPROCESS_TIMEOUT_SEC", "60")),
                    )
                    if ctx and getattr(ctx, "preprocessed_file", None):
                        p = Path(ctx.preprocessed_file)
                        if p.exists():
                            return p
        except Exception:
            pass

        return None

    def ensure_types_and_local_types_from_tu(
        self,
        *,
        module_name_to_src: Dict[str, Path],
        module_signatures: Dict[str, Sequence["FunctionSignature"]],
        header_files_present: bool,
    ) -> Dict[str, Any]:
        """
        Truth-firstè¡¥å…¨ï¼š
        - å…¨å±€ types.rsï¼šç¼ºå¤±çš„â€œå…±äº«ç±»å‹/å…¨å±€å˜é‡ç±»å‹â€ä» stage1 pinned `.i` ç”Ÿæˆå¹¶ re-exportã€‚
        - æ¨¡å—ç§æœ‰ç±»å‹ï¼šä»…åœ¨å•ä¸ª `.c` æ¨¡å—ç”¨åˆ°çš„ç±»å‹ï¼Œç”Ÿæˆåˆ°è¯¥æ¨¡å—çš„ `local_types` å­æ¨¡å—ï¼ˆinclude!ï¼‰ã€‚

        ç›®æ ‡ï¼š
        - ä¸ä¼ªé€ å®/static inline extern ç¬¦å·ï¼›
        - ä¸ä¾èµ– regex ä¿®è¡¥â€œè®©å®ƒèƒ½ç¼–è¯‘â€çš„æ´¾ç”Ÿå±‚ï¼›
        - è®©ç­¾å/globals/types éƒ½æ¥è‡ªåŒä¸€å¥— tu_context_map.json pin ä¸‹æ¥çš„ `.i`ã€‚
        """
        result: Dict[str, Any] = {
            "tu_context_map": str(getattr(self, "_tu_context_map_path", "") or ""),
            "tu_context_files": len(getattr(self, "_tu_context_files", {}) or {}),
            "global_missing_types": [],
            "local_missing_types": {},
            "generated_global_units": [],
            "generated_local_units": [],
            "skipped_missing_tu_i": [],
        }

        if not getattr(self, "_tu_context_files", None):
            return result

        src_dir = self.output_dir / "src"
        types_path = src_dir / "types.rs"
        globals_path = src_dir / "globals.rs"
        gen_dir = src_dir / "__c2r_generated"
        try:
            gen_dir.mkdir(parents=True, exist_ok=True)
        except Exception:
            pass

        # -----------------------------
        # Determine which types exist
        # -----------------------------
        defined_types: Set[str] = set()
        types_rs_text = ""
        try:
            if types_path.exists():
                types_rs_text = types_path.read_text(encoding="utf-8", errors="ignore")
                defined_types = self._parse_defined_type_names_from_types_rs_text(types_rs_text)
        except Exception:
            defined_types = set()
            types_rs_text = ""

        # If this is a headerless project, the stage-A placeholder `types.rs` is not truth.
        # Treat it as "no types defined" so we regenerate required items from pinned TU `.i`.
        if not header_files_present:
            if ("bindgen failed to generate types" in (types_rs_text or "")) or ("placeholder definitions" in (types_rs_text or "")):
                defined_types = set()

        # -----------------------------
        # Collect needed types (Rust signatures as compiled truth)
        # -----------------------------
        def _is_trivial_ident(name: str) -> bool:
            if not name:
                return True
            trivial = {
                # Rust primitives
                "i8",
                "u8",
                "i16",
                "u16",
                "i32",
                "u32",
                "i64",
                "u64",
                "i128",
                "u128",
                "isize",
                "usize",
                "f32",
                "f64",
                "bool",
                # Rust keywords / paths / common wrappers
                "pub",
                "unsafe",
                "extern",
                "fn",
                "mut",
                "const",
                "ref",
                "crate",
                "types",
                "core",
                "std",
                "alloc",
                "ffi",
                "Option",
                "Result",
                "Box",
                "Vec",
                "String",
                "MaybeUninit",
                "PhantomData",
                "NonNull",
                "ManuallyDrop",
                "CStr",
                "CString",
                # common core::ffi primitives
                "c_void",
                "c_char",
                "c_schar",
                "c_uchar",
                "c_short",
                "c_ushort",
                "c_int",
                "c_uint",
                "c_long",
                "c_ulong",
                "c_longlong",
                "c_ulonglong",
                "c_float",
                "c_double",
                # common tokens inside type exprs
                "where",
                "Self",
                "self",
            }
            return name in trivial

        def _idents_from_type_expr(expr: str) -> Set[str]:
            s = (expr or "").strip()
            if not s:
                return set()
            out: Set[str] = set()
            for m in re.findall(r"crate::types::([A-Za-z_]\w*)", s):
                if m and (not _is_trivial_ident(m)):
                    out.add(m)
            # Best-effort: take identifier tokens from the type expression.
            for ident in re.findall(r"[A-Za-z_]\w*", s):
                if ident and (not _is_trivial_ident(ident)):
                    out.add(ident)
            return out

        def _type_exprs_from_rust_sig(rust_sig: str) -> List[str]:
            rs = (rust_sig or "").strip()
            if not rs:
                return []
            # Drop any body if present.
            if "{" in rs:
                rs = rs.split("{", 1)[0].strip()
            m = re.search(r"\bfn\b", rs)
            if not m:
                return []
            lp = rs.find("(", m.end())
            if lp == -1:
                return []
            depth = 0
            rp = None
            for i in range(lp, len(rs)):
                ch = rs[i]
                if ch == "(":
                    depth += 1
                elif ch == ")":
                    depth = max(0, depth - 1)
                    if depth == 0:
                        rp = i
                        break
            if rp is None:
                return []
            params_str = rs[lp + 1 : rp]
            rest = rs[rp + 1 :]
            exprs: List[str] = []
            for item in self._split_top_level_commas(params_str):
                if ":" not in item:
                    continue
                _n, ty = item.split(":", 1)
                ty = (ty or "").strip()
                if ty:
                    exprs.append(ty)
            if "->" in rest:
                ret = rest.split("->", 1)[1]
                # Remove trailing where-clause or attributes.
                ret = ret.split(" where ", 1)[0].strip()
                if ret:
                    exprs.append(ret)
            return exprs

        sig_needed_by_mod: Dict[str, Set[str]] = {}
        for mod_name, sigs in (module_signatures or {}).items():
            need: Set[str] = set()
            for sig in sigs or []:
                try:
                    rs = str(getattr(sig, "rust_signature", "") or "").strip()
                except Exception:
                    rs = ""
                for expr in _type_exprs_from_rust_sig(rs):
                    need.update(_idents_from_type_expr(expr))
            sig_needed_by_mod[str(mod_name)] = need

        # Module-local statics (Scheme B): types used only by file-scope `static` vars should stay local.
        statics_needed_by_mod: Dict[str, Set[str]] = {}
        try:
            local_statics = getattr(self, "_module_local_file_statics", {}) or {}
            if isinstance(local_statics, dict):
                for mod_name, entries in local_statics.items():
                    need: Set[str] = set()
                    for ent in entries or []:
                        try:
                            ty = str((ent or {}).get("ty") or "").strip()
                        except Exception:
                            ty = ""
                        if ty:
                            need.update(_idents_from_type_expr(ty))
                    if need:
                        statics_needed_by_mod[str(mod_name)] = need
        except Exception:
            statics_needed_by_mod = {}

        # -----------------------------
        # Collect needed types (globals.rs)
        # -----------------------------
        global_needed: Set[str] = set()
        try:
            if globals_path.exists():
                txt = globals_path.read_text(encoding="utf-8", errors="ignore")
                # Prefer parsing actual static decl types.
                for ty_expr in re.findall(r"\bpub\s+static(?:\s+mut)?\s+[A-Za-z_]\w*\s*:\s*([^=;]+)", txt):
                    global_needed.update(_idents_from_type_expr(str(ty_expr)))
                # Also keep explicit `crate::types::X` occurrences.
                for m in re.findall(r"crate::types::([A-Za-z_]\w*)", txt):
                    if m and (not _is_trivial_ident(m)):
                        global_needed.add(m)
        except Exception:
            global_needed = set()

        # Compute usage counts across modules.
        type_to_mods: Dict[str, Set[str]] = defaultdict(set)
        for mod_name, types in sig_needed_by_mod.items():
            for t in types:
                type_to_mods[t].add(mod_name)

        # Decide whether to "globalize" signature types:
        # - When TU closure is required, skeleton signatures typically use `crate::types::T`.
        #   Any missing `T` must be present in types.rs, otherwise baseline compile fails.
        # - In relaxed mode, keep the older heuristic: only types shared by 2+ modules become global.
        try:
            require_tu = (os.environ.get("C2R_REQUIRE_TU_CLOSURE", "1") or "1").strip().lower() not in (
                "0",
                "false",
                "no",
            )
        except Exception:
            require_tu = True
        globalize_sig_types = self._env_flag(
            "C2R_TU_TRUTH_GLOBALIZE_SIGNATURE_TYPES",
            "1" if require_tu else "0",
        )

        # A type is "global" if:
        # - referenced by globals.rs, OR
        # - (TU-closure-required) referenced by ANY module signature, OR
        # - (legacy) referenced by 2+ modules.
        global_types: Set[str] = set(global_needed)
        if globalize_sig_types:
            for _mod, tys in sig_needed_by_mod.items():
                for t in tys:
                    if t:
                        global_types.add(t)
        else:
            for t, mods in type_to_mods.items():
                if len(mods) > 1:
                    global_types.add(t)

        # Missing types = not already defined in current types.rs.
        global_missing: Set[str] = {t for t in global_types if t and t not in defined_types}
        local_missing_by_mod: Dict[str, Set[str]] = {}
        if not globalize_sig_types:
            for mod_name, types in sig_needed_by_mod.items():
                local = {t for t in types if t and (t not in global_types) and (t not in defined_types)}
                if local:
                    local_missing_by_mod[mod_name] = set(local)
        # Always add file-scope static variable types as module-local (Scheme B), regardless of signature globalization.
        for mod_name, types in statics_needed_by_mod.items():
            local = {t for t in types if t and (t not in global_types) and (t not in defined_types)}
            if local:
                local_missing_by_mod.setdefault(mod_name, set()).update(local)

        result["global_missing_types"] = sorted(global_missing)
        result["local_missing_types"] = {k: sorted(v) for k, v in sorted(local_missing_by_mod.items(), key=lambda kv: kv[0])}

        # -----------------------------
        # Generate module-local types
        # -----------------------------
        def _lang_for_safe_name(safe_name: str) -> str:
            rec = self._tu_context_files.get(safe_name) if getattr(self, "_tu_context_files", None) else None
            if isinstance(rec, dict):
                p = rec.get("source_file_abs") or rec.get("source_for_cc_abs") or ""
                try:
                    suf = Path(str(p)).suffix.lower()
                except Exception:
                    suf = ""
                if suf in {".cc", ".cpp", ".cxx", ".c++"}:
                    return "c++"
            return "c"

        try:
            timeout_sec = int(os.environ.get("C2R_BINDGEN_TYPES_TIMEOUT_SEC", "120"))
        except Exception:
            timeout_sec = 120

        for mod_name, type_names in sorted(local_missing_by_mod.items(), key=lambda kv: kv[0]):
            pre_path = self._get_pinned_preprocessed_path_for_safe_name(mod_name, source_file=module_name_to_src.get(mod_name))
            if not pre_path:
                result["skipped_missing_tu_i"].append(mod_name)
                continue
            out_rs = gen_dir / f"local_types_{mod_name}.rs"
            ok = self._run_bindgen_allowlist_types(
                preprocessed_path=pre_path,
                type_names=sorted(type_names),
                lang=_lang_for_safe_name(mod_name),
                timeout_sec=timeout_sec,
                out_rs=out_rs,
            )
            if not ok:
                continue
            defined = self._extract_defined_type_names_from_bindgen_output(out_rs)
            requested = {n for n in (type_names or set()) if isinstance(n, str) and n.strip()}
            present = {n for n in requested if n in defined}
            missing = {n for n in requested if n not in defined}
            if present:
                result["generated_local_units"].append(mod_name)
            # Update remaining local-missing set to avoid importing non-existent names.
            if missing:
                local_missing_by_mod[mod_name] = set(missing)
            else:
                local_missing_by_mod.pop(mod_name, None)

            # Inject `local_types` include + import into the module file.
            try:
                mod_path = src_dir / f"{mod_name}.rs"
                if mod_path.exists():
                    txt = mod_path.read_text(encoding="utf-8", errors="ignore")
                    include_rel = f"__c2r_generated/local_types_{mod_name}.rs"
                    import_names = [n for n in sorted(present) if isinstance(n, str) and n.strip()]
                    import_line = f"use local_types::{{{', '.join(import_names)}}};" if import_names else ""
                    if "mod local_types" not in txt and include_rel not in txt:
                        lines = txt.splitlines()
                        insert_at = 0
                        for i, ln in enumerate(lines):
                            if ln.strip() == "use crate::compat::*;":
                                insert_at = i + 1
                                break
                        block = [
                            "",
                            "mod local_types {",
                            f'    include!(\"{include_rel}\");',
                            "}",
                        ]
                        if import_line:
                            block.append(import_line)
                        block.append("")
                        block.append("")
                        lines[insert_at:insert_at] = block
                        mod_path.write_text("\n".join(lines) + "\n", encoding="utf-8", errors="ignore")
                    else:
                        # Upgrade legacy glob import (can cause name ambiguity if bindgen emits dependent types).
                        if import_line and "use local_types::*;" in txt:
                            mod_path.write_text(txt.replace("use local_types::*;", import_line), encoding="utf-8", errors="ignore")
            except Exception:
                pass

        # -----------------------------
        # Generate missing *global* types from TU `.i` and re-export from crate::types
        # -----------------------------
        if global_missing:
            # Select a deterministic provider module per type (lexicographically smallest).
            providers: Dict[str, str] = {}
            all_modules = sorted(set((module_name_to_src or {}).keys()) or set(self._tu_context_files.keys()))
            for t in sorted(global_missing):
                mods = sorted(type_to_mods.get(t) or [])
                provider = mods[0] if mods else (all_modules[0] if all_modules else "")
                if provider:
                    providers[t] = provider

            by_provider: Dict[str, Set[str]] = defaultdict(set)
            for t, prov in providers.items():
                by_provider[prov].add(t)

            generated_units: List[str] = []
            exported_by_provider: Dict[str, List[str]] = {}
            exported_names: Set[str] = set()
            for prov, types in sorted(by_provider.items(), key=lambda kv: kv[0]):
                pre_path = self._get_pinned_preprocessed_path_for_safe_name(prov, source_file=module_name_to_src.get(prov))
                if not pre_path:
                    result["skipped_missing_tu_i"].append(prov)
                    continue
                out_rs = gen_dir / f"tu_types_{prov}.rs"
                ok = self._run_bindgen_allowlist_types(
                    preprocessed_path=pre_path,
                    type_names=sorted(types),
                    lang=_lang_for_safe_name(prov),
                    timeout_sec=timeout_sec,
                    out_rs=out_rs,
                )
                if not ok:
                    continue
                defined = self._extract_defined_type_names_from_bindgen_output(out_rs)
                requested = {n for n in (types or set()) if isinstance(n, str) and n.strip()}
                present = [n for n in sorted(requested) if n in defined]
                if present:
                    generated_units.append(prov)
                    exported_by_provider[prov] = present
                    exported_names.update(present)
            result["generated_global_units"] = generated_units

            if generated_units:
                # Write/update `types.rs` to re-export these items.
                reexport_block: List[str] = [
                    "",
                    "// ============================================================",
                    "// C2R: TU-pinned type supplements (from stage1 `.i` truth)",
                    "// ============================================================",
                ]
                for prov in generated_units:
                    mod_ident = f"__c2r_tu_types_{prov}"
                    include_rel = f"__c2r_generated/tu_types_{prov}.rs"
                    reexport_block.append(f"pub mod {mod_ident} {{")
                    reexport_block.append(f'    include!(\"{include_rel}\");')
                    reexport_block.append("}")
                    # Re-export only the types bindgen actually emitted to avoid E0432 at baseline compile.
                    names = exported_by_provider.get(prov) or []
                    if names:
                        reexport_block.append(f"pub use {mod_ident}::{{{', '.join(names)}}};")
                    reexport_block.append("")

                try:
                    if not types_path.exists() or (not header_files_present):
                        # Headerless project: overwrite placeholder types.rs with TU truth re-exports.
                        content = "\n".join(
                            [
                                "//! Auto-generated types module (TU truth entry)",
                                "//!",
                                "//! - Source of truth: stage1 pinned preprocessed `.i` from tu_context_map.json",
                                "//! - Shared/global types are re-exported here (crate::types::*).",
                                "//! - Per-module private types live in each module's `local_types` submodule.",
                                "",
                                "#![allow(non_camel_case_types)]",
                                "#![allow(non_snake_case)]",
                                "#![allow(non_upper_case_globals)]",
                                "#![allow(dead_code)]",
                                "#![allow(unused)]",
                            ]
                            + reexport_block
                        )
                        types_path.write_text(content + "\n", encoding="utf-8", errors="ignore")
                    else:
                        # Header-based types.rs exists: append TU supplements if not already present.
                        existing = types_path.read_text(encoding="utf-8", errors="ignore")
                        marker = "C2R: TU-pinned type supplements"
                        if marker not in existing:
                            types_path.write_text(existing.rstrip("\n") + "\n" + "\n".join(reexport_block) + "\n", encoding="utf-8", errors="ignore")
                except Exception:
                    pass

            # Update remaining global-missing set after generation (avoid stale report noise).
            try:
                global_missing = {t for t in global_missing if t and t not in exported_names}
            except Exception:
                pass

        # Finalize "still missing" lists after generation attempts.
        result["global_missing_types"] = sorted({t for t in (global_missing or set()) if t})
        result["local_missing_types"] = {k: sorted(v) for k, v in sorted((local_missing_by_mod or {}).items(), key=lambda kv: kv[0])}

        # Headerless projects: ensure `types.rs` is no longer the placeholder stub even if we didn't
        # need to re-export any shared/global types.
        if not header_files_present:
            try:
                existing = types_path.read_text(encoding="utf-8", errors="ignore") if types_path.exists() else ""
            except Exception:
                existing = ""
            if "Auto-generated types module (TU truth entry)" not in (existing or ""):
                if (not existing.strip()) or ("bindgen failed to generate types" in existing) or ("placeholder definitions" in existing):
                    try:
                        content = "\n".join(
                            [
                                "//! Auto-generated types module (TU truth entry)",
                                "//!",
                                "//! - Source of truth: stage1 pinned preprocessed `.i` from tu_context_map.json",
                                "//! - Shared/global types are re-exported here (crate::types::*).",
                                "//! - Per-module private types live in each module's `local_types` submodule.",
                                "",
                                "#![allow(non_camel_case_types)]",
                                "#![allow(non_snake_case)]",
                                "#![allow(non_upper_case_globals)]",
                                "#![allow(dead_code)]",
                                "#![allow(unused)]",
                                "",
                            ]
                        )
                        types_path.write_text(content, encoding="utf-8", errors="ignore")
                    except Exception:
                        pass

        # Best-effort: update types_generation_report.json for explainability.
        try:
            report_path = self.output_dir / "types_generation_report.json"
            base = {}
            if report_path.exists():
                try:
                    base = json.loads(report_path.read_text(encoding="utf-8", errors="ignore") or "{}")
                except Exception:
                    base = {}
            if not isinstance(base, dict):
                base = {}
            # Ensure the report stays compatible with Truth-mode gates in the pipeline.
            # Headerless projects may not have run Stage A bindgen, so the report could be empty
            # before TU-truth supplements are written here.
            base.setdefault("mode", "tu_truth")
            base.setdefault("success", True)
            base.setdefault("final_output_valid", True)
            # Backward-compatible fields expected by batch_test_staged.sh summary scripts.
            base.setdefault("compile_commands_loaded", bool(getattr(self, "compile_commands_parser", None)))
            base.setdefault(
                "compile_commands_path",
                str(self.compile_commands_parser.compile_db_path) if getattr(self, "compile_commands_parser", None) else None,
            )
            base.setdefault("tu_truth", {})
            base["tu_truth"].update(
                {
                    "tu_context_map": result.get("tu_context_map"),
                    "generated_global_units": result.get("generated_global_units"),
                    "generated_local_units": result.get("generated_local_units"),
                    "global_missing_types": result.get("global_missing_types"),
                    "local_missing_types": result.get("local_missing_types"),
                    "skipped_missing_tu_i": result.get("skipped_missing_tu_i"),
                }
            )
            report_path.write_text(json.dumps(base, ensure_ascii=False, indent=2) + "\n", encoding="utf-8", errors="ignore")
        except Exception:
            pass

        return result

    def generate_globals_rs_bindgen_static(
        self,
        variables: List[VariableInfo],
        output_file: str = "globals.rs",
    ) -> Path:
        """
        Generate globals.rs using Scheme A:
        - Use bindgen allowlist on preprocessed `.i` to get *exact* Rust types for globals.
        - Emit real Rust storage: `pub static mut NAME: TYPE = zeroed();`
        - No Mutex/safe wrappers.
        """
        output_path = self.output_dir / "src" / output_file
        output_path.parent.mkdir(parents=True, exist_ok=True)
        enable_fallback = (os.environ.get("C2R_ENABLE_GLOBALS_BINDGEN_FALLBACK", "false") or "false").strip().lower() in (
            "1",
            "true",
            "yes",
        )
        # Ensure stale RustMap safe-globals metadata doesn't affect later deterministic rewrites.
        try:
            meta_path = output_path.parent / "globals_accessors.json"
            if meta_path.exists():
                meta_path.unlink()
        except Exception:
            pass

        defined_types: Set[str] = set()
        try:
            types_rs = (self.output_dir / "src" / "types.rs").read_text(encoding="utf-8", errors="ignore")
            defined_types = self._parse_defined_type_names_from_types_rs_text(types_rs)
        except Exception:
            defined_types = set()

        # Split variables:
        # - global (external linkage)
        # - file-scope `static` (internal linkage) -> Scheme B: keep module-local, NOT in globals.rs
        # - lifted function-statics
        seen_names: Set[str] = set()
        unique_vars: List[Any] = []
        for v in variables or []:
            name = getattr(v, "name", None)
            if not isinstance(name, str) or not name:
                continue
            if name in seen_names:
                continue
            seen_names.add(name)
            unique_vars.append(v)

        global_vars: List[Any] = []
        file_static_vars: List[Any] = []
        lifted_vars: List[Any] = []
        for v in unique_vars:
            if getattr(v, "from_function", None):
                lifted_vars.append(v)
            else:
                if getattr(v, "is_static", False):
                    file_static_vars.append(v)
                else:
                    global_vars.append(v)

        vars_by_origin: Dict[str, Set[str]] = defaultdict(set)
        unassigned: Set[str] = set()
        # NOTE: For type-truth generation we still need bindgen info for module-local statics.
        for v in [*global_vars, *file_static_vars]:
            origin = getattr(v, "origin_file", None) or ""
            name = getattr(v, "name", "") or ""
            if not origin:
                unassigned.add(name)
            else:
                vars_by_origin[origin].add(name)

        timeout_sec = int(os.environ.get("C2R_BINDGEN_GLOBALS_TIMEOUT_SEC", "90"))
        tmp_dir = self.output_dir / ".c2r_bindgen_globals"
        bindgen_types: Dict[str, Dict[str, str]] = {}
        origin_by_var: Dict[str, str] = {}

        def _lang_for_safe_name(safe_name: str) -> str:
            rec = self._tu_context_files.get(safe_name) if getattr(self, "_tu_context_files", None) else None
            if isinstance(rec, dict):
                p = rec.get("source_file_abs") or rec.get("source_for_cc_abs") or ""
                try:
                    suf = Path(str(p)).suffix.lower()
                except Exception:
                    suf = ""
                if suf in {".cc", ".cpp", ".cxx", ".c++"}:
                    return "c++"
            return "c"

        for safe_name, names in sorted(vars_by_origin.items(), key=lambda kv: kv[0]):
            rec = self._tu_context_files.get(safe_name) if getattr(self, "_tu_context_files", None) else None
            pre = rec.get("preprocessed_file") if isinstance(rec, dict) else None
            if not pre:
                continue
            try:
                pre_path = Path(str(pre)).expanduser()
            except Exception:
                continue
            if not pre_path.exists():
                continue
            got = self._run_bindgen_allowlist_vars(
                preprocessed_path=pre_path,
                var_names=sorted(names),
                lang=_lang_for_safe_name(safe_name),
                defined_types=defined_types,
                timeout_sec=timeout_sec,
                tmp_dir=tmp_dir,
            )
            for n, info in got.items():
                if n and isinstance(info, dict) and info.get("ty"):
                    bindgen_types.setdefault(n, dict(info))
                    origin_by_var.setdefault(str(n), str(safe_name))

        # Best-effort: scan other `.i` files for remaining vars (including those without origin_file).
        missing: Set[str] = {
            getattr(v, "name", "")
            for v in [*global_vars, *file_static_vars]
            if getattr(v, "name", "") not in bindgen_types
        }
        missing.discard("")
        missing.update(unassigned)
        missing = {m for m in missing if m and m not in bindgen_types}
        if missing and getattr(self, "_tu_context_files", None):
            for safe_name, rec in sorted(self._tu_context_files.items(), key=lambda kv: kv[0]):
                if not missing:
                    break
                if not isinstance(rec, dict):
                    continue
                pre = rec.get("preprocessed_file")
                if not pre:
                    continue
                try:
                    pre_path = Path(str(pre)).expanduser()
                except Exception:
                    continue
                if not pre_path.exists():
                    continue
                got = self._run_bindgen_allowlist_vars(
                    preprocessed_path=pre_path,
                    var_names=sorted(missing),
                    lang=_lang_for_safe_name(safe_name),
                    defined_types=defined_types,
                    timeout_sec=timeout_sec,
                    tmp_dir=tmp_dir,
                )
                if not got:
                    continue
                for n, info in got.items():
                    if n and isinstance(info, dict) and info.get("ty"):
                        bindgen_types.setdefault(n, dict(info))
                        origin_by_var.setdefault(str(n), str(safe_name))
                    missing.discard(n)

        # Scheme B: file-scope `static` variables should stay module-local (internal linkage).
        # We still derive their Rust types from bindgen on the pinned TU `.i`, but we do NOT put them in globals.rs.
        module_local_statics: Dict[str, List[Dict[str, str]]] = defaultdict(list)
        omitted_local_statics: List[Dict[str, str]] = []
        for v in file_static_vars:
            name = getattr(v, "name", "") or ""
            if not name:
                continue
            safe_name = getattr(v, "origin_file", None) or origin_by_var.get(name) or ""
            safe_name = str(safe_name) if safe_name else ""
            info = bindgen_types.get(name) or {}
            ty = str(info.get("ty") or "").strip()
            init = str(info.get("init") or "").strip()
            if not ty and enable_fallback:
                rt = getattr(v, "rust_type", "") or ""
                ty = self._prefix_types_in_rust_type_expr(rt, defined_types) if rt else ""
            if not ty:
                omitted_local_statics.append({"name": name, "origin_file": safe_name})
                continue
            module_local_statics[safe_name].append(
                {
                    "name": name,
                    "ty": ty,
                    "init": init,
                    "c_type": str(getattr(v, "c_type", "") or ""),
                }
            )

        # Persist for later phases (module file generation + TU-truth local types extraction).
        try:
            self._module_local_file_statics = {
                k: sorted(vs, key=lambda x: x.get("name") or "")
                for k, vs in sorted(module_local_statics.items(), key=lambda kv: kv[0])
                if k and vs
            }
        except Exception:
            self._module_local_file_statics = {}

        # Emit globals.rs
        lines: List[str] = [
            "//! Global and Static Variable Declarations (Scheme A: bindgen-truth static storage)",
            "//!",
            "//! - No safe wrappers (Mutex/RwLock).",
            "//! - Types are derived from bindgen on the exact preprocessed `.i` TU.",
            "//! - Storage is real Rust `static mut`, zero-initialized (C-like).",
            "//! - NOTE: file-scope `static` (internal linkage) variables are emitted in each module file (Scheme B).",
            "",
            "#![allow(non_upper_case_globals)]",
            "#![allow(non_snake_case)]",
            "#![allow(dead_code)]",
            "#![allow(unused)]",
            "",
            "use core::mem::MaybeUninit;",
            "use crate::types::*;",
            "",
        ]
        omitted_globals: List[Dict[str, str]] = []

        if global_vars:
            lines.append("// ==========================================")
            lines.append("// Global Variables (top-level)")
            lines.append("// ==========================================")
            lines.append("")

            for name in sorted({getattr(v, "name", "") for v in global_vars if getattr(v, "name", "")}):
                info = bindgen_types.get(name) or {}
                ty = str(info.get("ty") or "").strip()
                init = str(info.get("init") or "").strip()
                if not ty:
                    if enable_fallback:
                        # Emergency-only fallback: use best-effort type (tree-sitter/type-mapper).
                        # Default OFF: if bindgen can't derive a decl, we treat it as an input-closure issue and report it.
                        rt = ""
                        try:
                            for v in global_vars:
                                if getattr(v, "name", "") == name:
                                    rt = getattr(v, "rust_type", "") or ""
                                    break
                        except Exception:
                            rt = ""
                        ty = self._prefix_types_in_rust_type_expr(rt, defined_types) if rt else ""
                        if not ty:
                            ty = "*mut core::ffi::c_void"
                        lines.append("// Source: fallback (no bindgen decl found)")
                    else:
                        omitted_globals.append(
                            {
                                "name": name,
                                "origin_file": str(
                                    next(
                                        (getattr(v, "origin_file", "") or "" for v in global_vars if getattr(v, "name", "") == name),
                                        "",
                                    )
                                ),
                            }
                        )
                        lines.append("// Source: bindgen missing (declaration omitted; see globals_generation_report.json)")
                        lines.append(f"// MISSING: {name}")
                        lines.append("")
                        continue
                else:
                    lines.append("// Source: bindgen on preprocessed TU")

                # Try to extract initializer from C source files if bindgen doesn't provide one
                c_init = None
                if not init:
                    try:
                        c_source_files = self._get_project_source_files()
                        c_init = self._extract_c_array_initializer(c_source_files, name)
                        if c_init:
                            logger.info(f"ä» C æºæ–‡ä»¶æå–å…¨å±€å˜é‡ {name} çš„åˆå§‹åŒ–å€¼")
                    except Exception as e:
                        logger.debug(f"æå– {name} åˆå§‹åŒ–å€¼å¤±è´¥: {e}")

                if init:
                    lines.append(f"pub static mut {name}: {ty} = {init};")
                elif c_init:
                    lines.append(f"// Initializer extracted from C source")
                    lines.append(f"pub static mut {name}: {ty} = {c_init};")
                else:
                    lines.append(f"pub static mut {name}: {ty} = unsafe {{ MaybeUninit::<{ty}>::zeroed().assume_init() }};")
                lines.append("")

        if lifted_vars:
            lines.append("// ==========================================")
            lines.append("// Lifted Static Variables (from functions)")
            lines.append("// ==========================================")
            lines.append("")

            by_fn: Dict[str, List[Any]] = defaultdict(list)
            for v in lifted_vars:
                by_fn[str(getattr(v, "from_function", "") or "")].append(v)
            for fn in sorted(by_fn.keys()):
                if not fn:
                    continue
                lines.append(f"// From function: {fn}()")
                for v in by_fn[fn]:
                    name = getattr(v, "name", "") or ""
                    c_type = getattr(v, "c_type", "") or ""
                    rt = getattr(v, "rust_type", "") or ""
                    ty = self._prefix_types_in_rust_type_expr(rt, defined_types) if rt else ""
                    if not ty:
                        ty = "*mut core::ffi::c_void"
                    if c_type:
                        original_name = name.replace(f"{fn}_", "")
                        lines.append(f"/// Originally: static {c_type} {original_name}")
                    lines.append(f"pub static mut {name}: {ty} = unsafe {{ MaybeUninit::<{ty}>::zeroed().assume_init() }};")
                lines.append("")

        if not variables:
            lines.append("// No global or static variables found in this project.")
            lines.append("")

        output_path.write_text("\n".join(lines), encoding="utf-8")
        # Dedup across files: if globals.rs defines real Rust storage for a global, keep it only in globals.rs.
        # bindgen also emits `extern "C" { pub static mut NAME: ...; }` in types.rs, which causes
        # ambiguous-name errors (E0659) when modules import both `crate::types::*` and `crate::globals::*`.
        try:
            types_path = output_path.parent / "types.rs"
            removed = self._remove_duplicate_extern_statics_from_types_rs(
                globals_rs_path=output_path,
                types_rs_path=types_path,
            )
            if removed:
                logger.info(f"types.rs å»é‡: ç§»é™¤ {removed} ä¸ªä¸ globals.rs é‡å¤çš„ extern static å£°æ˜")
        except Exception:
            pass
        # 2026-01-07 ä¿®å¤: åŒæ ·å»é‡ compat.rsï¼Œé¿å… E0659 æ­§ä¹‰é”™è¯¯
        # compat.rs çš„ C2R_EXTERN_VARS å—å¯èƒ½å£°æ˜äº†ä¸ globals.rs é‡å¤çš„å˜é‡ (å¦‚ stderr, incs ç­‰)
        try:
            compat_path = output_path.parent / "compat.rs"
            if compat_path.exists():
                removed_compat = self._remove_duplicate_extern_statics_from_types_rs(
                    globals_rs_path=output_path,
                    types_rs_path=compat_path,  # å¤ç”¨åŒä¸€å»é‡é€»è¾‘
                )
                if removed_compat:
                    logger.info(f"compat.rs å»é‡: ç§»é™¤ {removed_compat} ä¸ªä¸ globals.rs é‡å¤çš„ extern static å£°æ˜")
        except Exception:
            pass
        # Save a machine-readable report for diagnosing "globals closure" issues.
        try:
            report_path = self.output_dir / "globals_generation_report.json"
            report = {
                "generated_at": datetime.now().isoformat(timespec="seconds"),
                "mode": "bindgen_static",
                "globals_total": len(global_vars),
                "file_static_total": len(file_static_vars),
                "module_local_static_total": int(
                    sum(len(v) for v in (getattr(self, "_module_local_file_statics", {}) or {}).values())
                ),
                "lifted_total": len(lifted_vars),
                "bindgen_ok": len(bindgen_types),
                "bindgen_missing_names": sorted(missing),
                "omitted_globals": omitted_globals,
                "omitted_module_local_statics": omitted_local_statics,
                "enable_fallback": enable_fallback,
                "tu_context_map": str(getattr(self, "_tu_context_map_path", "") or ""),
            }
            report_path.write_text(json.dumps(report, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")
        except Exception:
            pass
        logger.info(
            f"ç”Ÿæˆ globals.rs (bindgen_static): {len(global_vars)} ä¸ªé¡¶å±‚å˜é‡ + {len(file_static_vars)} ä¸ªæ¨¡å—å†… static + {len(lifted_vars)} ä¸ªæå‡å˜é‡ "
            f"(bindgen_ok={len(bindgen_types)}, fallback_missing={len(missing)})"
        )
        return output_path

    @staticmethod
    def _extract_pub_static_names_from_globals_rs(globals_text: str) -> Set[str]:
        """
        Extract `pub static (mut)? NAME:` names from globals.rs (Scheme A).
        """
        if not globals_text:
            return set()
        try:
            return set(re.findall(r"(?m)^\s*pub\s+static(?:\s+mut)?\s+([A-Za-z_]\w*)\s*:", globals_text))
        except Exception:
            return set()

    def _remove_duplicate_extern_statics_from_types_rs(
        self,
        *,
        globals_rs_path: Path,
        types_rs_path: Path,
    ) -> int:
        """
        Remove `extern "C" { pub static ...; }` entries from types.rs when the same global is defined
        in globals.rs (real Rust storage). This prevents E0659 ambiguous-name failures.
        """
        if not globals_rs_path or not globals_rs_path.exists():
            return 0
        if not types_rs_path or not types_rs_path.exists():
            return 0
        try:
            globals_text = globals_rs_path.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            globals_text = ""
        names = self._extract_pub_static_names_from_globals_rs(globals_text)
        if not names:
            return 0
        try:
            types_text = types_rs_path.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            types_text = ""
        if not types_text:
            return 0

        lines = types_text.splitlines()
        out: List[str] = []
        removed = 0
        i = 0
        while i < len(lines):
            ln = lines[i]
            s = (ln or "").strip()
            m = re.match(r"^(?:pub\s+)?static\s+(?:mut\s+)?([A-Za-z_]\w*)\s*:", s)
            if m:
                name = (m.group(1) or "").strip()
                if name and name in names:
                    # Drop directly-attached attributes above this item (bindgen uses #[doc = ...], #[link_name = ...], etc).
                    while out and (out[-1] or "").strip().startswith("#["):
                        out.pop()
                    removed += 1
                    # Skip until the end of the declaration (`;`), in case bindgen wraps long types.
                    while i < len(lines):
                        if ";" in (lines[i] or ""):
                            i += 1
                            break
                        i += 1
                    # Also drop a single trailing blank line to keep formatting tidy.
                    if i < len(lines) and (lines[i] or "").strip() == "":
                        i += 1
                    continue
            out.append(ln)
            i += 1

        if removed <= 0:
            return 0

        new_text = "\n".join(out) + ("\n" if types_text.endswith("\n") else "")
        try:
            types_rs_path.write_text(new_text, encoding="utf-8", errors="ignore")
        except Exception:
            return 0
        return removed
    
    def generate_globals_rs(
        self, 
        variables: List[VariableInfo], 
        output_file: str = "globals.rs",
        use_safe_wrappers: bool = False
    ) -> Path:
        """
        ç”Ÿæˆ globals.rs æ–‡ä»¶
        
        åŸºäº EvoC2Rust çš„å˜é‡å°è£…ç­–ç•¥ï¼š
        - ç®€å•ç±»å‹ä½¿ç”¨ static mut
        - å¤æ‚ç±»å‹ä½¿ç”¨ static mutï¼ˆéœ€è¦ unsafe è®¿é—®ï¼‰
        - å‡½æ•°å†…æå‡çš„ static å˜é‡æ·»åŠ å‡½æ•°åå‰ç¼€
        
        å¢å¼ºåŠŸèƒ½ï¼š
        - use_safe_wrappers=True æ—¶ï¼Œä½¿ç”¨ Mutex/RwLock å°è£…ï¼ˆæ›´å®‰å…¨ä½†æ€§èƒ½ç•¥ä½ï¼‰
        
        Args:
            variables: å˜é‡åˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶å
            use_safe_wrappers: æ˜¯å¦ä½¿ç”¨å®‰å…¨åŒ…è£…ï¼ˆMutex/lazy_staticï¼‰
        
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        output_path = self.output_dir / "src" / output_file
        
        if use_safe_wrappers:
            return self._generate_safe_globals_rs(variables, output_path)
        
        lines = [
            '//! Global and Static Variable Declarations',
            '//!',
            '//! Auto-generated from C source code using tree-sitter analysis.',
            '//!',
            '//! ## Variable Lifting (Static Promotion)',
            '//! C allows `static` variables inside functions, but Rust does not.',
            '//! These variables are "lifted" to module level with function name prefix.',
            '//!',
            '//! Example:',
            '//! ```c',
            '//! void foo() { static int count = 0; }  // C code',
            '//! ```',
            '//! Becomes:',
            '//! ```rust',
            '//! static mut foo_count: i32 = 0;  // Rust code',
            '//! ```',
            '//!',
            '//! ## Usage',
            '//! Access these variables using `unsafe`:',
            '//! ```rust',
            '//! unsafe { foo_count += 1; }',
            '//! ```',
            '',
            '#![allow(non_upper_case_globals)]',
            '#![allow(non_snake_case)]',
            '#![allow(dead_code)]',
            '#![allow(unused)]',
            '',
        ]

        # Normalize and qualify pthread initializers in generated declarations.
        # This avoids fragile `use crate::types::...` imports that can mismatch across libc/boards
        # (e.g. `__PTHREAD_MUTEX_INITIALIZER` vs `PTHREAD_MUTEX_INITIALIZER`).
        pthread_aliases = {
            "__PTHREAD_MUTEX_INITIALIZER": "PTHREAD_MUTEX_INITIALIZER",
            "__PTHREAD_COND_INITIALIZER": "PTHREAD_COND_INITIALIZER",
            "__PTHREAD_RWLOCK_INITIALIZER": "PTHREAD_RWLOCK_INITIALIZER",
            "__PTHREAD_ONCE_INIT": "PTHREAD_ONCE_INIT",
        }
        pthread_constants = sorted(set(pthread_aliases.values()))

        def _fix_pthread_initializers_in_decl(decl: str) -> str:
            if not decl:
                return decl
            for src, dst in pthread_aliases.items():
                if src in decl:
                    decl = decl.replace(src, dst)
            for name in pthread_constants:
                decl = re.sub(rf'(?<!crate::types::)\b{name}\b', f'crate::types::{name}', decl)
            return decl
        
        # å»é‡ï¼šé˜²æ­¢åŒåå˜é‡é‡å¤å£°æ˜ï¼ˆå¯èƒ½æ¥è‡ªå¤šä¸ªæºæ–‡ä»¶ï¼‰
        seen_names = set()
        unique_variables = []
        for var in variables:
            if var.name not in seen_names:
                seen_names.add(var.name)
                unique_variables.append(var)
            else:
                logger.debug(f"è·³è¿‡é‡å¤å˜é‡: {var.name}")
        
        # åˆ†ç±»å˜é‡
        global_vars = []      # é¡¶å±‚å…¨å±€å˜é‡
        lifted_vars = []      # ä»å‡½æ•°å†…æå‡çš„ static å˜é‡
        
        for var in unique_variables:
            if var.from_function:
                lifted_vars.append(var)
            else:
                global_vars.append(var)
        
        # ç”Ÿæˆé¡¶å±‚å…¨å±€å˜é‡
        if global_vars:
            lines.append('// ==========================================')
            lines.append('// Global Variables (top-level declarations)')
            lines.append('// ==========================================')
            lines.append('')
            for var in global_vars:
                lines.append(f'/// C type: {var.c_type}')
                decl = _fix_pthread_initializers_in_decl(getattr(var, "rust_declaration", "") or "")
                lines.append(decl)
                lines.append('')
        
        # ç”Ÿæˆæå‡çš„ static å˜é‡
        if lifted_vars:
            lines.append('// ==========================================')
            lines.append('// Lifted Static Variables (from functions)')
            lines.append('// ==========================================')
            lines.append('')
            
            # æŒ‰æºå‡½æ•°åˆ†ç»„
            from collections import defaultdict
            by_function = defaultdict(list)
            for var in lifted_vars:
                by_function[var.from_function].append(var)
            
            for func_name in sorted(by_function.keys()):
                lines.append(f'// From function: {func_name}()')
                for var in by_function[func_name]:
                    original_name = var.name.replace(f"{func_name}_", "")
                    lines.append(f'/// Originally: static {var.c_type} {original_name}')
                    decl = _fix_pthread_initializers_in_decl(getattr(var, "rust_declaration", "") or "")
                    lines.append(decl)
                lines.append('')
        
        # å¦‚æœæ²¡æœ‰å˜é‡ï¼Œæ·»åŠ å ä½ç¬¦
        if not variables:
            lines.append('// No global or static variables found in this project.')
            lines.append('')
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        logger.info(f"ç”Ÿæˆ globals.rs: {len(variables)} ä¸ªå˜é‡ (å…¶ä¸­ {len(lifted_vars)} ä¸ªæå‡)")
        return output_path
    
    def _generate_safe_globals_rs(self, variables: List[VariableInfo], output_path: Path) -> Path:
        """
        ç”Ÿæˆ RustMap é£æ ¼çš„â€œå®‰å…¨å…¨å±€å˜é‡â€globals.rsï¼ˆè§„åˆ™ä¸ºä¸»ï¼ŒLLM ä¸ºè¾…ï¼‰

        ç­–ç•¥ï¼ˆä¸ RustMap çš„æè¿°å¯¹é½ï¼‰ï¼š
        - å¯¹â€œprimitive/C-POD/æŒ‡é’ˆâ€ç±»å…¨å±€å˜é‡ï¼šä½¿ç”¨ `Mutex<T>` æ‰˜ç®¡ï¼Œå¹¶ç”Ÿæˆ getter/setter/with_* API
          è¿™æ ·å‡½æ•°ä½“é‡Œæ— éœ€ `unsafe { static mut }`ï¼Œå¹¶ä¸”å¤©ç„¶çº¿ç¨‹å®‰å…¨ã€‚
        - å¯¹å¤æ‚ç±»å‹ï¼ˆstruct/union/æ•°ç»„/æœªçŸ¥åˆå§‹åŒ–ï¼‰ï¼šä»ä¿æŒ `static mut`ï¼ˆä¿æŒå¯ç¼–è¯‘ä¼˜å…ˆï¼‰

        è¯´æ˜ï¼š
        - è¿™é‡Œä¸ä¾èµ– `lazy_static`ï¼Œé¿å…é¢å¤– Cargo ä¾èµ–ï¼›Rust 1.9x æ”¯æŒ `static Mutex::new(...)`ã€‚
        - ä»…å¯¹â€œèƒ½ const åˆå§‹åŒ–â€çš„é»˜è®¤å€¼åš Mutex åˆå§‹åŒ–ï¼›å¤æ‚ç±»å‹ç•™ç»™åç»­ä¿®å¤/è¯­ä¹‰é˜¶æ®µå¤„ç†ã€‚
        """
        def _sanitize_ident(name: str) -> str:
            s = re.sub(r"[^0-9A-Za-z_]", "_", name or "")
            if not s:
                return "_"
            if s[0].isdigit():
                s = "_" + s
            keywords = {
                "as",
                "break",
                "const",
                "continue",
                "crate",
                "else",
                "enum",
                "extern",
                "false",
                "fn",
                "for",
                "if",
                "impl",
                "in",
                "let",
                "loop",
                "match",
                "mod",
                "move",
                "mut",
                "pub",
                "ref",
                "return",
                "self",
                "Self",
                "static",
                "struct",
                "super",
                "trait",
                "true",
                "type",
                "unsafe",
                "use",
                "where",
                "while",
                "async",
                "await",
                "dyn",
            }
            if s in keywords:
                s = s + "_"
            return s

        def _type_base(t: str) -> str:
            return (t or "").strip().replace("crate::types::", "")

        def _is_mutex_safe(var: VariableInfo) -> bool:
            if var.is_array:
                return False
            rt = (var.rust_type or "").strip()
            if not rt:
                return False
            if "[" in rt or "]" in rt:
                return False
            if "MaybeUninit" in rt:
                return False
            # Pointers and primitive scalars are OK.
            if rt.startswith("*mut ") or rt.startswith("*const "):
                return True
            base = _type_base(rt)
            primitives = {
                "i8",
                "u8",
                "i16",
                "u16",
                "i32",
                "u32",
                "i64",
                "u64",
                "isize",
                "usize",
                "f32",
                "f64",
                "bool",
                # common libc typedef aliases
                "c_char",
                "c_schar",
                "c_uchar",
                "c_short",
                "c_ushort",
                "c_int",
                "c_uint",
                "c_long",
                "c_ulong",
                "c_longlong",
                "c_ulonglong",
                "size_t",
                "ssize_t",
                "pid_t",
                "uid_t",
                "gid_t",
                "time_t",
                "off_t",
            }
            if base in primitives:
                return True
            # Anything else under crate::types is likely a struct/union -> not safe by default.
            if rt.startswith("crate::types::"):
                return False
            return False

        def _default_expr(rt: str) -> str:
            rt = (rt or "").strip()
            if rt.startswith("*mut "):
                # NOTE: pointer safe-globals use `Mutex<usize>` storage, so default is 0.
                return "0"
            if rt.startswith("*const "):
                return "0"
            base = _type_base(rt)
            if base == "bool":
                return "false"
            if base in {"f32", "f64"}:
                return "0.0"
            return "0"

        # Normalize and qualify pthread initializers in generated declarations.
        pthread_aliases = {
            "__PTHREAD_MUTEX_INITIALIZER": "PTHREAD_MUTEX_INITIALIZER",
            "__PTHREAD_COND_INITIALIZER": "PTHREAD_COND_INITIALIZER",
            "__PTHREAD_RWLOCK_INITIALIZER": "PTHREAD_RWLOCK_INITIALIZER",
            "__PTHREAD_ONCE_INIT": "PTHREAD_ONCE_INIT",
        }
        pthread_constants = sorted(set(pthread_aliases.values()))

        def _fix_pthread_initializers_in_decl(decl: str) -> str:
            if not decl:
                return decl
            for src, dst in pthread_aliases.items():
                if src in decl:
                    decl = decl.replace(src, dst)
            for name in pthread_constants:
                decl = re.sub(rf"(?<!crate::types::)\\b{name}\\b", f"crate::types::{name}", decl)
            return decl

        lines: List[str] = [
            '//! Global and Static Variable Declarations (RustMap-style Safe Globals)',
            '//!',
            '//! Auto-generated from C source code using tree-sitter analysis.',
            '//!',
            '//! Safe globals (primitive/pointer) are wrapped in `Mutex<T>` and accessed via getters/setters.',
            '//! Complex globals stay as `static mut` as a compilation-first fallback.',
            '',
            '#![allow(non_upper_case_globals)]',
            '#![allow(non_snake_case)]',
            '#![allow(dead_code)]',
            '#![allow(unused)]',
            '',
            'use std::sync::Mutex;',
            '',
        ]

        # å»é‡ï¼šé˜²æ­¢åŒåå˜é‡é‡å¤å£°æ˜ï¼ˆå¯èƒ½æ¥è‡ªå¤šä¸ªæºæ–‡ä»¶ï¼‰
        seen_names: Set[str] = set()
        unique_variables: List[VariableInfo] = []
        for var in variables:
            if var.name in seen_names:
                continue
            seen_names.add(var.name)
            unique_variables.append(var)

        # åˆ†ç±»å˜é‡
        global_vars: List[VariableInfo] = []
        lifted_vars: List[VariableInfo] = []
        for var in unique_variables:
            if var.from_function:
                lifted_vars.append(var)
            else:
                global_vars.append(var)

        meta: Dict[str, Any] = {
            "mode": "rustmap",
            "safe_globals": [],
            "unsafe_globals": [],
        }

        def _emit_var_group(title: str, vars_list: List[VariableInfo], *, is_lifted: bool):
            if not vars_list:
                return
            lines.append("// ==========================================")
            lines.append(f"// {title}")
            lines.append("// ==========================================")
            lines.append("")

            for var in vars_list:
                safe_ident = _sanitize_ident(var.name)
                is_safe = _is_mutex_safe(var)

                if is_safe:
                    cell_name = _sanitize_ident(var.name).upper()
                    get_fn = f"get_{safe_ident}"
                    set_fn = f"set_{safe_ident}"
                    with_fn = f"with_{safe_ident}"
                    default_expr = _default_expr(var.rust_type)
                    lines.append(f"/// C type: {var.c_type}")
                    if is_lifted and var.from_function:
                        original_name = var.name.replace(f"{var.from_function}_", "")
                        lines.append(f"/// Originally: static {var.c_type} {original_name} in {var.from_function}()")
                    # IMPORTANT:
                    # - `Mutex<T>` in a `static` requires `T: Send` (so that `Mutex<T>: Sync`).
                    # - Raw pointers / NonNull are NOT `Send` on recent Rust, so `Mutex<*mut T>` fails to compile.
                    # Strategy:
                    # - For pointer-typed globals, store as `usize` (which is `Send`) and cast in accessors.
                    rt = (var.rust_type or "").strip()
                    if rt.startswith("*mut ") or rt.startswith("*const "):
                        lines.append(f"// NOTE: pointer global stored as usize for `static Mutex` compatibility.")
                        lines.append(f"pub static {cell_name}: Mutex<usize> = Mutex::new({default_expr});")
                        lines.append(
                            f"pub fn {get_fn}() -> {rt} {{ *{cell_name}.lock().unwrap() as {rt} }}"
                        )
                        lines.append(
                            f"pub fn {set_fn}(v: {rt}) {{ *{cell_name}.lock().unwrap() = v as usize; }}"
                        )
                        lines.append(f"pub fn {with_fn}<R>(f: impl FnOnce(&mut {rt}) -> R) -> R {{")
                        lines.append(f"    let mut guard = {cell_name}.lock().unwrap();")
                        lines.append(f"    let mut tmp: {rt} = *guard as {rt};")
                        lines.append("    let r = f(&mut tmp);")
                        lines.append("    *guard = tmp as usize;")
                        lines.append("    r")
                        lines.append("}")
                    else:
                        lines.append(f"pub static {cell_name}: Mutex<{rt}> = Mutex::new({default_expr});")
                        lines.append(f"pub fn {get_fn}() -> {rt} {{ *{cell_name}.lock().unwrap() }}")
                        lines.append(f"pub fn {set_fn}(v: {rt}) {{ *{cell_name}.lock().unwrap() = v; }}")
                        lines.append(f"pub fn {with_fn}<R>(f: impl FnOnce(&mut {rt}) -> R) -> R {{")
                        lines.append(f"    let mut guard = {cell_name}.lock().unwrap();")
                        lines.append("    f(&mut *guard)")
                        lines.append("}")
                    lines.append("")
                    meta["safe_globals"].append(
                        {
                            "name": var.name,
                            "sanitized": safe_ident,
                            "rust_type": var.rust_type,
                            "cell": cell_name,
                            "get": get_fn,
                            "set": set_fn,
                            "with": with_fn,
                            "from_function": var.from_function,
                        }
                    )
                else:
                    # Keep original declaration (usually `pub static mut ...`) for complex types.
                    lines.append(f"/// C type: {var.c_type}")
                    if is_lifted and var.from_function:
                        original_name = var.name.replace(f"{var.from_function}_", "")
                        lines.append(f"/// Originally: static {var.c_type} {original_name} in {var.from_function}()")
                    decl = _fix_pthread_initializers_in_decl(getattr(var, "rust_declaration", "") or "")
                    lines.append(decl)
                    lines.append("")
                    meta["unsafe_globals"].append(
                        {
                            "name": var.name,
                            "rust_type": var.rust_type,
                            "decl": decl,
                            "from_function": var.from_function,
                        }
                    )

        _emit_var_group("Global Variables (top-level)", global_vars, is_lifted=False)
        _emit_var_group("Lifted Static Variables (from functions)", lifted_vars, is_lifted=True)

        if not variables:
            lines.append("// No global or static variables found in this project.")
            lines.append("")

        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text("\n".join(lines), encoding="utf-8")

        # Also emit a machine-readable map for deterministic rewriting passes.
        try:
            meta_path = output_path.parent / "globals_accessors.json"
            meta_path.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8")
        except Exception:
            pass

        logger.info(
            f"ç”Ÿæˆ RustMap é£æ ¼ globals.rs: {len(variables)} ä¸ªå˜é‡ "
            f"(safe={len(meta['safe_globals'])}, unsafe={len(meta['unsafe_globals'])})"
        )
        return output_path
    
    def _get_safe_type_and_default(self, var: VariableInfo) -> Tuple[str, str]:
        """
        è·å–ç”¨äº Mutex å°è£…çš„å®‰å…¨ç±»å‹å’Œé»˜è®¤å€¼
        
        Returns:
            (ç±»å‹å­—ç¬¦ä¸², é»˜è®¤å€¼å­—ç¬¦ä¸²)
        """
        rust_type = var.rust_type
        
        # å¤„ç†æŒ‡é’ˆç±»å‹ -> Option<NonNull<T>>
        if rust_type.startswith('*mut ') or rust_type.startswith('*const '):
            inner_type = rust_type.replace('*mut ', '').replace('*const ', '')
            return f"Option<std::ptr::NonNull<{inner_type}>>", "None"
        
        # å¤„ç†åŸºç¡€ç±»å‹
        if rust_type in ['i32', 'u32', 'i64', 'u64', 'i16', 'u16', 'i8', 'u8', 'usize', 'isize']:
            return rust_type, "0"
        elif rust_type in ['f32', 'f64']:
            return rust_type, "0.0"
        elif rust_type == 'bool':
            return "bool", "false"
        
        # å¤æ‚ç±»å‹ -> Option<T>
        if rust_type.startswith('crate::types::'):
            return f"Option<{rust_type}>", "None"
        
        # MaybeUninit ç±»å‹ -> Option<T>
        if 'MaybeUninit' in rust_type:
            # æå–å†…éƒ¨ç±»å‹
            inner_match = re.search(r'MaybeUninit<(.+)>', rust_type)
            if inner_match:
                inner_type = inner_match.group(1)
                return f"Option<{inner_type}>", "None"
        
        # é»˜è®¤æƒ…å†µ
        return f"Option<{rust_type}>", "None"
    
    # =========================================================================
    # é˜¶æ®µ C: å‡½æ•°éª¨æ¶å±‚ (The Logic Skeleton)
    # =========================================================================
    
    def _preprocess_source_for_parsing(self, source_code: str) -> str:
        """
        é¢„å¤„ç†æºç ä»¥æé«˜ Tree-sitter è§£ææˆåŠŸç‡
        
        å¤„ç†çš„é—®é¢˜ï¼š
        1. Windows æ¢è¡Œç¬¦ (CRLF) å¯¼è‡´è§£æé—®é¢˜
        2. #ifdef __cplusplus extern "C" { #endif å¯¼è‡´è§£ææ··ä¹±
        3. æ¡ä»¶ç¼–è¯‘åŒ…è£¹çš„ extern "C" å—
        
        ç­–ç•¥ï¼š
        - ç»Ÿä¸€æ¢è¡Œç¬¦ä¸º LF
        - ç§»é™¤ #ifdef __cplusplus ... extern "C" { ... #endif åŒ…è£…
        - ç§»é™¤å¯¹åº”çš„ #ifdef __cplusplus } #endif ç»“æŸæ ‡è®°
        - ä¿ç•™å®é™…çš„ä»£ç å†…å®¹
        """
        import re
        
        # é¦–å…ˆç»Ÿä¸€æ¢è¡Œç¬¦ (CRLF -> LF)
        processed = source_code.replace('\r\n', '\n').replace('\r', '\n')
        
        # æ¨¡å¼1: ç§»é™¤å¼€å§‹çš„ #ifdef __cplusplus extern "C" { #endif
        # è¿™ç§æ¨¡å¼ä¼šå¯¼è‡´ Tree-sitter CPP parser æ··ä¹±
        pattern_start = r'#ifdef\s+__cplusplus\s*\n\s*extern\s+"C"\s*\{\s*\n\s*#endif'
        processed = re.sub(pattern_start, '/* extern "C" removed for parsing */', processed)
        
        # æ¨¡å¼2: ç§»é™¤ç»“æŸçš„ #ifdef __cplusplus } #endif  
        pattern_end = r'#ifdef\s+__cplusplus\s*\n\s*\}\s*\n\s*#endif'
        processed = re.sub(pattern_end, '/* extern "C" end removed */', processed)
        
        # æ¨¡å¼3: å¤„ç†æ›´ç´§å‡‘çš„æ ¼å¼
        pattern_start_compact = r'#ifdef\s+__cplusplus\s+extern\s+"C"\s*\{\s+#endif'
        processed = re.sub(pattern_start_compact, '', processed)
        
        pattern_end_compact = r'#ifdef\s+__cplusplus\s+\}\s+#endif'
        processed = re.sub(pattern_end_compact, '', processed)
        
        return processed
    
    def extract_function_signatures(self, source_code: str) -> List[FunctionSignature]:
        """
        ä½¿ç”¨ Tree-sitter æå–æ‰€æœ‰å‡½æ•°ç­¾å
        
        å¢å¼ºåŠŸèƒ½ï¼š
        1. æ”¯æŒ C++ ç±»æˆå‘˜å‡½æ•° (method_definition)
        2. æ”¯æŒ extern "C" å—å†…çš„å‡½æ•° (linkage_specification)
        3. æ”¯æŒ namespace å†…çš„å‡½æ•°
        4. é¢„å¤„ç†ç§»é™¤ #ifdef __cplusplus extern "C" åŒ…è£…ï¼ˆé¿å…è§£æé”™è¯¯ï¼‰
        5. AST å¥åº·æ£€æŸ¥ï¼šæ£€æµ‹ ERROR èŠ‚ç‚¹ï¼Œé¢„è­¦è§£æé—®é¢˜
        
        Returns:
            å‡½æ•°ç­¾ååˆ—è¡¨
        """
        signatures = []
        seen_funcs = set()  # é¿å…é‡å¤
        
        try:
            # é¢„å¤„ç†æºç ï¼Œç§»é™¤ä¼šå¯¼è‡´è§£æé—®é¢˜çš„æ¡ä»¶ç¼–è¯‘å—
            processed_source = self._preprocess_source_for_parsing(source_code)
            
            # å…³é”®ï¼šå°†å­—ç¬¦ä¸²è½¬æ¢ä¸º bytesï¼ŒTree-sitter ä½¿ç”¨å­—èŠ‚åç§»
            # å¿…é¡»ç”¨ bytes æ¥æå–å†…å®¹ï¼Œå¦åˆ™ä¸­æ–‡æ³¨é‡Šç­‰å¤šå­—èŠ‚å­—ç¬¦ä¼šå¯¼è‡´åç§»é”™è¯¯
            processed_bytes = bytes(processed_source, 'utf-8')
            tree = cpp_parser.parse(processed_bytes)
            
            # ========== 0. AST å¥åº·æ£€æŸ¥ (åŸºäº EvoC2Rust çš„ç­–ç•¥) ==========
            health_report = self._check_ast_health(tree.root_node)
            if not health_report['is_healthy']:
                logger.warning(
                    f"âš ï¸ AST è§£æè´¨é‡è­¦å‘Š: é”™è¯¯ç‡ {health_report['error_rate']:.1%} "
                    f"({health_report['error_nodes']}/{health_report['total_nodes']} èŠ‚ç‚¹)"
                )
                if health_report['error_rate'] > 0.2:  # è¶…è¿‡ 20% é”™è¯¯ç‡
                    logger.error(
                        "âŒ AST é”™è¯¯ç‡è¿‡é«˜ï¼Œå‡½æ•°æå–ç»“æœå¯èƒ½ä¸å¯é ã€‚"
                        "å»ºè®®ï¼š1) æ£€æŸ¥æºæ–‡ä»¶è¯­æ³•ï¼›2) å°è¯• gcc é¢„å¤„ç†"
                    )
            
            # ========== 1. é€’å½’æå–æ‰€æœ‰å‡½æ•°å®šä¹‰ (åŒ…æ‹¬ extern "C" å’Œ namespace å—) ==========
            all_func_nodes = self._find_all_function_definitions(tree.root_node)
            
            for func_node in all_func_nodes:
                sig = self._parse_function_definition(func_node, processed_bytes)
                if sig:
                    func_key = f"{sig.name}_{len(sig.parameters)}"
                    if func_key not in seen_funcs:
                        signatures.append(sig)
                        seen_funcs.add(func_key)
            
            # ========== 2. æŸ¥è¯¢ C++ ç±»æˆå‘˜å‡½æ•° (è§£å†³ "No functions found" é—®é¢˜) ==========
            cpp_methods = self._extract_cpp_method_signatures(tree.root_node, processed_bytes)
            for sig in cpp_methods:
                func_key = f"{sig.name}_{len(sig.parameters)}"
                if func_key not in seen_funcs:
                    signatures.append(sig)
                    seen_funcs.add(func_key)
                        
        except Exception as e:
            logger.warning(f"Tree-sitter å‡½æ•°æå–å¤±è´¥: {e}")
        
        return signatures
    
    def _check_ast_health(self, root_node) -> dict:
        """
        æ£€æŸ¥ AST å¥åº·åº¦ï¼ˆåŸºäº EvoC2Rust çš„ if_parse_error æ–¹æ³•ï¼‰
        
        éå† AST ç»Ÿè®¡ ERROR èŠ‚ç‚¹æ•°é‡ï¼Œè¯„ä¼°è§£æè´¨é‡ã€‚
        
        Args:
            root_node: Tree-sitter AST æ ¹èŠ‚ç‚¹
        
        Returns:
            dict: {
                'total_nodes': int,
                'error_nodes': int,
                'error_rate': float,
                'is_healthy': bool,
                'error_locations': list  # [(line, col), ...]
            }
        """
        total_nodes = 0
        error_nodes = 0
        error_locations = []
        
        def traverse(node):
            nonlocal total_nodes, error_nodes
            total_nodes += 1
            
            if node.type == 'ERROR':
                error_nodes += 1
                error_locations.append((
                    node.start_point[0] + 1,  # è¡Œå·ä»1å¼€å§‹
                    node.start_point[1]
                ))
            
            for child in node.children:
                traverse(child)
        
        traverse(root_node)
        
        error_rate = error_nodes / total_nodes if total_nodes > 0 else 0.0
        
        # é˜ˆå€¼ï¼š5% é”™è¯¯ç‡ä»¥ä¸‹è®¤ä¸ºå¥åº·
        is_healthy = error_rate <= 0.05
        
        return {
            'total_nodes': total_nodes,
            'error_nodes': error_nodes,
            'error_rate': error_rate,
            'is_healthy': is_healthy,
            'error_locations': error_locations[:10]  # åªä¿ç•™å‰10ä¸ª
        }
    
    def _find_all_function_definitions(self, node) -> List:
        """
        é€’å½’æŸ¥æ‰¾æ‰€æœ‰ function_definition èŠ‚ç‚¹
        
        è§£å†³çš„é—®é¢˜ï¼š
        1. extern "C" { } å—å†…çš„å‡½æ•° (linkage_specification)
        2. namespace { } å—å†…çš„å‡½æ•° (namespace_definition)
        3. #ifdef __cplusplus å—å†…çš„å‡½æ•° (preproc_ifdef, preproc_if, preproc_else)
        4. é¡¶å±‚å‡½æ•°
        
        Args:
            node: AST èŠ‚ç‚¹
            
        Returns:
            æ‰€æœ‰ function_definition èŠ‚ç‚¹åˆ—è¡¨
        """
        func_nodes = []
        
        if node.type == 'function_definition':
            func_nodes.append(node)
            return func_nodes  # æ‰¾åˆ°å‡½æ•°å®šä¹‰åä¸å†æ·±å…¥
        
        # éœ€è¦é€’å½’å¤„ç†çš„å®¹å™¨èŠ‚ç‚¹ç±»å‹
        container_types = {
            'linkage_specification',    # extern "C" { }
            'namespace_definition',      # namespace X { }
            'declaration_list',          # { } å†…çš„å£°æ˜åˆ—è¡¨
            'translation_unit',          # é¡¶å±‚
            'preproc_ifdef',             # #ifdef ... #endif
            'preproc_if',                # #if ... #endif
            'preproc_else',              # #else
            'preproc_elif',              # #elif
            'compound_statement',        # { } å—
        }
        
        # é€’å½’å¤„ç†æ‰€æœ‰å­èŠ‚ç‚¹
        for child in node.children:
            if child.type == 'function_definition':
                func_nodes.append(child)
            else:
                # å¯¹æ‰€æœ‰å­èŠ‚ç‚¹éƒ½é€’å½’æŸ¥æ‰¾ï¼ˆç¡®ä¿ä¸é—æ¼åµŒå¥—çš„å‡½æ•°ï¼‰
                func_nodes.extend(self._find_all_function_definitions(child))
        
        return func_nodes
    
    def _extract_cpp_method_signatures(self, root_node, source_code: str) -> List[FunctionSignature]:
        """
        æå– C++ ç±»æˆå‘˜å‡½æ•°ç­¾å
        
        å¤„ç†çš„æƒ…å†µï¼š
        1. ç±»å†…å®šä¹‰çš„æ–¹æ³• (inline)
        2. ç±»å¤–å®šä¹‰çš„æ–¹æ³• (ClassName::methodName)
        3. åµŒå¥—å‘½åç©ºé—´å†…çš„æ–¹æ³• (Namespace::Class::method)
        
        ä¿®å¤ï¼š
        - æ”¯æŒ type_identifier (ç±»å) ä½œä¸º scope
        - æ”¯æŒ namespace_identifier (å‘½åç©ºé—´) ä½œä¸º scope  
        - æ”¯æŒåµŒå¥—çš„ qualified_identifier
        
        Returns:
            å‡½æ•°ç­¾ååˆ—è¡¨
        """
        methods = []
        seen_methods = set()  # é¿å…é‡å¤
        
        try:
            # 1. æŸ¥è¯¢ç±»å†…æ–¹æ³•å®šä¹‰
            # (class_specifier body: (field_declaration_list (function_definition)))
            class_query = CPP_LANGUAGE.query("""
                (class_specifier
                    name: (type_identifier) @class_name
                    body: (field_declaration_list) @class_body
                )
            """)
            
            class_captures = class_query.captures(root_node)
            
            class_name = None
            for node, cap_name in class_captures:
                if cap_name == 'class_name':
                    class_name = self._extract_text(source_code, node.start_byte, node.end_byte)
                elif cap_name == 'class_body' and class_name:
                    # åœ¨ç±»ä½“å†…æŸ¥æ‰¾å‡½æ•°å®šä¹‰
                    class_methods = self._find_methods_in_class_body(node, source_code, class_name)
                    for sig in class_methods:
                        method_key = f"{sig.name}_{len(sig.parameters)}"
                        if method_key not in seen_methods:
                            methods.append(sig)
                            seen_methods.add(method_key)
                    class_name = None
            
            # 2. æŸ¥è¯¢ç±»å¤–æ–¹æ³•å®šä¹‰ - ä½¿ç”¨å¤šç§æ¨¡å¼åŒ¹é…
            # æ¨¡å¼ A: ClassName::methodName (type_identifier ä½œä¸º scope)
            cpp_methods_a = self._extract_methods_with_type_scope(root_node, source_code, seen_methods)
            methods.extend(cpp_methods_a)
            
            # æ¨¡å¼ B: Namespace::methodName (namespace_identifier ä½œä¸º scope)
            cpp_methods_b = self._extract_methods_with_namespace_scope(root_node, source_code, seen_methods)
            methods.extend(cpp_methods_b)
            
            # æ¨¡å¼ C: é€’å½’éå†æŸ¥æ‰¾ qualified_identifier (å¤„ç†å¤æ‚åµŒå¥—)
            cpp_methods_c = self._extract_methods_recursive(root_node, source_code, seen_methods)
            methods.extend(cpp_methods_c)
                    
        except Exception as e:
            logger.debug(f"C++ æ–¹æ³•æå–å¤±è´¥: {e}")
        
        return methods
    
    def _extract_methods_with_type_scope(self, root_node, source_code: str, seen_methods: set) -> List[FunctionSignature]:
        """æå–ä½¿ç”¨ type_identifier (ç±»å) ä½œä¸º scope çš„æ–¹æ³•"""
        methods = []
        try:
            # æŸ¥è¯¢: ClassName::methodName å½¢å¼
            query = CPP_LANGUAGE.query("""
                (function_definition
                    declarator: (function_declarator
                        declarator: (qualified_identifier
                            scope: (type_identifier) @class_name
                            name: (identifier) @method_name
                        )
                    )
                ) @method_def
            """)
            
            captures = query.captures(root_node)
            
            class_name = None
            method_name = None
            for node, cap_name in captures:
                if cap_name == 'class_name':
                    class_name = self._extract_text(source_code, node.start_byte, node.end_byte)
                elif cap_name == 'method_name':
                    method_name = self._extract_text(source_code, node.start_byte, node.end_byte)
                elif cap_name == 'method_def' and class_name and method_name:
                    sig = self._parse_cpp_method_definition(node, source_code, class_name, method_name)
                    if sig:
                        method_key = f"{sig.name}_{len(sig.parameters)}"
                        if method_key not in seen_methods:
                            methods.append(sig)
                            seen_methods.add(method_key)
                    class_name = None
                    method_name = None
        except Exception as e:
            logger.debug(f"type_identifier æ–¹æ³•æå–å¤±è´¥: {e}")
        
        return methods
    
    def _extract_methods_with_namespace_scope(self, root_node, source_code: str, seen_methods: set) -> List[FunctionSignature]:
        """æå–ä½¿ç”¨ namespace_identifier ä½œä¸º scope çš„æ–¹æ³•"""
        methods = []
        try:
            query = CPP_LANGUAGE.query("""
                (function_definition
                    declarator: (function_declarator
                        declarator: (qualified_identifier
                            scope: (namespace_identifier) @ns_name
                            name: (identifier) @method_name
                        )
                    )
                ) @method_def
            """)
            
            captures = query.captures(root_node)
            
            ns_name = None
            method_name = None
            for node, cap_name in captures:
                if cap_name == 'ns_name':
                    ns_name = self._extract_text(source_code, node.start_byte, node.end_byte)
                elif cap_name == 'method_name':
                    method_name = self._extract_text(source_code, node.start_byte, node.end_byte)
                elif cap_name == 'method_def' and ns_name and method_name:
                    sig = self._parse_cpp_method_definition(node, source_code, ns_name, method_name)
                    if sig:
                        method_key = f"{sig.name}_{len(sig.parameters)}"
                        if method_key not in seen_methods:
                            methods.append(sig)
                            seen_methods.add(method_key)
                    ns_name = None
                    method_name = None
        except Exception as e:
            logger.debug(f"namespace_identifier æ–¹æ³•æå–å¤±è´¥: {e}")
        
        return methods
    
    def _extract_methods_recursive(self, root_node, source_code: str, seen_methods: set) -> List[FunctionSignature]:
        """
        é€’å½’éå† AST æŸ¥æ‰¾æ‰€æœ‰å¸¦ qualified_identifier çš„å‡½æ•°å®šä¹‰
        
        å¤„ç†å¤æ‚åµŒå¥—æƒ…å†µå¦‚ï¼š
        - OHOS::NWeb::AccessTokenAdapterImpl::GetInstance()
        - namespace::class::method()
        """
        methods = []
        
        def extract_qualified_name(node) -> Tuple[Optional[str], Optional[str]]:
            """ä» qualified_identifier èŠ‚ç‚¹æå– scope å’Œ name"""
            scope_parts = []
            method_name = None
            
            for child in node.children:
                if child.type in ['namespace_identifier', 'type_identifier']:
                    scope_parts.append(self._extract_text(source_code, child.start_byte, child.end_byte))
                elif child.type == 'identifier':
                    method_name = self._extract_text(source_code, child.start_byte, child.end_byte)
                elif child.type == 'qualified_identifier':
                    # é€’å½’å¤„ç†åµŒå¥—çš„ qualified_identifier
                    inner_scope, inner_name = extract_qualified_name(child)
                    if inner_scope:
                        scope_parts.append(inner_scope)
                    if inner_name:
                        scope_parts.append(inner_name)
            
            scope = '_'.join(scope_parts) if scope_parts else None
            return scope, method_name
        
        def visit(node):
            if node.type == 'function_definition':
                # æŸ¥æ‰¾ function_declarator
                for child in node.children:
                    if child.type == 'function_declarator':
                        for sub in child.children:
                            if sub.type == 'qualified_identifier':
                                scope, method_name = extract_qualified_name(sub)
                                if scope and method_name:
                                    sig = self._parse_cpp_method_definition(node, source_code, scope, method_name)
                                    if sig:
                                        method_key = f"{sig.name}_{len(sig.parameters)}"
                                        if method_key not in seen_methods:
                                            methods.append(sig)
                                            seen_methods.add(method_key)
                        break
            
            for child in node.children:
                visit(child)
        
        visit(root_node)
        return methods
    
    def _find_methods_in_class_body(
        self, 
        class_body_node, 
        source_code: str, 
        class_name: str
    ) -> List[FunctionSignature]:
        """åœ¨ç±»ä½“å†…æŸ¥æ‰¾æ–¹æ³•å®šä¹‰"""
        methods = []
        
        for child in class_body_node.children:
            if child.type == 'function_definition':
                sig = self._parse_function_definition(child, source_code)
                if sig:
                    # æ ‡è®°ä¸ºç±»æ–¹æ³•
                    sig.name = f"{class_name}_{sig.name}"  # æ·»åŠ ç±»åå‰ç¼€
                    sig.is_callback = True  # æˆå‘˜æ–¹æ³•å¯èƒ½ä½œä¸ºå›è°ƒ
                    methods.append(sig)
            elif child.type == 'declaration':
                # å¯èƒ½æ˜¯æˆå‘˜å‡½æ•°å£°æ˜ï¼ˆåªæœ‰å£°æ˜æ²¡æœ‰å®šä¹‰ï¼‰
                pass  # æˆ‘ä»¬ä¸»è¦å…³æ³¨å®šä¹‰
        
        return methods
    
    def _parse_cpp_method_definition(
        self, 
        func_node, 
        source_code,  # æ”¯æŒ bytes æˆ– str
        class_name: str,
        method_name: str
    ) -> Optional[FunctionSignature]:
        """è§£æ C++ ç±»å¤–æ–¹æ³•å®šä¹‰ï¼ˆæ”¯æŒ bytes å’Œ str è¾“å…¥ï¼‰"""
        try:
            func_text = self._extract_text(source_code, func_node.start_byte, func_node.end_byte)
            
            # æå–å‡½æ•°ç­¾åï¼ˆä¸å«å‡½æ•°ä½“ï¼‰
            brace_pos = func_text.find('{')
            if brace_pos == -1:
                return None
            
            c_signature = func_text[:brace_pos].strip()
            
            # æå–è¿”å›ç±»å‹
            return_type = self._extract_return_type(func_node, source_code)
            
            # æå–å‚æ•°
            parameters = self._extract_parameters(func_node, source_code)
            
            # å‚æ•°åå»é‡
            if TYPE_UTILS_AVAILABLE:
                parameters = sanitize_parameter_names(parameters)
            
            # ä½¿ç”¨ ClassName_methodName ä½œä¸ºå‡½æ•°å
            full_name = f"{class_name}_{method_name}"
            
            return FunctionSignature(
                name=full_name,
                c_signature=c_signature,
                rust_signature="",
                return_type=return_type,
                parameters=parameters,
                is_static=False,
                is_callback=True  # C++ æ–¹æ³•é€šå¸¸éœ€è¦ç‰¹æ®Šå¤„ç†
            )
            
        except Exception as e:
            logger.debug(f"è§£æ C++ æ–¹æ³•å¤±è´¥: {e}")
            return None
    
    def _extract_text(self, source, start_byte: int, end_byte: int) -> str:
        """
        ä» source ä¸­æå–æ–‡æœ¬ï¼Œæ­£ç¡®å¤„ç† bytes å’Œ str
        
        Tree-sitter è¿”å›å­—èŠ‚åç§»ï¼Œä½† Python str çš„ç´¢å¼•æ˜¯å­—ç¬¦åç§»ã€‚
        å½“æºç åŒ…å«å¤šå­—èŠ‚å­—ç¬¦ï¼ˆå¦‚ä¸­æ–‡æ³¨é‡Šï¼‰æ—¶ï¼Œä¼šå¯¼è‡´åç§»ä¸åŒ¹é…ã€‚
        
        Args:
            source: bytes æˆ– str
            start_byte: å¼€å§‹å­—èŠ‚åç§»
            end_byte: ç»“æŸå­—èŠ‚åç§»
            
        Returns:
            æå–çš„æ–‡æœ¬å­—ç¬¦ä¸²
        """
        if isinstance(source, bytes):
            return source[start_byte:end_byte].decode('utf-8', errors='ignore')
        else:
            # å¦‚æœæ˜¯ strï¼Œéœ€è¦è½¬æ¢ä¸º bytes å†æå–
            source_bytes = source.encode('utf-8')
            return source_bytes[start_byte:end_byte].decode('utf-8', errors='ignore')
    
    def _parse_function_definition(self, func_node, source_code) -> Optional[FunctionSignature]:
        """
        è§£æå‡½æ•°å®šä¹‰èŠ‚ç‚¹ï¼ˆæ”¯æŒ bytes å’Œ str è¾“å…¥ï¼‰
        
        å¢å¼ºåŠŸèƒ½ï¼ˆåŸºäº EvoC2Rust çš„é€’å½’å£°æ˜å™¨æŸ¥æ‰¾ï¼‰ï¼š
        - æ”¯æŒæŒ‡é’ˆè¿”å›ç±»å‹: Type* func()
        - æ”¯æŒå¼•ç”¨è¿”å›ç±»å‹: Type& func() (C++)
        - æ”¯æŒå¤šçº§æŒ‡é’ˆ: Type** func()
        - æ”¯æŒå¤æ‚åµŒå¥—: const Type* const * func()
        """
        try:
            func_text = self._extract_text(source_code, func_node.start_byte, func_node.end_byte)
            
            # æå–å‡½æ•°ç­¾åï¼ˆä¸å«å‡½æ•°ä½“ï¼‰
            brace_pos = func_text.find('{')
            if brace_pos == -1:
                return None
            
            c_signature = func_text[:brace_pos].strip()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ static å‡½æ•°
            is_static = c_signature.strip().startswith('static')
            
            # ========== å¢å¼ºï¼šé€’å½’æŸ¥æ‰¾å‡½æ•°å£°æ˜å™¨ ==========
            # è§£å†³ Type& func() å’Œ Type* func() ç­‰å¤æ‚æƒ…å†µ
            func_name = None
            declarator_wrappers = []  # è®°å½•å£°æ˜å™¨åŒ…è£…å±‚ï¼ˆæŒ‡é’ˆ/å¼•ç”¨ï¼‰
            
            # ä½¿ç”¨é€’å½’æŸ¥æ‰¾å‡½æ•°å£°æ˜å™¨
            func_name, declarator_wrappers = self._find_function_declarator_recursive(func_node, source_code)
            
            if not func_name:
                # å›é€€åˆ°åŸå§‹æ–¹æ³•
                for child in func_node.children:
                    if child.type == 'function_declarator':
                        for sub in child.children:
                            if sub.type == 'identifier':
                                func_name = self._extract_text(source_code, sub.start_byte, sub.end_byte)
                                break
            
            if not func_name:
                return None
            
            # === ä¼˜åŒ–ç‚¹ 1: è¿‡æ»¤éæ³•å‡½æ•°å (è§£å†³ pathselect/pack/installer å´©æºƒé—®é¢˜) ===
            if TYPE_UTILS_AVAILABLE:
                if not is_valid_c_identifier(func_name):
                    logger.debug(f"è·³è¿‡éæ³•å‡½æ•°å: {func_name}")
                    return None
            
            # æå–è¿”å›ç±»å‹
            return_type = self._extract_return_type(func_node, source_code)
            
            # === ä¼˜åŒ–ç‚¹ 2: æ”¶é›†è¿”å›å€¼ç±»å‹ (è§£å†³ E0412) ===
            if TYPE_UTILS_AVAILABLE:
                ret_base = extract_base_type(return_type)
                # è¿‡æ»¤æ‰åŸºç¡€ç±»å‹
                if ret_base and ret_base not in ['int', 'char', 'void', 'float', 'double', 'long', 'short', '_Bool', 'bool', 'unsigned', 'signed', 'size_t', 'ssize_t', 'ptrdiff_t', 'intptr_t', 'uintptr_t', 'uint8_t', 'uint16_t', 'uint32_t', 'uint64_t', 'int8_t', 'int16_t', 'int32_t', 'int64_t']:
                    self.collected_custom_types.add(ret_base)
            
            # æå–å‚æ•°
            parameters = self._extract_parameters(func_node, source_code)
            
            # === ä¼˜åŒ–ç‚¹ 3: æ”¶é›†å‚æ•°ç±»å‹ (è§£å†³ E0412) ===
            if TYPE_UTILS_AVAILABLE:
                for _, p_type in parameters:
                    p_base = extract_base_type(p_type)
                    # è¿‡æ»¤æ‰åŸºç¡€ç±»å‹
                    if p_base and p_base not in ['int', 'char', 'void', 'float', 'double', 'long', 'short', '_Bool', 'bool', 'unsigned', 'signed', 'size_t', 'ssize_t', 'ptrdiff_t', 'intptr_t', 'uintptr_t', 'uint8_t', 'uint16_t', 'uint32_t', 'uint64_t', 'int8_t', 'int16_t', 'int32_t', 'int64_t']:
                        self.collected_custom_types.add(p_base)
            
            # === ä¼˜åŒ–ç‚¹ 4: å‚æ•°åå»é‡ (è§£å†³ ipc_auth E0415) ===
            if TYPE_UTILS_AVAILABLE:
                parameters = sanitize_parameter_names(parameters)
            
            return FunctionSignature(
                name=func_name,
                c_signature=c_signature,
                rust_signature="",  # ç¨åç”± LLM ç”Ÿæˆ
                return_type=return_type,
                parameters=parameters,
                is_static=is_static
            )
            
        except Exception as e:
            logger.debug(f"è§£æå‡½æ•°å®šä¹‰å¤±è´¥: {e}")
            return None
    
    def _find_function_declarator_recursive(
        self, 
        node, 
        source_code
    ) -> Tuple[Optional[str], List[str]]:
        """
        é€’å½’æŸ¥æ‰¾å‡½æ•°å£°æ˜å™¨å¹¶æå–å‡½æ•°å
        
        å‚è€ƒ EvoC2Rust çš„ has_function_declarator æ–¹æ³•
        
        è§£å†³çš„é—®é¢˜ï¼š
        - Type& func() -> reference_declarator > function_declarator
        - Type* func() -> pointer_declarator > function_declarator
        - Type** func() -> pointer_declarator > pointer_declarator > function_declarator
        - const Type* const* func() -> å¤æ‚åµŒå¥—
        
        Args:
            node: è¦æœç´¢çš„ AST èŠ‚ç‚¹
            source_code: æºä»£ç ï¼ˆbytes æˆ– strï¼‰
        
        Returns:
            (func_name, declarator_wrappers)
            - func_name: å‡½æ•°å
            - declarator_wrappers: å£°æ˜å™¨åŒ…è£…å±‚åˆ—è¡¨ ["pointer", "reference", ...]
        """
        wrappers = []
        
        def search(n):
            """é€’å½’æœç´¢"""
            nonlocal wrappers
            
            if n.type == 'function_declarator':
                # æ‰¾åˆ°å‡½æ•°å£°æ˜å™¨ï¼Œæå–å‡½æ•°å
                for child in n.children:
                    if child.type == 'identifier':
                        return self._extract_text(source_code, child.start_byte, child.end_byte)
                    elif child.type == 'field_identifier':
                        return self._extract_text(source_code, child.start_byte, child.end_byte)
                    elif child.type == 'qualified_identifier':
                        return self._extract_text(source_code, child.start_byte, child.end_byte)
                    elif child.type == 'parenthesized_declarator':
                        # å‡½æ•°æŒ‡é’ˆæƒ…å†µ
                        result = search(child)
                        if result:
                            return result
                return None
            
            elif n.type == 'pointer_declarator':
                wrappers.append('pointer')
                # ç»§ç»­å‘ä¸‹æœç´¢
                for child in n.children:
                    if child.type in ('function_declarator', 'pointer_declarator', 
                                     'reference_declarator', 'identifier'):
                        result = search(child)
                        if result:
                            return result
            
            elif n.type == 'reference_declarator':
                wrappers.append('reference')
                # ç»§ç»­å‘ä¸‹æœç´¢
                for child in n.children:
                    if child.type in ('function_declarator', 'pointer_declarator', 
                                     'reference_declarator', 'identifier'):
                        result = search(child)
                        if result:
                            return result
            
            elif n.type == 'identifier':
                # ç›´æ¥æ‰¾åˆ°æ ‡è¯†ç¬¦
                return self._extract_text(source_code, n.start_byte, n.end_byte)
            
            # é€’å½’æœç´¢æ‰€æœ‰å­èŠ‚ç‚¹
            for child in n.children:
                result = search(child)
                if result:
                    return result
            
            return None
        
        func_name = search(node)
        return func_name, wrappers
    
    def _extract_return_type(self, func_node, source_code) -> str:
        """æå–è¿”å›ç±»å‹ï¼ˆæ”¯æŒ bytes å’Œ str è¾“å…¥ï¼‰

        å¢å¼ºåŠŸèƒ½ï¼ˆ2025-12-23ï¼‰ï¼š
        - æ”¯æŒè¿”å›æŒ‡é’ˆç±»å‹ï¼Œå¦‚ int*, char**, void*
        - æ”¯æŒè¿”å›å¼•ç”¨ç±»å‹ï¼Œå¦‚ int&
        - æ­£ç¡®å¤„ç†å£°æ˜å™¨ä¸­çš„æŒ‡é’ˆ/å¼•ç”¨ä¿¡æ¯
        """
        # å°è¯•æå–å®Œæ•´çš„è¿”å›ç±»å‹ï¼ˆåŒ…æ‹¬ static, const ç­‰ä¿®é¥°ç¬¦ï¼‰
        return_type_parts = []
        pointer_count = 0
        reference_count = 0

        # æŸ¥æ‰¾ç±»å‹è¯´æ˜ç¬¦èŠ‚ç‚¹
        for child in func_node.children:
            if child.type in ['type_identifier', 'primitive_type', 'sized_type_specifier']:
                return_type_parts.append(self._extract_text(source_code, child.start_byte, child.end_byte))
            elif child.type == 'storage_class_specifier':
                # static ç­‰å­˜å‚¨ç±»è¯´æ˜ç¬¦
                text = self._extract_text(source_code, child.start_byte, child.end_byte)
                if text == 'static':
                    # static ä¸æ˜¯è¿”å›ç±»å‹çš„ä¸€éƒ¨åˆ†ï¼Œè·³è¿‡
                    continue
            elif child.type == 'type_qualifier':
                # const, volatile ç­‰ç±»å‹é™å®šç¬¦
                return_type_parts.append(self._extract_text(source_code, child.start_byte, child.end_byte))
            elif child.type == 'struct_specifier':
                # struct xxx ç±»å‹
                struct_text = self._extract_text(source_code, child.start_byte, child.end_byte)
                return_type_parts.append(struct_text)
            elif child.type == 'enum_specifier':
                # enum xxx ç±»å‹
                enum_text = self._extract_text(source_code, child.start_byte, child.end_byte)
                return_type_parts.append(enum_text)
            elif child.type == 'pointer_declarator':
                # â˜… å¢å¼ºï¼šè®¡ç®—æŒ‡é’ˆå±‚æ•°
                pointer_count += self._count_pointer_levels(child)
            elif child.type == 'reference_declarator':
                # â˜… å¢å¼ºï¼šå¼•ç”¨ç±»å‹
                reference_count += 1

        # æ„å»ºè¿”å›ç±»å‹å­—ç¬¦ä¸²
        if return_type_parts:
            base_type = ' '.join(return_type_parts)
            # æ·»åŠ æŒ‡é’ˆæ ‡è®°
            if pointer_count > 0:
                base_type += '*' * pointer_count
            elif reference_count > 0:
                base_type += '&' * reference_count
            return base_type
        return 'void'

    def _count_pointer_levels(self, declarator_node) -> int:
        """è®¡ç®—å£°æ˜å™¨ä¸­çš„æŒ‡é’ˆå±‚æ•°

        ç”¨äºå¤„ç†å¤šçº§æŒ‡é’ˆè¿”å›ç±»å‹ï¼Œå¦‚ char** æˆ– int***
        """
        count = 0
        node = declarator_node

        while node is not None:
            if node.type == 'pointer_declarator':
                count += 1
                # ç»§ç»­æŸ¥æ‰¾åµŒå¥—çš„ pointer_declarator
                for child in node.children:
                    if child.type == 'pointer_declarator':
                        node = child
                        break
                else:
                    break
            else:
                break

        return count
    
    def _extract_parameters(self, func_node, source_code) -> List[Tuple[str, str]]:
        """æå–å‚æ•°åˆ—è¡¨ï¼ˆæ”¯æŒ bytes å’Œ str è¾“å…¥ï¼‰

        å¢å¼ºåŠŸèƒ½ï¼ˆ2025-12-23ï¼‰ï¼š
        - é€’å½’å¤„ç†åµŒå¥—å£°æ˜å™¨ï¼ˆå¤šçº§æŒ‡é’ˆã€æ•°ç»„ã€å‡½æ•°æŒ‡é’ˆï¼‰
        - è§£å†³å‚æ•°åæå–å¤±è´¥å¯¼è‡´çš„é‡å¤ 'arg' é—®é¢˜

        ä¿®å¤ï¼ˆ2026-01-08ï¼‰ï¼š
        - é€’å½’æŸ¥æ‰¾ function_declaratorï¼Œè§£å†³è¿”å›æŒ‡é’ˆç±»å‹å‡½æ•°å‚æ•°ä¸¢å¤±é—®é¢˜
        - å¯¹äº char * func(char *arg)ï¼Œfunction_declarator åµŒå¥—åœ¨ pointer_declarator ä¸­
        """
        params = []

        def extract_identifier_recursive(node) -> Optional[str]:
            """é€’å½’æå–æ ‡è¯†ç¬¦åç§°ï¼Œå¤„ç†åµŒå¥—å£°æ˜å™¨"""
            if node is None:
                return None

            # ç›´æ¥æ˜¯æ ‡è¯†ç¬¦
            if node.type == 'identifier':
                return self._extract_text(source_code, node.start_byte, node.end_byte)

            # é€’å½’å¤„ç†å„ç§å£°æ˜å™¨ç±»å‹
            if node.type in ['pointer_declarator', 'reference_declarator',
                             'array_declarator', 'parenthesized_declarator']:
                for child in node.children:
                    result = extract_identifier_recursive(child)
                    if result:
                        return result

            # å‡½æ•°æŒ‡é’ˆ: void (*callback)(int)
            # ç»“æ„: function_declarator > parenthesized_declarator > pointer_declarator > identifier
            if node.type == 'function_declarator':
                for child in node.children:
                    if child.type in ['parenthesized_declarator', 'pointer_declarator']:
                        result = extract_identifier_recursive(child)
                        if result:
                            return result
                    elif child.type == 'identifier':
                        return self._extract_text(source_code, child.start_byte, child.end_byte)

            return None

        def find_function_declarator(node):
            """é€’å½’æŸ¥æ‰¾ function_declarator èŠ‚ç‚¹

            è§£å†³è¿”å›æŒ‡é’ˆç±»å‹å‡½æ•°çš„å‚æ•°æå–é—®é¢˜ï¼š
            - _Bool func(char *arg): function_definition â†’ function_declarator (ç›´æ¥å­èŠ‚ç‚¹)
            - char * func(char *arg): function_definition â†’ pointer_declarator â†’ function_declarator (åµŒå¥—)
            """
            if node is None:
                return None
            if node.type == 'function_declarator':
                return node
            # åœ¨ pointer_declarator / reference_declarator / parenthesized_declarator ä¸­é€’å½’æŸ¥æ‰¾
            if node.type in ['pointer_declarator', 'reference_declarator', 'parenthesized_declarator']:
                for child in node.children:
                    result = find_function_declarator(child)
                    if result:
                        return result
            return None

        # æŸ¥æ‰¾ function_declaratorï¼ˆæ”¯æŒç›´æ¥å­èŠ‚ç‚¹å’ŒåµŒå¥—åœ¨ pointer_declarator ä¸­çš„æƒ…å†µï¼‰
        func_declarator = None
        for child in func_node.children:
            if child.type == 'function_declarator':
                func_declarator = child
                break
            elif child.type in ['pointer_declarator', 'reference_declarator', 'parenthesized_declarator']:
                # è¿”å›æŒ‡é’ˆ/å¼•ç”¨ç±»å‹çš„å‡½æ•°ï¼Œfunction_declarator åµŒå¥—åœ¨å†…éƒ¨
                func_declarator = find_function_declarator(child)
                if func_declarator:
                    break

        if func_declarator:
            for sub in func_declarator.children:
                if sub.type == 'parameter_list':
                    for param in sub.children:
                        if param.type == 'parameter_declaration':
                            # æå–å‚æ•°ç±»å‹å’Œåç§°
                            param_type_parts = []
                            param_name = None
                            is_pointer = False
                            is_array = False

                            for param_child in param.children:
                                if param_child.type in ['type_identifier', 'primitive_type', 'sized_type_specifier']:
                                    param_type_parts.append(self._extract_text(source_code, param_child.start_byte, param_child.end_byte))
                                elif param_child.type == 'type_qualifier':
                                    param_type_parts.append(self._extract_text(source_code, param_child.start_byte, param_child.end_byte))
                                elif param_child.type == 'struct_specifier':
                                    # å¤„ç† struct xxx ç±»å‹
                                    struct_text = self._extract_text(source_code, param_child.start_byte, param_child.end_byte)
                                    param_type_parts.append(struct_text)
                                elif param_child.type == 'enum_specifier':
                                    # å¤„ç† enum xxx ç±»å‹
                                    enum_text = self._extract_text(source_code, param_child.start_byte, param_child.end_byte)
                                    param_type_parts.append(enum_text)
                                elif param_child.type == 'union_specifier':
                                    # å¤„ç† union xxx ç±»å‹
                                    union_text = self._extract_text(source_code, param_child.start_byte, param_child.end_byte)
                                    param_type_parts.append(union_text)
                                elif param_child.type == 'identifier':
                                    param_name = self._extract_text(source_code, param_child.start_byte, param_child.end_byte)
                                elif param_child.type in ['pointer_declarator', 'reference_declarator']:
                                    is_pointer = True
                                    # ä½¿ç”¨é€’å½’æå–
                                    param_name = extract_identifier_recursive(param_child)
                                elif param_child.type == 'array_declarator':
                                    # æ•°ç»„å‚æ•°: int arr[10]
                                    is_array = True
                                    param_name = extract_identifier_recursive(param_child)
                                elif param_child.type == 'function_declarator':
                                    # å‡½æ•°æŒ‡é’ˆå‚æ•°: void (*callback)(int)
                                    is_pointer = True
                                    param_name = extract_identifier_recursive(param_child)
                                elif param_child.type == 'abstract_declarator':
                                    # åŒ¿åå‚æ•°ï¼ˆåªæœ‰ç±»å‹æ²¡æœ‰åå­—ï¼‰ï¼Œå¦‚: void func(int *, char[])
                                    is_pointer = '*' in self._extract_text(source_code, param_child.start_byte, param_child.end_byte)

                            # æ„å»ºå‚æ•°ç±»å‹å­—ç¬¦ä¸²
                            param_type = ' '.join(param_type_parts)
                            if is_pointer:
                                param_type += '*'
                            elif is_array:
                                param_type += '[]'

                            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å‚æ•°åï¼Œä½¿ç”¨é»˜è®¤å€¼
                            if not param_name:
                                param_name = 'arg'

                            params.append((param_name, param_type))

        return params
    
    def _collect_types_from_signature(self, sig: FunctionSignature):
        """
        ä»å‡½æ•°ç­¾åä¸­æ”¶é›†è‡ªå®šä¹‰ç±»å‹
        
        è¿™æ˜¯ finalize_types_rs() èƒ½æ­£ç¡®å·¥ä½œçš„å…³é”®ã€‚
        TypeMapper æœ¬èº«ä¸ä¼šæ”¶é›†ç±»å‹ï¼Œæ‰€ä»¥éœ€è¦åœ¨è°ƒç”¨ TypeMapper ä¹‹å‰æ‰‹åŠ¨æ”¶é›†ã€‚
        """
        if not TYPE_UTILS_AVAILABLE:
            return
        
        # åŸºç¡€ç±»å‹åˆ—è¡¨ï¼ˆä¸éœ€è¦æ”¶é›†ï¼‰
        primitives = {
            'int', 'char', 'void', 'float', 'double', 'long', 'short', '_Bool', 'bool',
            'unsigned', 'signed', 'size_t', 'ssize_t', 'ptrdiff_t', 'intptr_t', 'uintptr_t',
            'uint8_t', 'uint16_t', 'uint32_t', 'uint64_t',
            'int8_t', 'int16_t', 'int32_t', 'int64_t',
            'u8', 'u16', 'u32', 'u64', 's8', 's16', 's32', 's64',
            '__u8', '__u16', '__u32', '__u64', '__s8', '__s16', '__s32', '__s64',
        }
        
        # æ”¶é›†è¿”å›ç±»å‹
        if sig.return_type:
            ret_base = extract_base_type(sig.return_type)
            if ret_base and ret_base not in primitives:
                self.collected_custom_types.add(ret_base)
        
        # æ”¶é›†å‚æ•°ç±»å‹
        for _, param_type in sig.parameters:
            if param_type:
                p_base = extract_base_type(param_type)
                if p_base and p_base not in primitives:
                    self.collected_custom_types.add(p_base)
    
    def generate_function_stubs(
        self, 
        signatures: List[FunctionSignature], 
        llm_translate_fn=None,
        use_type_mapper: bool = True,
        use_llm_type_mapper: bool = False
    ) -> Dict[str, str]:
        """
        ç”Ÿæˆå‡½æ•°æ¡©ä»£ç 
        
        Args:
            signatures: å‡½æ•°ç­¾ååˆ—è¡¨
            llm_translate_fn: å¯é€‰çš„ LLM ç¿»è¯‘å‡½æ•°ï¼Œç­¾åä¸º (c_signature: str) -> str
            use_type_mapper: æ˜¯å¦ä½¿ç”¨ TypeMapperï¼ˆç¡®å®šæ€§è§„åˆ™å¼•æ“ï¼‰ï¼Œé»˜è®¤ True
            use_llm_type_mapper: æ˜¯å¦ä½¿ç”¨ LLMTypeMapperï¼ˆTypeMapper + LLM éªŒè¯/ä¿®æ­£ï¼‰ï¼Œé»˜è®¤ False
        
        Returns:
            Dict[func_name, rust_stub_code]
        """
        stubs = {}

        def _use_existing_rust_signature(sig: FunctionSignature) -> bool:
            """
            If `sig.rust_signature` is already populated (e.g., from bindgen allowlist on TU `.i`),
            we should treat it as the source of truth and avoid re-generating it via TypeMapper/LLM.
            """
            try:
                rs = (sig.rust_signature or "").strip()
            except Exception:
                rs = ""
            if not rs:
                return False
            # `bindgen` decls may end with `;` (extern blocks). We need a signature line for stub generation.
            if rs.endswith(";"):
                rs = rs[:-1].rstrip()
            # Basic sanity: must look like a Rust fn signature.
            if " fn " not in f" {rs} ":
                return False
            sig.rust_signature = rs
            try:
                stubs[sig.name] = self._generate_stub(sig)
            except Exception:
                stubs[sig.name] = f"{rs} {{\n    unimplemented!()\n}}"
            return True

        # LLM å¯¹â€œè§„åˆ™ç­¾åâ€è¿›è¡Œå¤æ ¸/è£å†³ï¼ˆé»˜è®¤å¼€å¯ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡å…³é—­ï¼‰ã€‚
        # - å…³é—­ï¼šC2R_LLM_REFINE_SIGNATURES=0
        # - types.rs ä¼šåšåˆ‡ç‰‡ï¼ˆé¿å…æŠŠæ•´ä»½ types.rs å¡è¿› promptï¼‰
        sig_refiner = None
        if self._env_flag("C2R_TRUTH_MODE", "0"):
            # Truth-mode: keep signatures fully deterministic (no LLM refiner).
            sig_refiner = None
        else:
            try:
                from llm_signature_refiner import build_refiner_from_env  # type: ignore

                sig_refiner = build_refiner_from_env(types_rs_path=(self.output_dir / "src" / "types.rs"))
                if sig_refiner is not None:
                    logger.info("å·²å¯ç”¨ç­¾å LLM å¤æ ¸ï¼ˆé»˜è®¤å¼€å¯ï¼Œå¯ç”¨ C2R_LLM_REFINE_SIGNATURES=0 å…³é—­ï¼‰")
            except Exception as e:
                logger.debug(f"åˆå§‹åŒ–ç­¾å LLM å¤æ ¸å¤±è´¥ï¼Œè·³è¿‡: {e}")
        
        # å¦‚æœå¯ç”¨ LLMTypeMapperï¼Œåˆ›å»ºå®ä¾‹
        # æ³¨æ„ï¼šLLMTypeMapper ä¼šå¯¹æ¯ä¸ªå‚æ•°/è¿”å›ç±»å‹åˆ†åˆ«è°ƒç”¨ä¸€æ¬¡ LLMï¼Œè°ƒç”¨æ¬¡æ•°â‰ˆ(å‚æ•°æ•°+1)ã€‚
        llm_type_mapper_instance = None
        if use_llm_type_mapper and LLM_TYPE_MAPPER_AVAILABLE:
            try:
                types_rs_path = self.output_dir / "src" / "types.rs"
                llm_type_mapper_instance = create_llm_type_mapper(
                    types_rs_path=types_rs_path if types_rs_path.exists() else None,
                    enable_llm=True
                )
                logger.info("LLMTypeMapper å·²åˆå§‹åŒ–ï¼Œå°†ä½¿ç”¨ LLM è¾…åŠ©éªŒè¯ç±»å‹æ˜ å°„")
            except Exception as e:
                logger.warning(f"LLMTypeMapper åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå›é€€åˆ° TypeMapper")
        
        # ä¼˜å…ˆä½¿ç”¨ TypeMapperï¼ˆç¡®å®šæ€§è§„åˆ™å¼•æ“ï¼‰
        if use_type_mapper and TYPE_MAPPER_AVAILABLE:
            for sig in signatures:
                try:
                    # If signature was already produced by a deterministic tool (e.g., bindgen),
                    # keep it intact. This avoids accidental parameter-name/type-name collisions
                    # and keeps skeleton signatures consistent with TU truth.
                    if _use_existing_rust_signature(sig):
                        continue

                    # ========== å…³é”®ä¿®å¤ï¼šæ”¶é›†è‡ªå®šä¹‰ç±»å‹ï¼ˆTypeMapper æœ¬èº«ä¸æ”¶é›†ï¼‰==========
                    self._collect_types_from_signature(sig)
                    
                    # å¦‚æœå¯ç”¨ LLMTypeMapperï¼Œä½¿ç”¨ LLM è¾…åŠ©æ˜ å°„å‚æ•°å’Œè¿”å›ç±»å‹
                    if llm_type_mapper_instance:
                        try:
                            # ç”¨ LLMTypeMapper å¤„ç†æ¯ä¸ªå‚æ•°ç±»å‹
                            mapped_params = []
                            for param_name, param_type in sig.parameters:
                                # è§£ææŒ‡é’ˆ/const/æ•°ç»„ä¿¡æ¯ï¼ˆä» C ç±»å‹å­—ç¬¦ä¸²ä¸­æå–ï¼‰
                                c_type = (param_type or "").strip()
                                is_ptr = "*" in c_type
                                is_const = "const" in c_type
                                is_array = "[" in c_type and "]" in c_type

                                # å‚æ•°åéœ€è¦åš Rust å…³é”®å­—è§„é¿ï¼ˆä¸ TypeMapper ä¿æŒä¸€è‡´ï¼‰
                                clean_name = param_name
                                if TYPE_MAPPER_AVAILABLE:
                                    clean_name = TypeMapper.sanitize_identifier(param_name)

                                result = llm_type_mapper_instance.map_type(
                                    c_type,
                                    is_pointer=is_ptr,
                                    is_const=is_const,
                                    is_array=is_array,
                                    context_location=f"param:{param_name}",
                                )
                                mapped_params.append((clean_name, result.final_rust_type))
                            
                            # å¤„ç†è¿”å›ç±»å‹
                            ret_c_type = (sig.return_type or "").strip()
                            ret_is_ptr = "*" in ret_c_type
                            ret_is_const = "const" in ret_c_type
                            ret_result = llm_type_mapper_instance.map_type(
                                ret_c_type,
                                is_pointer=ret_is_ptr,
                                is_const=ret_is_const,
                                context_location="return",
                            )
                            
                            # ç”Ÿæˆå‡½æ•°ç­¾å
                            func_mod = "fn" if sig.is_static else "pub extern \"C\" fn"
                            func_name = sig.name
                            if TYPE_MAPPER_AVAILABLE:
                                func_name = TypeMapper.sanitize_identifier(sig.name)
                            params_str = ", ".join([f"{name}: {rtype}" for name, rtype in mapped_params])
                            ret_str = f" -> {ret_result.final_rust_type}" if ret_result.final_rust_type != "()" else ""
                            
                            sig.rust_signature = f"{func_mod} {func_name}({params_str}){ret_str}"
                            # å¯é€‰ï¼šå¯¹ LLMTypeMapper çš„ç»“æœåšä¸€æ¬¡ç­¾åçº§å¤æ ¸ï¼ˆä»ç„¶æ˜¯â€œå¤±è´¥å›é€€åˆ°åŸç»“æœâ€ï¼‰
                            if sig_refiner is not None:
                                r = sig_refiner.refine(
                                    func_name=func_name,
                                    c_signature=sig.c_signature,
                                    candidate_rust_signature=sig.rust_signature,
                                    is_static=sig.is_static,
                                )
                                if r.ok and r.refined_signature:
                                    sig.rust_signature = r.refined_signature
                            stub = self._generate_stub(sig)
                            stubs[sig.name] = stub
                            continue  # æˆåŠŸï¼Œè·³è¿‡ TypeMapper å›é€€
                        except Exception as llm_e:
                            logger.debug(f"LLMTypeMapper å¤±è´¥: {sig.name}, {llm_e}ï¼Œå›é€€åˆ° TypeMapper")
                    
                    # ä½¿ç”¨ TypeMapper ç”Ÿæˆå‡½æ•°æ¡©ï¼ˆé»˜è®¤æˆ–å›é€€ï¼‰
                    func_mod, params_str, ret_str = TypeMapper.process_function_signature(
                        sig.return_type, sig.parameters, sig.is_static
                    )
                    # ç¡®ä¿å‡½æ•°åä¸ stub ä¸€è‡´ï¼ˆTypeMapper ä¼šè§„é¿ Rust å…³é”®å­—ï¼‰
                    func_name = TypeMapper.sanitize_identifier(sig.name)
                    sig.rust_signature = f"{func_mod} {func_name}({params_str}){ret_str}"

                    # å¯é€‰ï¼šç”¨ LLM å¤æ ¸è§„åˆ™ç­¾åï¼ˆåªåœ¨æœªå¯ç”¨ LLMTypeMapper æ—¶ï¼‰
                    if sig_refiner is not None:
                        r = sig_refiner.refine(
                            func_name=func_name,
                            c_signature=sig.c_signature,
                            candidate_rust_signature=sig.rust_signature,
                            is_static=sig.is_static,
                        )
                        if r.ok and r.refined_signature:
                            sig.rust_signature = r.refined_signature

                    stub = self._generate_stub(sig)
                    stubs[sig.name] = stub
                except Exception as e:
                    logger.warning(f"TypeMapper ç”Ÿæˆå¤±è´¥: {sig.name}, {e}ï¼Œä½¿ç”¨å›é€€æ–¹æ³•")
                    # å›é€€åˆ°æ—§æ–¹æ³•
                    if llm_translate_fn:
                        try:
                            rust_sig = llm_translate_fn(sig.c_signature)
                            sig.rust_signature = rust_sig
                        except Exception as e2:
                            logger.warning(f"LLM ç¿»è¯‘å¤±è´¥: {sig.name}, {e2}")
                            sig.rust_signature = self._fallback_signature_translation(sig)
                    else:
                        sig.rust_signature = self._fallback_signature_translation(sig)
                    stub = self._generate_stub(sig)
                    stubs[sig.name] = stub
        else:
            # ä½¿ç”¨ LLM æˆ–å›é€€æ–¹æ³•
            for sig in signatures:
                if _use_existing_rust_signature(sig):
                    continue
                if llm_translate_fn:
                    # ä½¿ç”¨ LLM ç¿»è¯‘ç­¾å
                    try:
                        rust_sig = llm_translate_fn(sig.c_signature)
                        sig.rust_signature = rust_sig
                    except Exception as e:
                        logger.warning(f"LLM ç¿»è¯‘å¤±è´¥: {sig.name}, {e}")
                        sig.rust_signature = self._fallback_signature_translation(sig)
                else:
                    # ä½¿ç”¨ç®€å•è§„åˆ™ç¿»è¯‘
                    sig.rust_signature = self._fallback_signature_translation(sig)
                
                # å¯é€‰ï¼šå¯¹å›é€€è§„åˆ™ç­¾ååšä¸€æ¬¡å¤æ ¸ï¼ˆä¿æŒä¸ TypeMapper åˆ†æ”¯ä¸€è‡´çš„è¡Œä¸ºï¼‰
                if sig_refiner is not None:
                    # å°è¯•ä»ç­¾åä¸­æå–å‡½æ•°åï¼ˆå›é€€ç­¾åå¯èƒ½å·²åš sanitizeï¼‰
                    fn_m = re.search(r"fn\s+([A-Za-z_][A-Za-z0-9_]*)", sig.rust_signature or "")
                    func_name = fn_m.group(1) if fn_m else sig.name
                    r = sig_refiner.refine(
                        func_name=func_name,
                        c_signature=sig.c_signature,
                        candidate_rust_signature=sig.rust_signature,
                        is_static=sig.is_static,
                    )
                    if r.ok and r.refined_signature:
                        sig.rust_signature = r.refined_signature

                # ç”Ÿæˆæ¡©ä»£ç 
                stub = self._generate_stub(sig)
                stubs[sig.name] = stub
        
        return stubs
    
    def _fallback_signature_translation(self, sig: FunctionSignature) -> str:
        """
        å›é€€çš„ç­¾åç¿»è¯‘ï¼ˆåŸºäºè§„åˆ™ï¼‰
        
        åŸºäº EvoC2Rust çš„ç±»å‹æ˜ å°„è§„åˆ™ï¼Œä¸ä¾èµ– LLM
        """
        rust_params = []
        for param_name, param_type in sig.parameters:
            # æ¸…ç†å‚æ•°åï¼ˆç§»é™¤å¯èƒ½çš„ * æˆ– & å‰ç¼€ï¼‰
            clean_param_name = param_name.strip('*&').strip()
            if not clean_param_name or clean_param_name in ['void']:
                continue
            
            # æ£€æŸ¥å‚æ•°ç±»å‹æ˜¯å¦ä¸º voidï¼ˆC ä¸­çš„ void å‚æ•°è¡¨ç¤ºæ— å‚æ•°ï¼‰
            clean_param_type = param_type.replace('const', '').replace('volatile', '').strip()
            if clean_param_type == 'void' and '*' not in param_type:
                # void (éæŒ‡é’ˆ) è¡¨ç¤ºæ— å‚æ•°ï¼Œè·³è¿‡
                continue
                
            # è½¬æ¢å‚æ•°ç±»å‹
            is_pointer = '*' in param_type or '*' in param_name
            is_const = 'const' in param_type
            rust_type = self._c_type_to_rust(param_type.replace('const', '').strip(), is_pointer, '[' in param_type)
            
            # å¤„ç† const æŒ‡é’ˆ -> *const T
            if is_pointer and is_const:
                if rust_type.startswith('*mut '):
                    rust_type = '*const ' + rust_type[5:]
            
            # ç¡®ä¿å‚æ•°åæ˜¯æœ‰æ•ˆçš„ Rust æ ‡è¯†ç¬¦
            # æ³¨æ„ï¼šself, Self, super, crate æ˜¯ç‰¹æ®Šå…³é”®å­—ï¼Œä¸èƒ½ç”¨ r# è½¬ä¹‰ï¼Œéœ€è¦é‡å‘½å
            if clean_param_name in ['self', 'Self']:
                clean_param_name = f"{clean_param_name}_"  # self -> self_, Self -> Self_
            elif clean_param_name in ['super', 'crate']:
                clean_param_name = f"_{clean_param_name}"  # super -> _super, crate -> _crate
            elif clean_param_name in ['type', 'match', 'fn', 'mod', 'use', 'impl', 'trait', 'struct', 'enum', 'in', 'ref', 'mut', 'const', 'static', 'priv', 'pub', 'let', 'loop', 'while', 'for', 'if', 'else', 'return', 'break', 'continue', 'as', 'where', 'async', 'await', 'dyn', 'move', 'box', 'extern', 'unsafe']:
                clean_param_name = f"r#{clean_param_name}"
            
            rust_params.append(f"{clean_param_name}: {rust_type}")
        
        # è½¬æ¢è¿”å›ç±»å‹
        rust_return = self._c_type_to_rust(sig.return_type, False, False)
        if rust_return == 'std::ffi::c_void' or sig.return_type.strip() == 'void':
            return_clause = ""
        else:
            return_clause = f" -> {rust_return}"
        
        params_str = ", ".join(rust_params)
        
        # ç”Ÿæˆå‡½æ•°ç­¾å
        # static å‡½æ•°: æ™®é€š Rust å‡½æ•°
        # é static å‡½æ•°: pub extern "C" fnï¼ˆå¯èƒ½è¢«å¤–éƒ¨è°ƒç”¨ï¼‰
        if sig.is_static:
            return f"fn {sig.name}({params_str}){return_clause}"
        else:
            # é static C å‡½æ•°é€šå¸¸å¯èƒ½è¢«å¤–éƒ¨è°ƒç”¨ï¼Œä½¿ç”¨ extern "C"
            return f"pub extern \"C\" fn {sig.name}({params_str}){return_clause}"
    
    def _generate_stub(self, sig: FunctionSignature) -> str:
        """
        ç”Ÿæˆå‡½æ•°æ¡©ä»£ç 
        
        é‡è¦ï¼šåªç”Ÿæˆå‡½æ•°ç­¾å + unimplemented!()ï¼Œä¸æå–æˆ–ç¿»è¯‘å‡½æ•°ä½“
        """
        rust_sig = sig.rust_signature.strip()
        
        # å¦‚æœç­¾åå·²ç»åŒ…å«å‡½æ•°ä½“ï¼Œæå–ç­¾åéƒ¨åˆ†ï¼ˆå¿½ç•¥å‡½æ•°ä½“ï¼‰
        # è¿™æ˜¯ä¸ºäº†ç¡®ä¿ä¸ä¼šä¿ç•™ä»»ä½•å‡½æ•°ä½“å†…å®¹
        if '{' in rust_sig:
            # æå–ç­¾åéƒ¨åˆ†ï¼ˆåˆ°ç¬¬ä¸€ä¸ª { ä¹‹å‰ï¼‰
            brace_pos = rust_sig.find('{')
            sig_part = rust_sig[:brace_pos].strip()
            # ç¡®ä¿ç­¾åéƒ¨åˆ†ä¸ä»¥ { ç»“å°¾
            sig_part = sig_part.rstrip('{').strip()
        else:
            sig_part = rust_sig
        
        # å§‹ç»ˆç”ŸæˆåªåŒ…å« unimplemented!() çš„æ¡©ä»£ç 
        # ä¸ä¿ç•™ä»»ä½•å‡½æ•°ä½“å†…å®¹
        return f"""{sig_part} {{
    unimplemented!()
}}"""
    
    # =========================================================================
    # é›†æˆæ–¹æ³•
    # =========================================================================
    
    def build_skeleton(
        self,
        source_files: List[Path],
        header_files: List[Path],
        llm_translate_fn=None,
        use_hybrid_build: bool = True,
        target_files: List[Path] = None,
        dependency_files: List[Path] = None
    ) -> Path:
        """
        æ„å»ºå®Œæ•´çš„ Rust éª¨æ¶
        
        æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
        1. å…¨é‡ç¿»è¯‘æ¨¡å¼ï¼šæ‰€æœ‰æºæ–‡ä»¶éƒ½ç¿»è¯‘æˆ Rust
        2. æ··åˆæ„å»ºæ¨¡å¼ï¼šåªç¿»è¯‘ç›®æ ‡æ–‡ä»¶ï¼Œå…¶ä»–æ–‡ä»¶ä¿ç•™ä¸º C é€šè¿‡ FFI é“¾æ¥
        
        Args:
            source_files: æºæ–‡ä»¶åˆ—è¡¨
            header_files: å¤´æ–‡ä»¶åˆ—è¡¨
            llm_translate_fn: å¯é€‰çš„ LLM ç¿»è¯‘å‡½æ•°
            use_hybrid_build: æ˜¯å¦ä½¿ç”¨æ··åˆæ„å»ºæ¨¡å¼ï¼ˆæ¨è Trueï¼‰
            target_files: æ··åˆæ¨¡å¼ä¸‹è¦ç¿»è¯‘çš„æ–‡ä»¶ï¼ˆé»˜è®¤å…¨éƒ¨ï¼‰
            dependency_files: æ··åˆæ¨¡å¼ä¸‹çš„ä¾èµ–æ–‡ä»¶ï¼ˆä¿ç•™ä¸º Cï¼‰
        
        Returns:
            éª¨æ¶é¡¹ç›®è·¯å¾„
        """
        truth_mode = self._env_flag("C2R_TRUTH_MODE", "0")

        # å¦‚æœæœªæŒ‡å®š target_filesï¼Œåˆ™å…¨éƒ¨ä½œä¸ºç›®æ ‡
        if target_files is None:
            target_files = source_files
        
        # å¦‚æœæœªæŒ‡å®š dependency_filesï¼Œè‡ªåŠ¨æ¨æ–­
        if dependency_files is None and use_hybrid_build:
            target_names = {f.name for f in target_files}
            dependency_files = [f for f in source_files if f.name not in target_names]
        
        logger.info(f"å¼€å§‹æ„å»ºéª¨æ¶: {len(source_files)} ä¸ªæºæ–‡ä»¶, {len(header_files)} ä¸ªå¤´æ–‡ä»¶")
        if use_hybrid_build and dependency_files:
            logger.info(f"æ··åˆæ„å»ºæ¨¡å¼: {len(target_files)} ä¸ªç›®æ ‡æ–‡ä»¶, {len(dependency_files)} ä¸ª C ä¾èµ–")
        
        # é˜¶æ®µ A: ç±»å‹éª¨æ¶
        logger.info("é˜¶æ®µ A: ç”Ÿæˆç±»å‹éª¨æ¶ (bindgen)")
        # å¢å¼ºï¼šä¼ é€’æºæ–‡ä»¶ä»¥åˆ†æå¤–éƒ¨ä¾èµ–
        self.generate_type_skeleton(header_files, source_files=source_files)
        
        # é˜¶æ®µ B: å˜é‡éª¨æ¶
        logger.info("é˜¶æ®µ B: æå–å…¨å±€å˜é‡ (tree-sitter)")
        all_variables = []
        for src_file in source_files:
            try:
                # Truth-first: reuse stage1 pinned TU `.i` when available; it has the exact flags/macros/include order.
                preprocessed = None
                try:
                    safe_name = self._get_safe_module_name(src_file)
                    rec = (getattr(self, "_tu_context_files", {}) or {}).get(safe_name)
                    pre_path = (rec or {}).get("preprocessed_file") if isinstance(rec, dict) else None
                    if pre_path:
                        p = Path(str(pre_path)).expanduser()
                        if p.exists():
                            preprocessed = p.read_text(encoding="utf-8", errors="ignore")
                except Exception:
                    preprocessed = None

                if not preprocessed:
                    preprocessed = self.preprocess_source(src_file)
                # æå–å˜é‡
                variables = self.extract_variables_with_treesitter(preprocessed, src_file.stem)
                all_variables.extend(variables)
            except Exception as e:
                logger.warning(f"å¤„ç† {src_file.name} å¤±è´¥: {e}")
        
        self.generate_globals_rs(all_variables)

        # Centralized compat layer (placeholders + accessor shims)
        # Needed because module stubs import `crate::compat::*;`.
        self._generate_compat_rs()
        
        # é˜¶æ®µ C: å‡½æ•°éª¨æ¶
        logger.info("é˜¶æ®µ C: ç”Ÿæˆå‡½æ•°éª¨æ¶")
        for src_file in source_files:
            try:
                # Truth-first: reuse stage1 pinned TU `.i` when available (ä¸é˜¶æ®µ B ä¿æŒä¸€è‡´)
                # ä¿®å¤ï¼šurlparser ç­‰é¡¹ç›®çš„ .c æ–‡ä»¶åªæœ‰ #include "xxx.h"ï¼Œå‡½æ•°å®šä¹‰åœ¨å¤´æ–‡ä»¶ä¸­
                # å¿…é¡»ä½¿ç”¨é¢„å¤„ç†åçš„ä»£ç æ‰èƒ½æå–å®Œæ•´çš„å‡½æ•°ç­¾å
                source_code = None
                try:
                    safe_name = self._get_safe_module_name(src_file)
                    rec = (getattr(self, "_tu_context_files", {}) or {}).get(safe_name)
                    pre_path = (rec or {}).get("preprocessed_file") if isinstance(rec, dict) else None
                    if pre_path:
                        p = Path(str(pre_path)).expanduser()
                        if p.exists():
                            source_code = p.read_text(encoding="utf-8", errors="ignore")
                            logger.debug(f"é˜¶æ®µ C: ä½¿ç”¨é¢„å¤„ç†æ–‡ä»¶ {p} æå–å‡½æ•°ç­¾å")
                except Exception:
                    source_code = None

                if not source_code:
                    source_code = self.preprocess_source(src_file)

                signatures = self.extract_function_signatures(source_code)
                stubs = self.generate_function_stubs(signatures, llm_translate_fn)

                # ç”Ÿæˆæ¨¡å—æ–‡ä»¶ï¼ˆä½¿ç”¨å®‰å…¨çš„æ¨¡å—åï¼Œé¿å…æ–‡ä»¶åå†²çªï¼‰
                self._generate_module_file(src_file, stubs)

            except Exception as e:
                logger.warning(f"ç”Ÿæˆ {src_file.name} éª¨æ¶å¤±è´¥: {e}")
        
        # ç”Ÿæˆ main.rs å’Œ Cargo.toml
        self._generate_main_rs()
        self._generate_cargo_toml(use_hybrid_build=use_hybrid_build)
        
        # æ··åˆæ„å»ºæ¨¡å¼ï¼šè®¾ç½® native/ ç›®å½•å’Œ build.rs
        if use_hybrid_build and HYBRID_BUILD_AVAILABLE:
            logger.info("è®¾ç½®æ··åˆæ„å»ºç¯å¢ƒ (C/Rust é“¾æ¥)")
            self._setup_hybrid_build(
                target_files=target_files,
                dependency_files=dependency_files or [],
                header_files=header_files
            )
        
        # é˜¶æ®µ D: ç±»å‹ä¿®å¤ä¸éªŒè¯
        logger.info("é˜¶æ®µ D: ç±»å‹ä¿®å¤ä¸éªŒè¯")
        
        # D.1: è¿½åŠ ç¼ºå¤±çš„ç±»å‹å®šä¹‰
        self.finalize_types_rs()

        # D.1.2: Tier-0 primitive typedef fixes (deterministic)
        if truth_mode:
            logger.info("Truth-mode: è·³è¿‡ primitive typedef fixesï¼ˆä¿æŒ types.rs çœŸå€¼å±‚ä¸åšæ´¾ç”Ÿä¿®è¡¥ï¼‰")
        else:
            try:
                self.apply_primitive_typedef_fixes()
            except Exception as e:
                logger.debug(f"Tier-0 primitive typedef fixes failed: {e}")
        
        # D.1.5: è‡ªåŠ¨æ£€æµ‹å¹¶ç”Ÿæˆç¼ºå¤±çš„å¤–éƒ¨ç¬¦å·å ä½
        types_file = self.output_dir / "src" / "types.rs"
        if truth_mode:
            logger.info("Truth-mode: è·³è¿‡è‡ªåŠ¨ç¼ºå¤±ç¬¦å·å ä½ï¼ˆä¸ç”Ÿæˆå®/extern/const çš„å ä½å®šä¹‰ï¼‰")
        else:
            try:
                self.detect_and_generate_missing_symbols(source_files, types_file)
            except Exception as e:
                logger.warning(f"ç¼ºå¤±ç¬¦å·æ£€æµ‹å¤±è´¥: {e}")
        
        # D.2: LLM ä¿®å¤é—®é¢˜ç±»å‹ï¼ˆå¯é€‰ï¼Œæ—§æ–¹æ³•ï¼‰
        # ç”¨äºæŸ¥æ‰¾ C ä¸Šä¸‹æ–‡çš„æ ¹ç›®å½•ï¼šå¿…é¡»å°½é‡è¦†ç›–æ•´ä¸ªé¡¹ç›®æ ‘ï¼Œå¦åˆ™å®¹æ˜“â€œæ‰¾ä¸åˆ°å®šä¹‰ â†’ LLM æ— ä¸Šä¸‹æ–‡ â†’ åªèƒ½å›é€€â€ã€‚
        c_source_dir = self.project_root if self.project_root and self.project_root.exists() else (source_files[0].parent if source_files else None)
        if truth_mode:
            logger.info("Truth-mode: è·³è¿‡ LLM éª¨æ¶ç±»å‹ä¿®å¤ï¼ˆtypes.rs åªæ¥å— bindgen/ç¼–è¯‘æ•°æ®åº“çœŸå€¼ï¼‰")
        else:
            try:
                self.repair_skeleton_types(c_source_dir)
            except Exception as e:
                logger.warning(f"éª¨æ¶ç±»å‹ä¿®å¤å¤±è´¥: {e}")
        
        # D.3: éªŒè¯éª¨æ¶ç¼–è¯‘
        success, error_msg = self.cargo_check()
        if success:
            logger.info("âœ“ éª¨æ¶ç¼–è¯‘éªŒè¯é€šè¿‡")
        else:
            logger.warning(f"âš  éª¨æ¶ç¼–è¯‘éªŒè¯å¤±è´¥")
            
            # D.4: AI åŸç”Ÿè‡ªæ„ˆå¾ªç¯ (æ–°æ¶æ„)
            # åŸºäº rustc JSON è¾“å‡ºçš„ç¡®å®šæ€§é”™è¯¯ä¿®å¤
            # æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦å¯ç”¨è‡ªæ„ˆå¾ªç¯
            # Truth-mode: never run self-healing (it will generate placeholders/extern/dummy defs).
            use_self_healing = (not truth_mode) and (os.environ.get("USE_SELF_HEALING", "true").lower() == "true")
            
            if not use_self_healing:
                if truth_mode:
                    logger.info("â­ï¸ Truth-mode: è‡ªæ„ˆå¾ªç¯å·²ç¦ç”¨ï¼ˆä¿æŒçœŸå€¼ï¼Œä¸åšæ´¾ç”Ÿä¿®è¡¥ï¼‰")
                else:
                    logger.info("â­ï¸ è‡ªæ„ˆå¾ªç¯å·²ç¦ç”¨ (USE_SELF_HEALING=false)")
                if truth_mode:
                    print("â­ï¸ Self-Healing disabled by truth-mode")
                else:
                    print("â­ï¸ Self-Healing disabled by environment variable")
            elif SELF_HEALING_AVAILABLE:
                logger.info("ğŸ”„ å¯åŠ¨ AI åŸç”Ÿè‡ªæ„ˆå¾ªç¯...")
                try:
                    # Self-healing çš„ LLM éœ€è¦çš„æ˜¯â€œprompt -> raw responseâ€çš„å‡½æ•°ï¼›
                    # llm_translate_fn æ˜¯â€œC signature -> Rust signatureâ€çš„ä¸“ç”¨ç¿»è¯‘å™¨ï¼Œä¸èƒ½å¤ç”¨ã€‚
                    llm_prompt_fn = None
                    try:
                        from generate.generation import generation as _generation  # prompt(str) -> str (å…¼å®¹)
                        llm_prompt_fn = _generation
                    except Exception:
                        llm_prompt_fn = None

                    try:
                        max_cycles = int(os.environ.get("C2R_SELF_HEALING_MAX_CYCLES", "5"))
                        if max_cycles < 1:
                            max_cycles = 1
                    except Exception:
                        max_cycles = 5

                    print(f"  [SelfHealing] c_source_dir={c_source_dir}")
                    print(f"  [SelfHealing] llm_enabled={bool(llm_prompt_fn)} max_cycles={max_cycles}")

                    result = self._run_self_healing_loop(c_source_dir, llm_prompt_fn, max_cycles=max_cycles)
                    if result.success:
                        logger.info(f"âœ“ è‡ªæ„ˆå¾ªç¯æˆåŠŸ: {len(result.symbols_fixed)} ä¸ªç¬¦å·å·²ä¿®å¤")
                        print(f"âœ… Self-Healing Success: Fixed {len(result.symbols_fixed)} symbols")
                    else:
                        logger.warning(f"âš  è‡ªæ„ˆå¾ªç¯éƒ¨åˆ†æˆåŠŸ: ä¿®å¤ {len(result.symbols_fixed)}, å‰©ä½™ {len(result.remaining_errors)}")
                        print(f"âš ï¸ Self-Healing Partial: Fixed {len(result.symbols_fixed)}, Remaining {len(result.remaining_errors)}")
                except Exception as e:
                    logger.warning(f"è‡ªæ„ˆå¾ªç¯å¼‚å¸¸: {e}")
            else:
                logger.warning("è‡ªæ„ˆæ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡è‡ªæ„ˆå¾ªç¯")
        
        logger.info(f"éª¨æ¶æ„å»ºå®Œæˆ: {self.output_dir}")
        return self.output_dir
    
    def _run_self_healing_loop(
        self, 
        c_source_dir: Path = None,
        llm_fn=None,
        max_cycles: int = 5
    ):
        """
        è¿è¡Œ AI åŸç”Ÿè‡ªæ„ˆå¾ªç¯
        
        åŸºäº rustc --message-format=json çš„ç¡®å®šæ€§é”™è¯¯ä¿®å¤ã€‚
        
        Args:
            c_source_dir: C æºç ç›®å½•
            llm_fn: LLM è°ƒç”¨å‡½æ•°
            max_cycles: æœ€å¤§å¾ªç¯æ¬¡æ•°
            
        Returns:
            SelfHealingResult
        """
        logger.info("ğŸ”„ å¯åŠ¨ AI åŸç”Ÿè‡ªæ„ˆå¾ªç¯...")
        print("\n" + "="*60)
        print("ğŸ”„ AI-Native Self-Healing Loop")
        print("="*60)
        
        loop = SelfHealingLoop(
            project_root=self.output_dir,
            c_source_dir=c_source_dir,
            llm_fn=llm_fn,
            max_cycles=max_cycles
        )
        
        return loop.run()
    
    def _get_safe_module_name(self, src_file: Path) -> str:
        """
        è¾…åŠ©æ–¹æ³•ï¼šæ ¹æ®æ–‡ä»¶ç›¸å¯¹è·¯å¾„ç”Ÿæˆå”¯ä¸€çš„æ¨¡å—å

        è§£å†³æ–‡ä»¶åå†²çªé—®é¢˜ï¼š
        - /abs/path/src/linux/ipc.c -> src_linux_ipc
        - /abs/path/src/liteos_m/ipc.c -> src_liteos_m_ipc

        Args:
            src_file: æºæ–‡ä»¶è·¯å¾„

        Returns:
            å®‰å…¨çš„ Rust æ¨¡å—å
        """
        # è°ƒç”¨å…¬å…±å‡½æ•°ï¼Œç¡®ä¿ä¸ get_dependencies.py ç­‰å…¶ä»–æ¨¡å—å‘½åä¸€è‡´
        return safe_module_name(self.project_root, src_file)
    
    def _generate_module_file(self, src_file_or_name, stubs: Dict[str, str]) -> str:
        """
        ç”Ÿæˆæ¨¡å—æ–‡ä»¶
        
        Args:
            src_file_or_name: æºæ–‡ä»¶è·¯å¾„ (Path) æˆ–æ¨¡å—å (str)
            stubs: å‡½æ•°æ¡©ä»£ç å­—å…¸ {func_name: stub_code}
        
        Returns:
            ç”Ÿæˆçš„æ¨¡å—å
        """
        # æ”¯æŒæ—§çš„è°ƒç”¨æ–¹å¼ï¼ˆä¼ å…¥å­—ç¬¦ä¸²æ¨¡å—åï¼‰å’Œæ–°çš„è°ƒç”¨æ–¹å¼ï¼ˆä¼ å…¥ Pathï¼‰
        if isinstance(src_file_or_name, Path):
            module_name = self._get_safe_module_name(src_file_or_name)
        else:
            module_name = src_file_or_name
        
        output_path = self.output_dir / "src" / f"{module_name}.rs"
        
        lines = [
            f'//! Module: {module_name}',
            '//!',
            '//! Auto-generated skeleton - function bodies are unimplemented.',
            '',
            '#![allow(unused_imports)]',
            '#![allow(dead_code)]',
            '#![allow(unused_variables)]',
            '#![allow(non_camel_case_types)]',
            '#![allow(non_snake_case)]',
            '',
            'use crate::types::*;',
            'use crate::globals::*;',
            'use crate::compat::*;',
            '',
        ]

        # Scheme B: file-scope `static` variables (internal linkage) live in the module, not in globals.rs.
        try:
            local_statics = getattr(self, "_module_local_file_statics", {}) or {}
            entries = local_statics.get(module_name) if isinstance(local_statics, dict) else None
        except Exception:
            entries = None
        if entries:
            lines.append("// === C2R_FILE_STATICS_BEGIN ===")
            lines.append("// File-scope `static` variables (internal linkage) from the original C TU.")
            lines.append("// These are module-local by design (Scheme B).")
            for ent in entries:
                try:
                    name = str(ent.get("name") or "").strip()
                    ty = str(ent.get("ty") or "").strip()
                    init = str(ent.get("init") or "").strip()
                    c_ty = str(ent.get("c_type") or "").strip()
                except Exception:
                    continue
                if not name or not ty:
                    continue
                if c_ty:
                    lines.append(f"/// C: static {c_ty} {name}")
                if init:
                    lines.append(f"static mut {name}: {ty} = {init};")
                else:
                    lines.append(
                        f"static mut {name}: {ty} = unsafe {{ core::mem::MaybeUninit::<{ty}>::zeroed().assume_init() }};"
                    )
                lines.append("")
            lines.append("// === C2R_FILE_STATICS_END ===")
            lines.append("")
        
        for func_name, stub in stubs.items():
            lines.append(stub)
            lines.append('')
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        return module_name

    def _generate_compat_rs(self):
        """Generate `src/compat.rs` and `src/compatibility.rs` (centralized fallbacks + shims).

        Why both?
        - New skeletons should use `crate::compat`.
        - Some repair runs (or legacy outputs) may reference `crate::compatibility`.
          Keeping an alias module avoids noisy, non-semantic build failures.
        """
        src_dir = self.output_dir / "src"
        compat_path = src_dir / "compat.rs"

        compat_template: List[str] = [
            '//! Compatibility / Fallback Layer',
            '//!',
            '//! This module is auto-generated to keep the translated project compiling.',
            '//!',
            '//! Design goals:',
            '//! - Centralize placeholders and shims in ONE place (easy to audit & remove later).',
            '//! - Keep function bodies as close to translated semantics as possible.',
            '//!',
            '//! IMPORTANT:',
            '//! - Items here may be placeholders (value/layout unknown). Always review before relying on semantics.',
            '',
            '#![allow(dead_code)]',
            '#![allow(unused)]',
            '#![allow(non_snake_case)]',
            '#![allow(non_camel_case_types)]',
            '',
            '/// Minimal FFI prelude (for legacy skeletons that import `crate::compat::ffi::*`).',
            'pub mod ffi {',
            '    pub use core::ffi::*;',
            '}',
            '',
            '// === C2R_COMPAT_PLACEHOLDERS_BEGIN ===',
            '// (auto-appended placeholders will be inserted here)',
            '// === C2R_COMPAT_PLACEHOLDERS_END ===',
            '',
            '// === C2R_ACCESSOR_SHIMS_BEGIN ===',
            '// (auto-appended accessor shim declarations will be inserted here)',
            '// === C2R_ACCESSOR_SHIMS_END ===',
            '',
        ]

        src_dir.mkdir(parents=True, exist_ok=True)

        # Create-or-extend compat.rs (idempotent, non-destructive).
        if not compat_path.exists():
            compat_path.write_text("\n".join(compat_template), encoding="utf-8")
        else:
            try:
                existing = compat_path.read_text(encoding="utf-8", errors="ignore")
            except Exception:
                existing = ""
            # Avoid top-level `pub use core::ffi::*;` because it conflicts with `crate::types::*`
            # (e.g., `c_void` becomes ambiguous when both are glob-imported).
            lines = existing.splitlines()
            filtered: List[str] = []
            for line in lines:
                if line.strip() == "pub use core::ffi::*;" and not line.startswith(" "):
                    continue
                # Also drop the old comment line if it immediately precedes the removed export.
                if line.strip() == "/// Common C FFI types (c_int, c_char, c_void, ...)." and not line.startswith(" "):
                    continue
                filtered.append(line)
            updated = "\n".join(filtered)

            # Ensure minimal ffi prelude for older/LLM-modified imports.
            if "pub mod ffi" not in updated:
                updated = updated.rstrip() + "\n\n/// Minimal FFI prelude (for legacy skeletons that import `crate::compat::ffi::*`).\npub mod ffi {\n    pub use core::ffi::*;\n}\n"
            # Ensure insertion anchors exist for placeholder/shim injection.
            if "C2R_COMPAT_PLACEHOLDERS_BEGIN" not in updated:
                updated = updated.rstrip() + "\n\n// === C2R_COMPAT_PLACEHOLDERS_BEGIN ===\n// (auto-appended placeholders will be inserted here)\n// === C2R_COMPAT_PLACEHOLDERS_END ===\n"
            if "C2R_ACCESSOR_SHIMS_BEGIN" not in updated:
                updated = updated.rstrip() + "\n\n// === C2R_ACCESSOR_SHIMS_BEGIN ===\n// (auto-appended accessor shim declarations will be inserted here)\n// === C2R_ACCESSOR_SHIMS_END ===\n"
            if updated != existing and updated:
                compat_path.write_text(updated, encoding="utf-8")

        # Backward-compatibility alias: some outputs import `crate::compatibility::*;`
        compatibility_path = src_dir / "compatibility.rs"
        if not compatibility_path.exists():
            compatibility_path.write_text(
                "\n".join(
                    [
                        "//! Backward-compatibility alias for legacy skeleton outputs.",
                        "//!",
                        "//! Prefer `crate::compat` for new code.",
                        "",
                        "#![allow(dead_code)]",
                        "#![allow(unused)]",
                        "",
                        "pub use crate::compat::*;",
                        "",
                    ]
                ),
                encoding="utf-8",
            )
    
    def _generate_main_rs(self):
        """ç”Ÿæˆ main.rs"""
        output_path = self.output_dir / "src" / "main.rs"
        
        # æ”¶é›†æ‰€æœ‰æ¨¡å—
        modules = []
        for rs_file in (self.output_dir / "src").glob("*.rs"):
            if rs_file.name not in ['main.rs', 'lib.rs']:
                modules.append(rs_file.stem)
        
        lines = [
            '//! Auto-generated main module',
            '',
            '#![allow(unused_imports)]',
            '#![allow(dead_code)]',
            '',
        ]
        
        for module in sorted(modules):
            lines.append(f'pub mod {module};')
        
        lines.extend([
            '',
            'fn main() {',
            '    println!("Skeleton project - implement function bodies");',
            '}',
        ])
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
    
    def _generate_cargo_toml(self, use_hybrid_build: bool = True):
        """
        ç”Ÿæˆ Cargo.toml
        
        Args:
            use_hybrid_build: æ˜¯å¦ä½¿ç”¨æ··åˆæ„å»ºæ¨¡å¼ï¼ˆC/Rust é“¾æ¥ï¼‰
        """
        output_path = self.output_dir / "Cargo.toml"
        # ä» project_root æˆ– output_dir æ¨æ–­é¡¹ç›®åç§°
        project_name = getattr(self, 'project_name', None) or self.project_root.name or "rust_skeleton"
        # ç¡®ä¿é¡¹ç›®åç§°æ˜¯æœ‰æ•ˆçš„ Rust åŒ…åï¼ˆåªåŒ…å«å­—æ¯æ•°å­—å’Œä¸‹åˆ’çº¿ï¼‰
        project_name = re.sub(r'[^a-zA-Z0-9_]', '_', project_name)
        
        if use_hybrid_build:
            # æ··åˆæ„å»ºæ¨¡å¼ï¼šåŒ…å« cc ç”¨äºç¼–è¯‘ C ä¾èµ–
            # æ³¨æ„ï¼šä¸ä½¿ç”¨ [lib] éƒ¨åˆ†ï¼Œå› ä¸ºéª¨æ¶é¡¹ç›®ä½¿ç”¨ main.rs
            content = f'''[package]
name = "{project_name}"
version = "0.1.0"
edition = "2021"
build = "build.rs"

[dependencies]
libc = "0.2"

[build-dependencies]
cc = "1.0"       # ç¼–è¯‘ C/C++ ä»£ç 

[profile.dev]
opt-level = 0
debug = true

[profile.release]
opt-level = 3
lto = true
'''
        else:
            # ä¼ ç»Ÿæ¨¡å¼ï¼šçº¯ Rust éª¨æ¶
            content = f'''[package]
name = "{project_name}"
version = "0.1.0"
edition = "2021"

[dependencies]
libc = "0.2"

[profile.dev]
opt-level = 0
debug = true
'''
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        # å¦‚æœä½¿ç”¨æ··åˆæ„å»ºæ¨¡å¼ï¼Œç¡®ä¿ build.rs å­˜åœ¨ï¼ˆå³ä½¿æ˜¯ç©ºçš„ï¼‰
        if use_hybrid_build:
            build_rs_path = self.output_dir / "build.rs"
            if not build_rs_path.exists():
                self._generate_empty_build_rs()
        
        logger.info(f"ç”Ÿæˆ Cargo.toml: {output_path} (æ··åˆæ„å»º: {use_hybrid_build})")
    
    def _setup_hybrid_build(
        self,
        target_files: List[Path],
        dependency_files: List[Path],
        header_files: List[Path] = None
    ) -> bool:
        """
        è®¾ç½®æ··åˆ C/Rust æ„å»ºç¯å¢ƒ
        
        è¿™æ˜¯æ¸è¿›å¼é‡å†™çš„æ ¸å¿ƒï¼š
        - åªç¿»è¯‘ target_files
        - å…¶ä»–æ–‡ä»¶ä¿ç•™ä¸º Cï¼Œç¼–è¯‘æˆåº“é€šè¿‡ FFI é“¾æ¥
        
        Args:
            target_files: è¦ç¿»è¯‘æˆ Rust çš„æ–‡ä»¶
            dependency_files: ä¾èµ–çš„ C æ–‡ä»¶ï¼ˆä¿ç•™ä¸º Cï¼‰
            header_files: å¤´æ–‡ä»¶
        
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if not HYBRID_BUILD_AVAILABLE:
            logger.warning("æ··åˆæ„å»ºæ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡")
            return False
        
        try:
            # 1. åˆ›å»º native ç›®å½•ç®¡ç†å™¨
            native_manager = NativeDirectoryManager(self.output_dir)
            native_manager.setup()
            
            # 2. å¤åˆ¶ä¾èµ–æ–‡ä»¶åˆ° native/ï¼ˆæ’é™¤ç›®æ ‡æ–‡ä»¶ï¼‰
            target_names = {f.name for f in target_files}
            for dep_file in dependency_files:
                if dep_file.name not in target_names and dep_file.exists():
                    native_manager.copy_source_file(dep_file, is_header=False)
            
            # 3. å¤åˆ¶å¤´æ–‡ä»¶åˆ° native/include/
            if header_files:
                for h in header_files:
                    if h.exists():
                        native_manager.copy_source_file(h, is_header=True)
            
            # 4. ä» compile_commands.json æå–ç¼–è¯‘å‚æ•°
            include_dirs = list(self.include_dirs)
            defines = {}
            compiler_flags = []
            
            if self.compile_commands_parser:
                all_files = target_files + dependency_files
                cc_includes, cc_defines, cc_flags = extract_compile_flags_from_commands(
                    self.compile_commands_parser.compile_commands_path,
                    all_files
                )
                include_dirs.extend(cc_includes)
                defines.update(cc_defines)
                compiler_flags.extend(cc_flags)
            
            # 5. æ·»åŠ  native/include åˆ° include è·¯å¾„
            native_include = self.output_dir / "native" / "include"
            if native_include.exists():
                include_dirs.insert(0, native_include)
            
            # 6. ç”Ÿæˆ build.rs
            c_sources = []
            for dep_file in dependency_files:
                if dep_file.name not in target_names:
                    c_sources.append(CSourceFile(
                        path=dep_file,
                        is_target=False
                    ))
            
            # ä» project_root æ¨æ–­é¡¹ç›®åç§°
            project_name = getattr(self, 'project_name', None) or self.project_root.name or "rust_skeleton"
            project_name = re.sub(r'[^a-zA-Z0-9_]', '_', project_name)

            # ç”Ÿæˆ build.rsï¼ˆåŠ¨æ€æ‰«æ native/ ä¸‹çš„ C/C++ æºæ–‡ä»¶ï¼‰
            # ç›®çš„ï¼šåç»­é˜¶æ®µå¯ä»¥ç”Ÿæˆé¢å¤–çš„ C shimï¼ˆä¾‹å¦‚å­—æ®µ accessor shimsï¼‰è€Œæ— éœ€é‡å†™ build.rsã€‚
            generate_build_rs(
                self.output_dir,
                c_sources,
                include_dirs,
                defines,
                compiler_flags,
                lib_name=f"{project_name}_native"
            )
            if c_sources:
                print(f"âœ… ç”Ÿæˆ build.rsï¼šå°†ç¼–è¯‘ {len(c_sources)} ä¸ª C ä¾èµ–æ–‡ä»¶ï¼ˆnative/ åŠ¨æ€æ‰«æåŒ…å«é¢å¤– shimï¼‰")
            else:
                print("âœ… ç”Ÿæˆ build.rsï¼šå½“å‰æ—  C ä¾èµ–æ–‡ä»¶ï¼ˆnative/ åŠ¨æ€æ‰«æå…è®¸åç»­ shimï¼‰")
            
            logger.info(f"æ··åˆæ„å»ºç¯å¢ƒè®¾ç½®å®Œæˆ: {len(c_sources)} ä¸ª C ä¾èµ–æ–‡ä»¶")
            return True
            
        except Exception as e:
            logger.error(f"è®¾ç½®æ··åˆæ„å»ºç¯å¢ƒå¤±è´¥: {e}")
            return False
    
    def _generate_empty_build_rs(self):
        """ç”Ÿæˆç©ºçš„ build.rsï¼ˆå½“æ²¡æœ‰ C ä¾èµ–æ—¶ï¼‰"""
        content = '''//! æ„å»ºè„šæœ¬
//! 
//! å½“å‰é¡¹ç›®æ²¡æœ‰ C ä¾èµ–ï¼Œæ­¤è„šæœ¬ä¸ºç©ºã€‚

fn main() {
    // æ²¡æœ‰ C ä»£ç éœ€è¦ç¼–è¯‘
    println!("cargo:rerun-if-changed=build.rs");
}
'''
        build_rs_path = self.output_dir / "build.rs"
        with open(build_rs_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    def _generate_extern_bindings(
        self,
        external_functions: List[Dict],
        external_variables: List[Dict] = None
    ):
        """
        ç”Ÿæˆå¤–éƒ¨ C å‡½æ•°/å˜é‡çš„ extern "C" ç»‘å®š
        
        è¿™äº›å‡½æ•°æ¥è‡ª native/ ä¸­ç¼–è¯‘çš„ C ä»£ç ï¼Œ
        é€šè¿‡ FFI é“¾æ¥è€Œéç¿»è¯‘ã€‚
        
        Args:
            external_functions: å¤–éƒ¨å‡½æ•°åˆ—è¡¨
            external_variables: å¤–éƒ¨å˜é‡åˆ—è¡¨
        """
        if not HYBRID_BUILD_AVAILABLE:
            return
        
        output_file = self.output_dir / "src" / "extern_bindings.rs"
        
        generate_extern_declarations(
            external_functions or [],
            external_variables or [],
            output_file
        )
        
        # åœ¨ lib.rs ä¸­æ·»åŠ  mod extern_bindings
        lib_rs_path = self.output_dir / "src" / "lib.rs"
        if lib_rs_path.exists():
            with open(lib_rs_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if 'mod extern_bindings' not in content:
                with open(lib_rs_path, 'a', encoding='utf-8') as f:
                    f.write('\n\npub mod extern_bindings;\n')
                    f.write('pub use extern_bindings::*;\n')
    
    def finalize_types_rs(self):
        """
        åœ¨ types.rs æœ«å°¾è¿½åŠ  bindgen é—æ¼çš„ç±»å‹å®šä¹‰ã€‚
        
        è¿™æ˜¯è§£å†³ "cannot find type" çš„å…œåº•æ–¹æ¡ˆã€‚
        åœ¨æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œåè°ƒç”¨æ­¤æ–¹æ³•ï¼Œç”Ÿæˆç¼ºå¤±çš„ä¸é€æ˜ç»“æ„ä½“ã€‚
        """
        # Truth-mode: do not generate defensive opaque types / common constants.
        # Keep missing types as compile-time signals (usually indicates incomplete TU/build context).
        if self._env_flag("C2R_TRUTH_MODE", "0") or (not self._env_flag("C2R_ENABLE_FINALIZE_TYPES_RS", "1")):
            logger.info("finalize_types_rs skipped (truth-mode or disabled)")
            return

        if not TYPE_UTILS_AVAILABLE:
            logger.warning("type_utils ä¸å¯ç”¨ï¼Œè·³è¿‡ finalize_types_rs")
            return
        
        types_rs_path = self.output_dir / "src" / "types.rs"
        
        # 1. è¯»å–ç°æœ‰çš„ types.rsï¼Œçœ‹çœ‹ bindgen å·²ç»ç”Ÿæˆäº†ä»€ä¹ˆ
        existing_content = ""
        if types_rs_path.exists():
            with open(types_rs_path, 'r', encoding='utf-8') as f:
                existing_content = f.read()
        
        # ç®€å•æ­£åˆ™æå–å·²å®šä¹‰çš„ struct/enum/type åç§°ï¼Œé¿å…é‡å¤å®šä¹‰
        defined_types = set(re.findall(r'pub (?:struct|enum|union|type) (\w+)', existing_content))

        # åŒæ—¶æå–é€šè¿‡ `pub use` é‡æ–°å¯¼å‡ºçš„ç±»å‹ (ä¾‹å¦‚ TU types: pub use module::{Type1, Type2};)
        # Pattern 1: pub use module::{Type1, Type2};
        pub_use_pattern = r'pub use [^;]+::\{([^}]+)\}'
        for match in re.findall(pub_use_pattern, existing_content):
            # è§£æ {Type1, Type2, ...} ä¸­çš„ç±»å‹å
            for type_name in match.split(','):
                type_name = type_name.strip()
                # å¤„ç† `as OtherName` é‡å‘½åçš„æƒ…å†µ
                if ' as ' in type_name:
                    type_name = type_name.split(' as ')[1].strip()
                if type_name and type_name.isidentifier():
                    defined_types.add(type_name)

        # Pattern 2: pub use module::Type; (å•ä¸ªç±»å‹å¯¼å‡º)
        pub_use_single_pattern = r'pub use \w+::(\w+);'
        for type_name in re.findall(pub_use_single_pattern, existing_content):
            if type_name and type_name.isidentifier():
                defined_types.add(type_name)
        
        # 2. è®¡ç®—ç¼ºå¤±çš„ç±»å‹
        # ä»æ”¶é›†åˆ°çš„æ‰€æœ‰ç±»å‹ä¸­ï¼Œå‡å» Rust åŸç”Ÿç±»å‹å’Œå·²ç»å®šä¹‰çš„ç±»å‹
        rust_primitives = {
            'i8', 'u8', 'i16', 'u16', 'i32', 'u32', 'i64', 'u64', 
            'f32', 'f64', 'bool', 'usize', 'isize', 'str', 'String',
            'Vec', 'Option', 'Result', 'Box', 'Rc', 'Arc', 'self', 'Self',
            'true', 'false', 'None', 'Some', 'Ok', 'Err',
            # C åŸºç¡€ç±»å‹ï¼ˆå·²åœ¨ç±»å‹æ˜ å°„ä¸­å¤„ç†ï¼‰
            'int', 'char', 'void', 'float', 'double', 'long', 'short',
            '_Bool', 'bool', 'unsigned', 'signed',
            'size_t', 'ssize_t', 'ptrdiff_t', 'intptr_t', 'uintptr_t',
            'uint8_t', 'uint16_t', 'uint32_t', 'uint64_t',
            'int8_t', 'int16_t', 'int32_t', 'int64_t'
        }
        missing_types = self.collected_custom_types - defined_types - rust_primitives
        
        if not missing_types:
            logger.debug("æ²¡æœ‰ç¼ºå¤±çš„ç±»å‹éœ€è¦ç”Ÿæˆ")
            # å³ä½¿æ²¡æœ‰ç¼ºå¤±ç±»å‹ï¼Œä¹Ÿéœ€è¦è¡¥é½å¸¸ç”¨å¸¸é‡ï¼ˆä¾‹å¦‚ pthread initializerï¼‰ã€‚
            self._append_common_constants(types_rs_path, existing_content)
            return
        
        # ========== å¢å¼º: è¿‡æ»¤éæ³•ç±»å‹å (è§£å†³ pack é¡¹ç›®å´©æºƒé—®é¢˜) ==========
        # åœ¨ç”Ÿæˆä¹‹å‰å…ˆè¿‡æ»¤æ‰æ‰€æœ‰éæ³•ç±»å‹å
        valid_types = set()
        skipped_types = []
        for type_name in missing_types:
            # è¿‡æ»¤æ‰æ˜¾ç„¶éæ³•çš„åå­—
            if not is_valid_c_identifier(type_name):
                skipped_types.append(type_name)
                logger.debug(f"è·³è¿‡éæ³•ç±»å‹å: {type_name}")
                continue
            valid_types.add(type_name)
        
        if skipped_types:
            print(f"âš ï¸ Skipped {len(skipped_types)} invalid type names: {skipped_types[:5]}{'...' if len(skipped_types) > 5 else ''}")
        
        if not valid_types:
            logger.debug("è¿‡æ»¤åæ²¡æœ‰éœ€è¦ç”Ÿæˆçš„ç±»å‹")
            return
        
        print(f"ğŸ›¡ï¸ Defensively generating {len(valid_types)} opaque types: {sorted(valid_types)}")
        logger.info(f"ç”Ÿæˆ {len(valid_types)} ä¸ªé˜²å¾¡æ€§ä¸é€æ˜ç±»å‹")
        
        # 3. è¿½åŠ ä¸é€æ˜å®šä¹‰ (ä½¿ç”¨ RustCodeBuilder ç¡®ä¿è¯­æ³•æ­£ç¡®)
        with open(types_rs_path, 'a', encoding='utf-8') as f:
            if RUST_CODE_BUILDER_AVAILABLE:
                # â˜… ä½¿ç”¨ RustCodeBuilder å®‰å…¨ç”Ÿæˆ â˜…
                builder = RustCodeBuilder()
                builder.add_line("")
                builder.add_line("// ============================================================")
                builder.add_line("// Auto-generated Defensive Opaque Types")
                builder.add_line("// These types were found in function signatures or variable")
                builder.add_line("// declarations but were not generated by bindgen.")
                builder.add_line("// ============================================================")
                builder.add_line("")
                
                # å·²çŸ¥ç³»ç»Ÿç±»å‹çš„ç‰¹æ®Šå®šä¹‰ï¼ˆæ¯”ç©ºç»“æ„ä½“æ›´æ­£ç¡®ï¼‰
                known_system_types = {
                    'file': 'pub struct file { _opaque: [u8; 0] }',
                    'FILE': 'pub struct FILE { _opaque: [u8; 0] }',
                    'pthread_mutex_t': 'pub struct pthread_mutex_t { _opaque: [u8; 40] }',
                    'pthread_cond_t': 'pub struct pthread_cond_t { _opaque: [u8; 48] }',
                    'pthread_t': 'pub type pthread_t = usize;',
                    'pthread_attr_t': 'pub struct pthread_attr_t { _opaque: [u8; 56] }',
                    'sem_t': 'pub struct sem_t { _opaque: [u8; 32] }',
                    'AudioPort': 'pub struct AudioPort { _opaque: [u8; 0] }',
                    'AudioPortCapability': 'pub struct AudioPortCapability { _opaque: [u8; 0] }',
                    'AudioAdapter': 'pub struct AudioAdapter { _opaque: [u8; 0] }',
                    'AudioCapture': 'pub struct AudioCapture { _opaque: [u8; 0] }',
                    'AudioRender': 'pub struct AudioRender { _opaque: [u8; 0] }',
                    'AudioDeviceDescriptor': 'pub struct AudioDeviceDescriptor { _opaque: [u8; 0] }',
                }
                
                for type_name in sorted(valid_types):
                    # ç¡®ä¿ç±»å‹åæ˜¯æœ‰æ•ˆçš„ Rust æ ‡è¯†ç¬¦
                    rust_safe_name = type_name.replace(' ', '_')
                    if rust_safe_name and not rust_safe_name[0].isalpha() and rust_safe_name[0] != '_':
                        rust_safe_name = '_' + rust_safe_name
                    
                    # Tier-0: map common primitive typedefs to real aliases
                    if type_name in PRIMITIVE_TYPEDEF_ALIASES:
                        alias = PRIMITIVE_TYPEDEF_ALIASES[type_name]
                        builder.add_line(f"/// C2R_PRIMITIVE_TYPEDEF: rule-mapped `{type_name}` -> `{alias}`")
                        builder.add_line(f"pub type {rust_safe_name} = {alias};")
                        builder.add_line("")
                        continue

                    # æ£€æŸ¥æ˜¯å¦æ˜¯å·²çŸ¥ç³»ç»Ÿç±»å‹
                    if type_name in known_system_types:
                        builder.add_line(f"/// Known system type `{type_name}`")
                        stmt = known_system_types[type_name]
                        if stmt.strip().startswith("pub type"):
                            builder.add_line(stmt)
                        else:
                            builder.add_line("#[repr(C)]")
                            builder.add_line(stmt)
                        builder.add_line("")
                    else:
                        # ä½¿ç”¨ Builder ç”Ÿæˆä¸é€æ˜ç»“æ„ä½“
                        builder.add_opaque_struct(
                            rust_safe_name, 
                            doc=f"Opaque placeholder for external type `{type_name}`"
                        )
                
                f.write(builder.build())
            else:
                # å›é€€åˆ°ä¼ ç»Ÿå­—ç¬¦ä¸²æ‹¼æ¥
                f.write("\n\n// --- Auto-generated Defensive Opaque Types ---\n")
                f.write("// These types were found in function signatures or variable declarations\n")
                f.write("// but were not generated by bindgen. They are defined as opaque types\n")
                f.write("// to allow compilation without the actual header definitions.\n\n")
                
                for type_name in sorted(valid_types):
                    rust_safe_name = type_name.replace(' ', '_')
                    if rust_safe_name and not rust_safe_name[0].isalpha() and rust_safe_name[0] != '_':
                        rust_safe_name = '_' + rust_safe_name

                    # Tier-0: map common primitive typedefs to real aliases
                    if type_name in PRIMITIVE_TYPEDEF_ALIASES:
                        alias = PRIMITIVE_TYPEDEF_ALIASES[type_name]
                        f.write(f"/// C2R_PRIMITIVE_TYPEDEF: rule-mapped `{type_name}` -> `{alias}`\n")
                        f.write(f"pub type {rust_safe_name} = {alias};\n\n")
                        continue

                    f.write(f"/// Opaque placeholder for external type `{type_name}`\n")
                    f.write(f"#[repr(C)]\n")
                    f.write(f"#[derive(Debug, Copy, Clone)]\n")
                    f.write(f"pub struct {rust_safe_name} {{\n")
                    f.write(f"    _private: [u8; 0],\n")
                    f.write(f"}}\n\n")
        
        logger.info(f"å·²è¿½åŠ  {len(valid_types)} ä¸ªä¸é€æ˜ç±»å‹åˆ° types.rs")
        
        # 3. è¿½åŠ å¸¸ç”¨å¸¸é‡å®šä¹‰ï¼ˆæ— è®º bindgen æ˜¯å¦æˆåŠŸéƒ½éœ€è¦ï¼‰
        try:
            updated_content = types_rs_path.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            updated_content = existing_content
        self._append_common_constants(types_rs_path, updated_content)

    def apply_primitive_typedef_fixes(self) -> dict:
        """
        Tier-0: Replace trivial opaque structs for common typedefs with Rust type aliases.

        This is a post-process step after types.rs generation/finalization, and it is
        intentionally deterministic (no LLM). It targets cases like:

            pub struct INT32 { _private: [u8; 0] }

        and rewrites them to:

            pub type INT32 = i32;
        """
        import json
        import re

        types_rs_path = self.output_dir / "src" / "types.rs"
        if not types_rs_path.exists():
            return {"applied": 0, "fixes": []}

        try:
            content = types_rs_path.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            return {"applied": 0, "fixes": []}

        allowed_field_names = {"_opaque", "_private", "_unused", "_c2r_private", "_reserved"}

        def _is_trivial_opaque_struct(block_text: str) -> bool:
            body_match = re.search(r"(?s)\{(.*)\}", block_text)
            if not body_match:
                return False
            body = body_match.group(1)
            for m in re.finditer(r"\b(pub\s+)?([A-Za-z_][A-Za-z0-9_]*)\s*:", body):
                name = m.group(2)
                if name not in allowed_field_names:
                    return False
            return True

        def _find_struct_block_span(src: str, struct_name: str) -> Optional[Tuple[int, int, str]]:
            m = re.search(rf"(?m)^\s*pub\s+struct\s+{re.escape(struct_name)}\b", src)
            if not m:
                return None
            # expand upward to include contiguous doc/attr lines
            start = src.rfind("\n", 0, m.start()) + 1
            while start > 0:
                prev_nl = src.rfind("\n", 0, start - 1)
                if prev_nl == -1:
                    break
                prev_line_start = prev_nl + 1
                prev_line = src[prev_line_start:start].strip()
                if prev_line.startswith("///") or prev_line.startswith("#["):
                    start = prev_line_start
                    continue
                break

            # find matching brace block
            brace_open = src.find("{", m.end())
            if brace_open == -1:
                return None
            depth = 0
            i = brace_open
            while i < len(src):
                ch = src[i]
                if ch == "{":
                    depth += 1
                elif ch == "}":
                    depth -= 1
                    if depth == 0:
                        end = i + 1
                        # include trailing whitespace/newlines
                        while end < len(src) and src[end] in " \t\r":
                            end += 1
                        if end < len(src) and src[end] == "\n":
                            end += 1
                        block = src[start:end]
                        return start, end, block
                i += 1
            return None

        fixes: List[dict] = []
        new_content = content

        for type_name, alias in PRIMITIVE_TYPEDEF_ALIASES.items():
            span = _find_struct_block_span(new_content, type_name)
            if not span:
                continue
            start, end, block = span
            if not _is_trivial_opaque_struct(block):
                continue
            replacement = (
                f"/// C2R_PRIMITIVE_TYPEDEF: rule-mapped `{type_name}` -> `{alias}`\n"
                f"pub type {type_name} = {alias};\n"
            )
            new_content = new_content[:start] + replacement + new_content[end:]
            fixes.append({"name": type_name, "mapped_to": alias, "action": "replace_opaque_struct"})

        if new_content == content:
            # Still record the mapping table (best effort) for traceability.
            try:
                report_path = self.output_dir / "types_generation_report.json"
                if report_path.exists():
                    report = json.loads(report_path.read_text(encoding="utf-8", errors="ignore") or "{}")
                else:
                    report = {}
                report.setdefault("primitive_typedef_aliases", PRIMITIVE_TYPEDEF_ALIASES)
                report_path.write_text(json.dumps(report, ensure_ascii=False, indent=2, default=str), encoding="utf-8")
            except Exception:
                pass
            return {"applied": 0, "fixes": []}

        try:
            types_rs_path.write_text(new_content, encoding="utf-8", errors="ignore")
        except Exception:
            return {"applied": 0, "fixes": []}

        # Update types_generation_report.json (best effort)
        report_path = self.output_dir / "types_generation_report.json"
        try:
            if report_path.exists():
                report = json.loads(report_path.read_text(encoding="utf-8", errors="ignore") or "{}")
            else:
                report = {}
            report.setdefault("primitive_typedef_aliases", PRIMITIVE_TYPEDEF_ALIASES)
            report["primitive_typedef_fixes"] = fixes
            report_path.write_text(json.dumps(report, ensure_ascii=False, indent=2, default=str), encoding="utf-8")
        except Exception:
            pass

        logger.info(f"Tier-0 primitive typedef fixes applied: {len(fixes)}")
        return {"applied": len(fixes), "fixes": fixes}
    
    def _append_common_constants(self, types_rs_path: Path, existing_content: str):
        """
        è¿½åŠ å¸¸ç”¨å¸¸é‡å®šä¹‰åˆ° types.rs
        
        ä½¿ç”¨å¯é…ç½®çš„ PredefineManager è·å–å¸¸é‡å®šä¹‰ã€‚
        è¿™äº›å¸¸é‡åœ¨ OpenHarmony/SoftBus é¡¹ç›®ä¸­ç»å¸¸ä½¿ç”¨ï¼Œ
        LLM ç¿»è¯‘æ—¶ä¼šä¿ç•™åŸå§‹å¸¸é‡åï¼Œå› æ­¤éœ€è¦é¢„å…ˆå®šä¹‰ã€‚
        """
        # æ£€æŸ¥å·²å­˜åœ¨çš„å¸¸é‡ï¼Œé¿å…é‡å¤å®šä¹‰
        defined_constants = set(re.findall(r'pub const (\w+):', existing_content))
        
        constants_to_add = []
        
        # ä»é…ç½®è·å–æ‰€æœ‰å¸¸é‡
        if PREDEFINES_AVAILABLE:
            manager = get_predefine_manager(enable_ohos=True)
            all_constants = manager.get_all_constants()
        else:
            # å›é€€åˆ°ç¡¬ç¼–ç ï¼ˆå…¼å®¹æ€§ï¼‰
            all_constants = [
                # SoftBus å¸¸é‡
                ("SOFTBUS_OK", "i32", "0"),
                ("SOFTBUS_ERR", "i32", "-1"),
                ("SOFTBUS_INVALID_PARAM", "i32", "-3"),
                # HDF å¸¸é‡
                ("HDF_SUCCESS", "i32", "0"),
                ("HDF_FAILURE", "i32", "-1"),
                # LOS å¸¸é‡
                ("LOS_OK", "i32", "0"),
                ("LOS_NOK", "i32", "-1"),
                # POSIX å¸¸é‡
                ("PTHREAD_MUTEX_INITIALIZER", "pthread_mutex_t", "unsafe { ::core::mem::zeroed() }"),
            ]
        
        # å…ˆç¡®ä¿ pthread ç±»å‹å­˜åœ¨ï¼ˆåœ¨å¸¸é‡ä¹‹å‰æ·»åŠ ï¼‰
        self._ensure_pthread_types(types_rs_path, existing_content)
        
        for name, typ, value in all_constants:
            if name not in defined_constants:
                constants_to_add.append((name, typ, value))
        
        if not constants_to_add:
            return
        
        # è¿½åŠ åˆ° types.rs (ä½¿ç”¨ RustCodeBuilder ç¡®ä¿è¯­æ³•æ­£ç¡®)
        with open(types_rs_path, 'a', encoding='utf-8') as f:
            if RUST_CODE_BUILDER_AVAILABLE:
                builder = RustCodeBuilder()
                builder.add_line("")
                builder.add_line("// ============================================================")
                builder.add_line("// Common Constants (è‡ªåŠ¨è¿½åŠ )")
                builder.add_line("// ============================================================")
                builder.add_line("")
                
                for name, typ, value in constants_to_add:
                    builder.add_const(name, typ, value)
                
                f.write(builder.build())
            else:
                f.write("\n// ============================================================\n")
                f.write("// Common Constants (è‡ªåŠ¨è¿½åŠ )\n")
                f.write("// ============================================================\n\n")
                
                for name, typ, value in constants_to_add:
                    f.write(f"pub const {name}: {typ} = {value};\n")
        
        logger.info(f"å·²è¿½åŠ  {len(constants_to_add)} ä¸ªå¸¸ç”¨å¸¸é‡åˆ° types.rs")
    
    def _ensure_pthread_types(self, types_rs_path: Path, existing_content: str):
        """ç¡®ä¿ pthread ç›¸å…³ç±»å‹å­˜åœ¨ï¼ˆPTHREAD_MUTEX_INITIALIZER ç­‰å¸¸é‡éœ€è¦å®ƒä»¬ï¼‰"""
        pthread_types = [
            ('pthread_mutex_t', '#[repr(C)]\npub struct pthread_mutex_t { _opaque: [u8; 40] }'),
            ('pthread_cond_t', '#[repr(C)]\npub struct pthread_cond_t { _opaque: [u8; 48] }'),
            ('pthread_rwlock_t', '#[repr(C)]\npub struct pthread_rwlock_t { _opaque: [u8; 56] }'),
            ('pthread_once_t', 'pub type pthread_once_t = i32;'),
        ]
        
        types_to_add = []
        for type_name, definition in pthread_types:
            # æ£€æŸ¥æ˜¯å¦å·²å®šä¹‰
            if f'struct {type_name}' not in existing_content and f'type {type_name}' not in existing_content:
                types_to_add.append(definition)
        
        if types_to_add:
            with open(types_rs_path, 'a', encoding='utf-8') as f:
                f.write("\n// --- POSIX Thread Types ---\n")
                for definition in types_to_add:
                    f.write(definition + '\n')
                f.write('\n')
    
    def repair_skeleton_types(self, c_source_dir: Path = None, max_rounds: int = 3) -> bool:
        """
        LLM è¾…åŠ©ç±»å‹å®šä¹‰ä¿®å¤ (å‚è€ƒ EvoC2Rust & Tymcrat)
        
        å¾ªç¯ä¿®å¤æœºåˆ¶ï¼šä¿®å¤ä¸€ä¸ªç±»å‹å¯èƒ½ä¼šæš´éœ²ä¸‹ä¸€ä¸ªä¾èµ–ç±»å‹çš„é”™è¯¯ï¼Œ
        å› æ­¤éœ€è¦å¤šè½®ä¿®å¤ç›´åˆ°æ²¡æœ‰æ–°é”™è¯¯æˆ–è¾¾åˆ°æœ€å¤§è½®æ¬¡ã€‚
        
        Args:
            c_source_dir: C æºç ç›®å½•ï¼ˆç”¨äºæŸ¥æ‰¾ç±»å‹ä¸Šä¸‹æ–‡ï¼‰
            max_rounds: æœ€å¤§ä¿®å¤è½®æ¬¡ï¼ˆé»˜è®¤ 3ï¼‰
            
        Returns:
            æ˜¯å¦éª¨æ¶èƒ½é€šè¿‡ç¼–è¯‘
        """
        types_rs_path = self.output_dir / "src" / "types.rs"
        if not types_rs_path.exists():
            logger.warning("types.rs ä¸å­˜åœ¨ï¼Œè·³è¿‡éª¨æ¶ä¿®å¤")
            return True
        
        total_fixed = 0
        total_fallback = 0
        attempted_types = set()  # é¿å…é‡å¤å°è¯•åŒä¸€ä¸ªç±»å‹
        
        for round_num in range(1, max_rounds + 1):
            with open(types_rs_path, 'r', encoding='utf-8') as f:
                types_content = f.read()
            
            # 1. æ£€æµ‹é—®é¢˜ç±»å‹ï¼ˆæ’é™¤å·²å°è¯•çš„ï¼‰
            problem_types = self._detect_problem_types(types_content)
            new_problems = {k: v for k, v in problem_types.items() if k not in attempted_types}
            
            if not new_problems:
                if round_num == 1:
                    logger.info("æœªæ£€æµ‹åˆ°é—®é¢˜ç±»å‹ï¼Œéª¨æ¶ç±»å‹å®šä¹‰æ­£å¸¸")
                else:
                    logger.info(f"ç¬¬ {round_num} è½®ï¼šæ— æ–°é—®é¢˜ç±»å‹")
                break
            
            print(f"\nğŸ”§ ç¬¬ {round_num}/{max_rounds} è½®ï¼šæ£€æµ‹åˆ° {len(new_problems)} ä¸ªé—®é¢˜ç±»å‹")
            logger.info(f"ç¬¬ {round_num} è½®é—®é¢˜ç±»å‹: {list(new_problems.keys())}")
            
            # 2. å¯¹æ¯ä¸ªé—®é¢˜ç±»å‹ï¼Œå°è¯• LLM ä¿®å¤
            round_fixed = 0
            round_fallback = 0
            
            for type_name, problem_desc in new_problems.items():
                attempted_types.add(type_name)
                
                # æŸ¥æ‰¾ç±»å‹åœ¨ C æºç ä¸­çš„ä¸Šä¸‹æ–‡
                c_context = ""
                if c_source_dir and c_source_dir.exists():
                    c_context = self._find_type_context(type_name, c_source_dir)
                
                # è°ƒç”¨ LLM ä¿®å¤
                fixed_def = self._llm_fix_type(type_name, problem_desc, c_context, types_content)
                
                if fixed_def:
                    # LLM ä¿®å¤æˆåŠŸ
                    types_content = self._replace_type_definition(types_content, type_name, fixed_def)
                    round_fixed += 1
                    print(f"  âœ“ LLM ä¿®å¤: {type_name}")
                else:
                    # LLM ä¿®å¤å¤±è´¥ï¼Œä½¿ç”¨ FIXME å›é€€æ–¹æ¡ˆ
                    fallback_def = self._generate_fixme_fallback(type_name, problem_desc, c_context)
                    types_content = self._replace_type_definition(types_content, type_name, fallback_def)
                    round_fallback += 1
                    print(f"  âš  FIXME å›é€€: {type_name}")
            
            # 3. å†™å›æ–‡ä»¶
            with open(types_rs_path, 'w', encoding='utf-8') as f:
                f.write(types_content)
            
            total_fixed += round_fixed
            total_fallback += round_fallback
            
            print(f"  ç¬¬ {round_num} è½®å®Œæˆ: LLM ä¿®å¤ {round_fixed}, FIXME å›é€€ {round_fallback}")
            
            # 4. éªŒè¯ç¼–è¯‘ï¼ˆå¦‚æœè¿™è½®æœ‰ä¿®æ”¹ï¼‰
            if round_fixed + round_fallback > 0:
                success, error_msg = self.cargo_check()
                if success:
                    print(f"âœ“ éª¨æ¶ç¼–è¯‘éªŒè¯é€šè¿‡")
                    break
                else:
                    # è§£æç¼–è¯‘é”™è¯¯ï¼Œå¯èƒ½æœ‰æ–°çš„ç±»å‹é—®é¢˜
                    new_type_errors = self._extract_type_errors_from_cargo(error_msg)
                    if new_type_errors:
                        logger.info(f"ç¼–è¯‘å‘ç°æ–°ç±»å‹é”™è¯¯: {new_type_errors}")
        
        # æœ€ç»ˆç»Ÿè®¡
        if total_fixed + total_fallback > 0:
            print(f"\nğŸ“Š éª¨æ¶ä¿®å¤ç»Ÿè®¡: LLM æˆåŠŸ {total_fixed}, FIXME å›é€€ {total_fallback}")
        
        # æœ€ç»ˆç¼–è¯‘éªŒè¯
        success, _ = self.cargo_check()
        return success
    
    def _generate_fixme_fallback(self, type_name: str, problem_desc: str, c_context: str) -> str:
        """
        ç”Ÿæˆ FIXME å›é€€ç±»å‹å®šä¹‰
        
        å½“ LLM æ— æ³•ä¿®å¤ç±»å‹æ—¶ï¼Œç”Ÿæˆä¸€ä¸ª libc::c_void å ä½ç¬¦ï¼Œ
        ç¡®ä¿éª¨æ¶èƒ½é€šè¿‡ç¼–è¯‘ï¼Œè€Œä¸æ˜¯å¡æ­»ã€‚
        """
        # ç”Ÿæˆè¯¦ç»†çš„ FIXME æ³¨é‡Š
        lines = [
            f"/// FIXME: {type_name} - {problem_desc}",
            f"/// ",
            f"/// This type could not be automatically translated.",
            f"/// Original C context (if found):",
        ]
        
        if c_context:
            for line in c_context.split('\n')[:5]:  # æœ€å¤š 5 è¡Œ C ä»£ç 
                lines.append(f"/// {line}")
        else:
            lines.append("/// (no C definition found)")
        
        lines.append(f"/// ")
        lines.append(f"/// Manual translation required.")
        # ä½¿ç”¨ Zero-Sized Type (ZST) è€Œé c_voidï¼Œé˜²æ­¢ç±»å‹æ··æ·†
        lines.append(f"#[repr(C)]")
        lines.append(f"#[derive(Debug, Copy, Clone)]")
        lines.append(f"pub struct {type_name} {{")
        lines.append(f"    _private: [u8; 0],")
        lines.append(f"}}")
        
        return '\n'.join(lines)
    
    def _extract_type_errors_from_cargo(self, error_msg: str) -> List[str]:
        """
        ä» cargo check é”™è¯¯ä¿¡æ¯ä¸­æå–ç±»å‹ç›¸å…³é”™è¯¯
        
        Returns:
            ç¼ºå¤±æˆ–é”™è¯¯çš„ç±»å‹ååˆ—è¡¨
        """
        type_errors = []
        
        # åŒ¹é… "cannot find type `X`" é”™è¯¯
        pattern1 = re.compile(r"cannot find type `(\w+)`")
        for match in pattern1.finditer(error_msg):
            type_errors.append(match.group(1))
        
        # åŒ¹é… "not found in this scope" ç±»å‹é”™è¯¯
        pattern2 = re.compile(r"`(\w+)` not found in this scope")
        for match in pattern2.finditer(error_msg):
            type_errors.append(match.group(1))
        
        return list(set(type_errors))
    
    def _detect_problem_types(self, types_content: str) -> Dict[str, str]:
        """
        æ£€æµ‹ types.rs ä¸­çš„é—®é¢˜ç±»å‹
        
        Returns:
            {type_name: problem_description}
        """
        problems = {}
        
        # æ£€æµ‹ unknown ç±»å‹ï¼ˆTypeMapper çš„å ä½ç¬¦ï¼‰
        unknown_pattern = r'pub type (\w+)\s*=\s*(?:\*mut\s+)?c_void\s*;.*unknown'
        for match in re.finditer(unknown_pattern, types_content, re.IGNORECASE):
            type_name = match.group(1)
            problems[type_name] = "unknown type (placeholder from TypeMapper)"
        
        # æ£€æµ‹ç©ºç»“æ„ä½“ï¼ˆå¯èƒ½æ˜¯ä¸å®Œæ•´çš„å®šä¹‰ï¼‰
        empty_struct_pattern = r'pub struct (\w+)\s*\{\s*_private:\s*\[u8;\s*0\]'
        for match in re.finditer(empty_struct_pattern, types_content):
            type_name = match.group(1)
            # æ£€æŸ¥æ˜¯å¦æœ‰ "Opaque placeholder" æ³¨é‡Šï¼ˆè¿™æ˜¯æ­£å¸¸çš„ï¼‰
            context_start = max(0, match.start() - 100)
            context = types_content[context_start:match.start()]
            if "Opaque placeholder" not in context and "opaque" not in context.lower():
                problems[type_name] = "empty struct (possibly incomplete)"
        
        # æ£€æµ‹åŒ…å«éæ³•å­—ç¬¦çš„ç±»å‹å
        all_types = re.findall(r'pub (?:struct|enum|type|union) (\w+)', types_content)
        for type_name in all_types:
            if ' ' in type_name or not type_name[0].isalpha() and type_name[0] != '_':
                problems[type_name] = "invalid type name"
        
        return problems
    
    def _find_type_context(self, type_name: str, c_source_dir: Path, max_lines: int = 50) -> str:
        """
        åœ¨ C æºç ä¸­æŸ¥æ‰¾ç±»å‹å®šä¹‰çš„ä¸Šä¸‹æ–‡
        
        Args:
            type_name: ç±»å‹å
            c_source_dir: C æºç ç›®å½•
            max_lines: æœ€å¤§è¿”å›è¡Œæ•°
            
        Returns:
            C æºç ä¸Šä¸‹æ–‡
        """
        contexts = []
        
        # åœ¨å¤´æ–‡ä»¶å’Œæºæ–‡ä»¶ä¸­æœç´¢
        for ext in ['*.h', '*.hpp', '*.c', '*.cpp']:
            for file_path in c_source_dir.rglob(ext):
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    # æŸ¥æ‰¾ç±»å‹å®šä¹‰
                    patterns = [
                        rf'typedef\s+[^;]*\b{re.escape(type_name)}\b[^;]*;',
                        rf'struct\s+{re.escape(type_name)}\s*\{{[^}}]*\}}',
                        rf'enum\s+{re.escape(type_name)}\s*\{{[^}}]*\}}',
                        rf'#define\s+{re.escape(type_name)}\b[^\n]*',
                    ]
                    
                    for pattern in patterns:
                        matches = re.findall(pattern, content, re.DOTALL)
                        for match in matches:
                            if len(match) < 2000:  # é¿å…è¿‡é•¿
                                contexts.append(f"// From {file_path.name}:\n{match}")
                    
                    if len(contexts) >= 3:
                        break
                except Exception:
                    continue
            
            if len(contexts) >= 3:
                break
        
        return "\n\n".join(contexts[:3])
    
    def _llm_fix_type(self, type_name: str, problem_desc: str, c_context: str, existing_types: str) -> Optional[str]:
        """
        è°ƒç”¨ LLM ä¿®å¤ç±»å‹å®šä¹‰
        
        Returns:
            ä¿®å¤åçš„ Rust ç±»å‹å®šä¹‰ï¼Œæˆ– Noneï¼ˆå¦‚æœä¿®å¤å¤±è´¥ï¼‰
        """
        try:
            from generate.generation import generation
        except ImportError:
            logger.warning("æ— æ³•å¯¼å…¥ generation æ¨¡å—ï¼Œè·³è¿‡ LLM ç±»å‹ä¿®å¤")
            return None
        
        system_prompt = """You are a C to Rust type translation expert.

Your task is to generate a valid Rust type definition for a C type.

RULES:
1. Generate a compilable Rust struct/enum/type alias
2. Use #[repr(C)] for C compatibility
3. If the type is complex or unknown, generate an opaque Zero-Sized Type (ZST):
   ```rust
   #[repr(C)]
   #[derive(Debug, Copy, Clone)]
   pub struct TypeName {
       _private: [u8; 0],
   }
   ```
   DO NOT use `pub type TypeName = *mut std::ffi::c_void;` - it loses type safety!
4. Add helpful comments explaining the type

Output ONLY the Rust type definition (no markdown, no explanation)."""

        user_prompt = f"""Fix this problematic type: {type_name}
Problem: {problem_desc}

C source context (if available):
```c
{c_context if c_context else "(no context found)"}
```

Existing Rust types (for reference):
```rust
{existing_types[:2000]}
```

Generate a valid Rust type definition for `{type_name}`:"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]
        
        try:
            response = generation(messages)
            if isinstance(response, dict):
                response = response.get("content", "")
            
            # æ¸…ç†å“åº”ï¼ˆç§»é™¤ markdownï¼‰
            response = response.strip()
            if response.startswith("```"):
                response = re.sub(r'^```\w*\n?', '', response)
                response = re.sub(r'\n?```$', '', response)
            
            # éªŒè¯å“åº”æ˜¯å¦åŒ…å«ç±»å‹å®šä¹‰
            if type_name in response and ('pub ' in response or 'type ' in response or 'struct ' in response):
                return response.strip()
            else:
                logger.warning(f"LLM å“åº”ä¸åŒ…å«æœ‰æ•ˆçš„ç±»å‹å®šä¹‰: {response[:100]}")
                return None
        except Exception as e:
            logger.warning(f"LLM ç±»å‹ä¿®å¤å¤±è´¥ [{type_name}]: {e}")
            return None
    
    def _replace_type_definition(self, content: str, type_name: str, new_definition: str) -> str:
        """
        æ›¿æ¢ types.rs ä¸­çš„ç±»å‹å®šä¹‰
        """
        # å°è¯•åŒ¹é…å¹¶æ›¿æ¢ç°æœ‰å®šä¹‰
        patterns = [
            rf'(///[^\n]*\n)?#\[repr\(C\)\]\s*#\[derive[^\]]*\]\s*pub struct {re.escape(type_name)}\s*\{{[^}}]*\}}',
            rf'(///[^\n]*\n)?pub type {re.escape(type_name)}\s*=[^;]*;',
            rf'(///[^\n]*\n)?pub struct {re.escape(type_name)}\s*\{{[^}}]*\}}',
        ]
        
        for pattern in patterns:
            if re.search(pattern, content):
                content = re.sub(pattern, new_definition, content)
                return content
        
        # å¦‚æœæ²¡æ‰¾åˆ°ç°æœ‰å®šä¹‰ï¼Œè¿½åŠ åˆ°æœ«å°¾
        content += f"\n\n// LLM-generated type definition\n{new_definition}\n"
        return content
    
    def cargo_check(
        self,
        log_suffix: str = "full",
        use_offline: bool = True
    ) -> Tuple[bool, str]:
        """
        è¿è¡Œ cargo check éªŒè¯éª¨æ¶

        Phase 0 æ”¹è¿›ï¼š
        - ä½¿ç”¨ç¦»çº¿æ¨¡å¼é¿å…ç½‘ç»œé—®é¢˜å¹²æ‰°çœŸå®é”™è¯¯
        - å®Œæ•´æ—¥å¿—è½ç›˜ä¾¿äºè°ƒè¯•

        ä½¿ç”¨ RUSTFLAGS æŠ‘åˆ¶éª¨æ¶é˜¶æ®µå¸¸è§çš„æ— å®³è­¦å‘Šï¼š
        - unused_imports: å ä½ç”¨çš„ use è¯­å¥
        - dead_code: æœªè¢« main è°ƒç”¨çš„å‡½æ•°ï¼ˆéª¨æ¶ä¸­é—´çŠ¶æ€ï¼‰
        - unused_variables: å ä½å‚æ•°
        - unused_mut: é˜²å¾¡æ€§å¯å˜å£°æ˜

        Args:
            log_suffix: æ—¥å¿—æ–‡ä»¶åç¼€ï¼Œç”¨äºåŒºåˆ†ä¸åŒé˜¶æ®µ
                       - "full": åˆå§‹ç¼–è¯‘ -> compile_error_full.log
                       - "after_rule_fix": è§„åˆ™ä¿®å¤å -> compile_error_after_rule_fix.log
                       - "after_precise_fix": ç²¾ç¡®ä¿®å¤å -> compile_error_after_precise_fix.log
            use_offline: æ˜¯å¦ä½¿ç”¨ç¦»çº¿æ¨¡å¼ï¼ˆé»˜è®¤ Trueï¼Œé¿å…ç½‘ç»œå¹²æ‰°ï¼‰

        Returns:
            (æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯)
        """
        try:
            # è®¾ç½®ç¯å¢ƒå˜é‡
            env = os.environ.copy()
            # RUSTFLAGS æŠ‘åˆ¶æ— å®³è­¦å‘Š
            env["RUSTFLAGS"] = "-A unused_imports -A dead_code -A unused_variables -A unused_mut"
            # ç¦»çº¿æ¨¡å¼ï¼šé¿å… crates.io index / lock æŠŠçœŸæ­£é”™è¯¯æ·¹æ²¡
            if use_offline:
                env["CARGO_NET_OFFLINE"] = "true"

            # æ„å»ºå‘½ä»¤
            cmd = ["cargo", "check"]
            if use_offline:
                cmd.append("--offline")
            try:
                from cargo_utils import with_cargo_jobs
                cmd = with_cargo_jobs(cmd)
            except Exception:
                pass

            try:
                result = subprocess.run(
                    cmd,
                    cwd=self.output_dir,
                    capture_output=True,
                    text=True,
                    timeout=120,
                    env=env,
                )
            except subprocess.TimeoutExpired as e:
                output = ""
                if e.stdout:
                    output += e.stdout
                if e.stderr:
                    output += e.stderr
                msg = f"cargo check timed out after {e.timeout} seconds"
                if output:
                    msg += "\n\n" + output
                # å†™å…¥æ—¥å¿—æ–‡ä»¶
                self._write_compile_log(msg, log_suffix)
                return False, msg

            # åˆå¹¶è¾“å‡º
            output = result.stdout + result.stderr

            # å†™å…¥æ—¥å¿—æ–‡ä»¶ï¼ˆæ— è®ºæˆåŠŸå¤±è´¥éƒ½å†™ï¼‰
            if output.strip():
                self._write_compile_log(output, log_suffix)

            if result.returncode == 0:
                return True, ""

            # å³ä½¿è¿”å›ç é0ï¼Œå¦‚æœåªæœ‰è­¦å‘Šæ²¡æœ‰é”™è¯¯ï¼Œä¹Ÿè§†ä¸ºæˆåŠŸ
            has_error = bool(re.search(r'error\[E\d+\]:', output))
            if not has_error and "Finished" in output:
                return True, ""

            return False, output

        except Exception as e:
            error_msg = str(e)
            self._write_compile_log(f"Exception: {error_msg}", log_suffix)
            return False, error_msg

    def _write_compile_log(self, content: str, log_suffix: str):
        """
        å†™å…¥ç¼–è¯‘æ—¥å¿—æ–‡ä»¶

        Args:
            content: æ—¥å¿—å†…å®¹
            log_suffix: æ—¥å¿—åç¼€
        """
        log_filename = f"compile_error_{log_suffix}.log"
        log_path = self.output_dir / log_filename

        try:
            with open(log_path, 'w', encoding='utf-8') as f:
                f.write(f"# Compilation Log ({log_suffix})\n")
                f.write(f"# Generated at: {__import__('datetime').datetime.now().isoformat()}\n")
                f.write(f"# Project: {self.output_dir}\n")
                f.write("=" * 60 + "\n\n")
                f.write(content)
            logger.debug(f"ç¼–è¯‘æ—¥å¿—å·²å†™å…¥: {log_path}")
        except Exception as e:
            logger.warning(f"å†™å…¥ç¼–è¯‘æ—¥å¿—å¤±è´¥: {e}")


# =========================================================================
# LLM ç­¾åç¿»è¯‘è¾…åŠ©
# =========================================================================

def create_signature_translation_prompt(c_signature: str) -> str:
    """
    åˆ›å»ºç­¾åç¿»è¯‘çš„ LLM æç¤ºè¯
    
    è¿™ä¸ªæç¤ºè¯ä¸“é—¨ç”¨äºç¿»è¯‘ç­¾åï¼Œéš¾åº¦ä½ï¼Œå‡†ç¡®ç‡é«˜
    """
    return f'''Translate the following C function signature to Rust.

Rules:
1. Use types from `crate::types::*` for custom types.
2. Keep the function body as `unimplemented!();` - DO NOT implement the logic.
3. Common type mappings: intâ†’i32, unsigned intâ†’u32, charâ†’i8, void*â†’*mut std::ffi::c_void
4. Pointer parameters: Type* â†’ *mut Type or *const Type
5. For callbacks/function pointers, use: extern "C" fn(...) -> ...

C Signature:
{c_signature}

Output only the Rust function definition (signature + unimplemented body), no explanation:
'''


def parse_llm_signature_response(response: str) -> str:
    """è§£æ LLM ç­¾åç¿»è¯‘å“åº”"""
    # æå–ä»£ç å—
    code_match = re.search(r'```rust\s*(.*?)\s*```', response, re.DOTALL)
    if code_match:
        return code_match.group(1).strip()
    
    # å°è¯•ç›´æ¥æå–å‡½æ•°å®šä¹‰
    fn_match = re.search(r'((?:pub\s+)?(?:unsafe\s+)?(?:extern\s+"C"\s+)?fn\s+\w+\s*\([^)]*\)(?:\s*->\s*[^{]+)?\s*\{[^}]*\})', response, re.DOTALL)
    if fn_match:
        return fn_match.group(1).strip()
    
    return response.strip()


# =========================================================================
# ä¾¿æ·å‡½æ•°
# =========================================================================

def build_skeleton_for_project(
    project_root: str,
    output_dir: str,
    llm_generation_fn=None
) -> Path:
    """
    ä¸ºé¡¹ç›®æ„å»ºéª¨æ¶çš„ä¾¿æ·å‡½æ•°
    
    Args:
        project_root: C++ é¡¹ç›®æ ¹ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        llm_generation_fn: å¯é€‰çš„ LLM ç”Ÿæˆå‡½æ•°ï¼Œç­¾åä¸º (messages: List[Dict]) -> str
    
    Returns:
        éª¨æ¶é¡¹ç›®è·¯å¾„
    """
    project_root = Path(project_root)
    output_dir = Path(output_dir)
    
    # æ”¶é›†æºæ–‡ä»¶å’Œå¤´æ–‡ä»¶
    source_files = list(project_root.glob("**/*.c")) + list(project_root.glob("**/*.cpp"))
    header_files = list(project_root.glob("**/*.h")) + list(project_root.glob("**/*.hpp"))
    
    # åˆ›å»ºæ„å»ºå™¨
    builder = SkeletonBuilder(project_root, output_dir)
    
    # LLM ç¿»è¯‘åŒ…è£…å™¨
    llm_translate_fn = None
    if llm_generation_fn:
        def translate_signature(c_sig: str) -> str:
            prompt = create_signature_translation_prompt(c_sig)
            messages = [
                {"role": "system", "content": "You are a C to Rust translation expert. Translate function signatures accurately."},
                {"role": "user", "content": prompt}
            ]
            response = llm_generation_fn(messages)
            return parse_llm_signature_response(response)
        
        llm_translate_fn = translate_signature
    
    # æ„å»ºéª¨æ¶
    return builder.build_skeleton(source_files, header_files, llm_translate_fn)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    import sys
    
    if len(sys.argv) < 3:
        print("Usage: python skeleton_builder.py <project_root> <output_dir>")
        sys.exit(1)
    
    project_root = sys.argv[1]
    output_dir = sys.argv[2]
    
    logging.basicConfig(level=logging.INFO)
    
    result = build_skeleton_for_project(project_root, output_dir)
    print(f"éª¨æ¶å·²ç”Ÿæˆ: {result}")
