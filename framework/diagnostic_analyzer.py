#!/usr/bin/env python3
"""
è¯Šæ–­åˆ†æå™¨ (Diagnostic Analyzer)

ä¸å…¶å•çº¯ä¸ºäº†é€šè¿‡ç¼–è¯‘è€Œç»™å ä½ç¬¦å€¼ï¼Œä¸å¦‚ï¼š
1. è¿½æº¯æ¥æº - åœ¨ C æºç ä¸­æ‰¾åˆ°åŸå§‹å®šä¹‰
2. åˆ†æåŸå›  - ä¸ºä»€ä¹ˆè½¬æ¢/è¯†åˆ«å¤±è´¥
3. æ”¶é›†è¯æ® - ç»™å‡ºå…·ä½“çš„ä»£ç ä½ç½®å’Œä¸Šä¸‹æ–‡
4. æä¾›å¯æ“ä½œçš„å»ºè®®

æ ¸å¿ƒç†å¿µï¼š
- ä¸è¦ç”¨"ç³Šå¼„"çš„æ–¹å¼é€šè¿‡ç¼–è¯‘
- è¦æ‰¾åˆ°é—®é¢˜çš„æ ¹æœ¬åŸå› 
- ç”Ÿæˆå¯è¯»çš„è¯Šæ–­æŠ¥å‘Š
"""

import re
import os
import json
import logging
import subprocess
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Set, Any
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum

logger = logging.getLogger(__name__)


class MissingSymbolType(Enum):
    """ç¼ºå¤±ç¬¦å·çš„ç±»å‹"""
    TYPE = "type"           # ç±»å‹ï¼ˆstruct, enum, typedefï¼‰
    CONSTANT = "constant"   # å¸¸é‡ï¼ˆ#define, constï¼‰
    FUNCTION = "function"   # å‡½æ•°
    MACRO = "macro"         # å®


class FailureReason(Enum):
    """å¤±è´¥åŸå› åˆ†ç±»"""
    MACRO_NOT_EXPANDED = "macro_not_expanded"           # å®æœªå±•å¼€
    HEADER_NOT_INCLUDED = "header_not_included"         # å¤´æ–‡ä»¶æœªåŒ…å«
    CROSS_FILE_DEPENDENCY = "cross_file_dependency"     # è·¨æ–‡ä»¶ä¾èµ–
    CONDITIONAL_COMPILE = "conditional_compile"         # æ¡ä»¶ç¼–è¯‘æ’é™¤
    TYPEDEF_CHAIN = "typedef_chain"                     # typedef é“¾æœªè§£æ
    OPAQUE_TYPE = "opaque_type"                         # ä¸é€æ˜ç±»å‹ï¼ˆå‰å‘å£°æ˜ï¼‰
    BINDGEN_FAILURE = "bindgen_failure"                 # bindgen è½¬æ¢å¤±è´¥
    TREE_SITTER_PARSE_ERROR = "tree_sitter_parse_error" # Tree-sitter è§£æå¤±è´¥
    UNKNOWN = "unknown"                                  # æœªçŸ¥åŸå› 


@dataclass
class SourceEvidence:
    """æ¥æºè¯æ®"""
    file_path: str                  # æ–‡ä»¶è·¯å¾„
    line_number: int                # è¡Œå·
    column: int = 0                 # åˆ—å·
    code_snippet: str = ""          # ä»£ç ç‰‡æ®µï¼ˆå«ä¸Šä¸‹æ–‡ï¼‰
    surrounding_context: str = ""   # æ›´å¤§èŒƒå›´çš„ä¸Šä¸‹æ–‡


@dataclass
class DiagnosticResult:
    """è¯Šæ–­ç»“æœ"""
    symbol_name: str                           # ç¬¦å·åç§°
    symbol_type: MissingSymbolType             # ç¬¦å·ç±»å‹
    failure_reason: FailureReason = FailureReason.UNKNOWN  # å¤±è´¥åŸå› 
    confidence: float = 0.0                    # ç½®ä¿¡åº¦ (0-1)
    
    # è¯æ®
    c_source_evidence: Optional[SourceEvidence] = None  # C æºç ä¸­çš„å®šä¹‰ä½ç½®
    header_evidence: Optional[SourceEvidence] = None    # å¤´æ–‡ä»¶ä¸­çš„å®šä¹‰ä½ç½®
    rust_error_location: Optional[SourceEvidence] = None # Rust ç¼–è¯‘é”™è¯¯ä½ç½®
    
    # åˆ†æç»“æœ
    original_definition: str = ""              # åŸå§‹å®šä¹‰ï¼ˆå¦‚æœæ‰¾åˆ°ï¼‰
    dependent_symbols: List[str] = field(default_factory=list)  # ä¾èµ–çš„å…¶ä»–ç¬¦å·
    suggested_fix: str = ""                    # å»ºè®®çš„ä¿®å¤æ–¹å¼
    manual_review_required: bool = False       # æ˜¯å¦éœ€è¦äººå·¥å®¡æŸ¥
    
    # å…ƒæ•°æ®
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    diagnostic_notes: List[str] = field(default_factory=list)  # è¯Šæ–­å¤‡æ³¨


@dataclass
class DiagnosticReport:
    """è¯Šæ–­æŠ¥å‘Š"""
    project_name: str
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    
    # åˆ†ç±»ç»Ÿè®¡
    total_missing_symbols: int = 0
    by_type: Dict[str, int] = field(default_factory=dict)
    by_reason: Dict[str, int] = field(default_factory=dict)
    
    # è¯¦ç»†ç»“æœ
    diagnostics: List[DiagnosticResult] = field(default_factory=list)
    
    # éœ€è¦äººå·¥å®¡æŸ¥çš„
    manual_review_items: List[DiagnosticResult] = field(default_factory=list)
    
    # æ±‡æ€»å»ºè®®
    summary_recommendations: List[str] = field(default_factory=list)


class DiagnosticAnalyzer:
    """
    è¯Šæ–­åˆ†æå™¨
    
    èŒè´£ï¼š
    1. è§£æç¼–è¯‘é”™è¯¯ï¼Œæå–ç¼ºå¤±çš„ç¬¦å·
    2. åœ¨ C æºç ä¸­æœç´¢åŸå§‹å®šä¹‰
    3. åˆ†æå¤±è´¥åŸå› 
    4. ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
    """
    
    def __init__(
        self,
        c_source_dirs: List[Path],
        include_dirs: List[Path] = None,
        compile_commands_path: Optional[Path] = None
    ):
        """
        åˆå§‹åŒ–è¯Šæ–­åˆ†æå™¨
        
        Args:
            c_source_dirs: C æºç ç›®å½•åˆ—è¡¨
            include_dirs: å¤´æ–‡ä»¶æœç´¢ç›®å½•
            compile_commands_path: compile_commands.json è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        self.c_source_dirs = [Path(d) for d in c_source_dirs]
        self.include_dirs = [Path(d) for d in (include_dirs or [])]
        self.compile_commands_path = compile_commands_path
        
        # ç¼“å­˜ï¼šæ–‡ä»¶å†…å®¹
        self._file_cache: Dict[str, str] = {}
        
        # ç¼“å­˜ï¼šç¬¦å·å®šä¹‰ä½ç½®
        self._symbol_location_cache: Dict[str, SourceEvidence] = {}
        
        # åŠ è½½ compile_commands.jsonï¼ˆå¦‚æœæœ‰ï¼‰
        self._compile_commands = self._load_compile_commands()
    
    def _load_compile_commands(self) -> Dict[str, Dict]:
        """åŠ è½½ compile_commands.json"""
        if not self.compile_commands_path or not self.compile_commands_path.exists():
            return {}
        
        try:
            with open(self.compile_commands_path, 'r') as f:
                commands = json.load(f)
            return {cmd['file']: cmd for cmd in commands}
        except Exception as e:
            logger.warning(f"åŠ è½½ compile_commands.json å¤±è´¥: {e}")
            return {}
    
    def _get_file_content(self, file_path: str) -> Optional[str]:
        """è·å–æ–‡ä»¶å†…å®¹ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        if file_path not in self._file_cache:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
                    self._file_cache[file_path] = f.read()
            except Exception as e:
                logger.debug(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
                return None
        return self._file_cache[file_path]
    
    def analyze_compilation_errors(
        self,
        error_output: str,
        rust_project_dir: Path
    ) -> DiagnosticReport:
        """
        åˆ†æç¼–è¯‘é”™è¯¯å¹¶ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
        
        Args:
            error_output: cargo check çš„é”™è¯¯è¾“å‡º
            rust_project_dir: Rust é¡¹ç›®ç›®å½•
            
        Returns:
            è¯Šæ–­æŠ¥å‘Š
        """
        report = DiagnosticReport(
            project_name=rust_project_dir.name
        )
        
        # æå–ç¼ºå¤±çš„ç¬¦å·
        missing_symbols = self._extract_missing_symbols(error_output)
        report.total_missing_symbols = len(missing_symbols)
        
        # å¯¹æ¯ä¸ªç¬¦å·è¿›è¡Œè¯Šæ–­
        for symbol_name, symbol_type, error_location in missing_symbols:
            diagnostic = self._diagnose_symbol(
                symbol_name, 
                symbol_type, 
                error_location,
                rust_project_dir
            )
            
            report.diagnostics.append(diagnostic)
            
            # ç»Ÿè®¡
            type_key = diagnostic.symbol_type.value
            reason_key = diagnostic.failure_reason.value
            report.by_type[type_key] = report.by_type.get(type_key, 0) + 1
            report.by_reason[reason_key] = report.by_reason.get(reason_key, 0) + 1
            
            # éœ€è¦äººå·¥å®¡æŸ¥çš„
            if diagnostic.manual_review_required:
                report.manual_review_items.append(diagnostic)
        
        # ç”Ÿæˆæ±‡æ€»å»ºè®®
        report.summary_recommendations = self._generate_recommendations(report)
        
        return report
    
    def _extract_missing_symbols(
        self, 
        error_output: str
    ) -> List[Tuple[str, MissingSymbolType, Optional[SourceEvidence]]]:
        """
        ä»ç¼–è¯‘é”™è¯¯ä¸­æå–ç¼ºå¤±çš„ç¬¦å·
        
        Returns:
            [(ç¬¦å·å, ç¬¦å·ç±»å‹, é”™è¯¯ä½ç½®), ...]
        """
        results = []
        seen = set()
        
        # E0412: cannot find type
        for match in re.finditer(
            r'error\[E0412\]: cannot find type `(\w+)`.*?'
            r'(?:--> ([^:]+):(\d+):(\d+))?',
            error_output, 
            re.DOTALL
        ):
            symbol_name = match.group(1)
            if symbol_name in seen:
                continue
            seen.add(symbol_name)
            
            error_loc = None
            if match.group(2):
                error_loc = SourceEvidence(
                    file_path=match.group(2),
                    line_number=int(match.group(3)) if match.group(3) else 0,
                    column=int(match.group(4)) if match.group(4) else 0
                )
            
            results.append((symbol_name, MissingSymbolType.TYPE, error_loc))
        
        # E0425: cannot find value (å¸¸é‡)
        for match in re.finditer(
            r'error\[E0425\]: cannot find value `(\w+)`.*?'
            r'(?:--> ([^:]+):(\d+):(\d+))?',
            error_output,
            re.DOTALL
        ):
            symbol_name = match.group(1)
            if symbol_name in seen:
                continue
            seen.add(symbol_name)
            
            error_loc = None
            if match.group(2):
                error_loc = SourceEvidence(
                    file_path=match.group(2),
                    line_number=int(match.group(3)) if match.group(3) else 0,
                    column=int(match.group(4)) if match.group(4) else 0
                )
            
            results.append((symbol_name, MissingSymbolType.CONSTANT, error_loc))
        
        # E0433: failed to resolve (å¯èƒ½æ˜¯æ¨¡å—æˆ–ç±»å‹)
        for match in re.finditer(
            r'error\[E0433\]: failed to resolve.*?`(\w+)`',
            error_output
        ):
            symbol_name = match.group(1)
            if symbol_name not in seen:
                seen.add(symbol_name)
                results.append((symbol_name, MissingSymbolType.TYPE, None))
        
        return results
    
    def _diagnose_symbol(
        self,
        symbol_name: str,
        symbol_type: MissingSymbolType,
        error_location: Optional[SourceEvidence],
        rust_project_dir: Path
    ) -> DiagnosticResult:
        """
        è¯Šæ–­å•ä¸ªç¬¦å·
        
        è¿™æ˜¯æ ¸å¿ƒæ–¹æ³•ï¼šæ‰¾åˆ°ç¬¦å·åœ¨ C æºç ä¸­çš„åŸå§‹å®šä¹‰ï¼Œåˆ†æä¸ºä»€ä¹ˆè½¬æ¢å¤±è´¥
        """
        diagnostic = DiagnosticResult(
            symbol_name=symbol_name,
            symbol_type=symbol_type,
            rust_error_location=error_location
        )
        
        # æ­¥éª¤ 1: åœ¨ C æºç ä¸­æœç´¢å®šä¹‰
        c_definition = self._find_c_definition(symbol_name, symbol_type)
        
        if c_definition:
            diagnostic.c_source_evidence = c_definition['evidence']
            diagnostic.original_definition = c_definition['definition']
            diagnostic.confidence = 0.9
            
            # æ­¥éª¤ 2: åˆ†æä¸ºä»€ä¹ˆè½¬æ¢å¤±è´¥
            failure_analysis = self._analyze_failure_reason(
                symbol_name, 
                symbol_type,
                c_definition
            )
            diagnostic.failure_reason = failure_analysis['reason']
            diagnostic.diagnostic_notes = failure_analysis['notes']
            diagnostic.dependent_symbols = failure_analysis.get('dependencies', [])
            diagnostic.suggested_fix = failure_analysis.get('suggested_fix', '')
            
            # å¦‚æœåŸå› å¤æ‚ï¼Œæ ‡è®°éœ€è¦äººå·¥å®¡æŸ¥
            if diagnostic.failure_reason in [
                FailureReason.CONDITIONAL_COMPILE,
                FailureReason.TYPEDEF_CHAIN,
                FailureReason.UNKNOWN
            ]:
                diagnostic.manual_review_required = True
        else:
            # æ²¡æ‰¾åˆ° C å®šä¹‰
            diagnostic.failure_reason = FailureReason.UNKNOWN
            diagnostic.confidence = 0.3
            diagnostic.manual_review_required = True
            diagnostic.diagnostic_notes.append(
                f"âš ï¸ æœªèƒ½åœ¨ C æºç ä¸­æ‰¾åˆ° '{symbol_name}' çš„å®šä¹‰"
            )
            diagnostic.diagnostic_notes.append(
                "å¯èƒ½åŸå› ï¼š1) æ¥è‡ªæœªåŒ…å«çš„å¤´æ–‡ä»¶ 2) æ˜¯å®å®šä¹‰ 3) æ˜¯æ¡ä»¶ç¼–è¯‘æ’é™¤çš„ä»£ç "
            )
            
            # å°è¯•åœ¨å¤´æ–‡ä»¶ä¸­æœç´¢
            header_result = self._search_in_headers(symbol_name, symbol_type)
            if header_result:
                diagnostic.header_evidence = header_result['evidence']
                diagnostic.original_definition = header_result['definition']
                diagnostic.failure_reason = FailureReason.HEADER_NOT_INCLUDED
                diagnostic.confidence = 0.7
                diagnostic.diagnostic_notes.append(
                    f"âœ“ åœ¨å¤´æ–‡ä»¶ä¸­æ‰¾åˆ°å®šä¹‰: {header_result['evidence'].file_path}"
                )
        
        return diagnostic
    
    def _find_c_definition(
        self, 
        symbol_name: str, 
        symbol_type: MissingSymbolType
    ) -> Optional[Dict]:
        """
        åœ¨ C æºç ä¸­æœç´¢ç¬¦å·çš„å®šä¹‰
        
        Returns:
            {
                'evidence': SourceEvidence,
                'definition': str,
                'context': str
            }
        """
        # æ„å»ºæœç´¢æ¨¡å¼
        patterns = self._get_search_patterns(symbol_name, symbol_type)
        
        # åœ¨æ‰€æœ‰æºæ–‡ä»¶ä¸­æœç´¢
        for source_dir in self.c_source_dirs:
            if not source_dir.exists():
                continue
                
            for file_path in source_dir.rglob('*'):
                if not file_path.suffix in ['.c', '.cpp', '.h', '.hpp', '.cc']:
                    continue
                
                content = self._get_file_content(str(file_path))
                if not content:
                    continue
                
                for pattern, pattern_desc in patterns:
                    match = re.search(pattern, content, re.MULTILINE | re.DOTALL)
                    if match:
                        line_number = content[:match.start()].count('\n') + 1
                        
                        # æå–ä»£ç ç‰‡æ®µï¼ˆåŒ…å«ä¸Šä¸‹æ–‡ï¼‰
                        lines = content.split('\n')
                        start_line = max(0, line_number - 4)
                        end_line = min(len(lines), line_number + 6)
                        code_snippet = '\n'.join(
                            f"{i+1:4d} | {lines[i]}" 
                            for i in range(start_line, end_line)
                        )
                        
                        return {
                            'evidence': SourceEvidence(
                                file_path=str(file_path),
                                line_number=line_number,
                                code_snippet=code_snippet,
                                surrounding_context=match.group(0)[:500]
                            ),
                            'definition': match.group(0).strip(),
                            'pattern_desc': pattern_desc
                        }
        
        return None
    
    def _get_search_patterns(
        self, 
        symbol_name: str, 
        symbol_type: MissingSymbolType
    ) -> List[Tuple[str, str]]:
        """
        è·å–æœç´¢æ¨¡å¼
        
        Returns:
            [(regex_pattern, description), ...]
        """
        patterns = []
        
        if symbol_type == MissingSymbolType.TYPE:
            # struct å®šä¹‰
            patterns.append((
                rf'\bstruct\s+{re.escape(symbol_name)}\s*\{{[^}}]*\}}',
                f"struct {symbol_name} {{ ... }}"
            ))
            # typedef struct
            patterns.append((
                rf'\btypedef\s+struct\s+\w*\s*\{{[^}}]*\}}\s*{re.escape(symbol_name)}\s*;',
                f"typedef struct {{ ... }} {symbol_name};"
            ))
            # typedef å…¶ä»–ç±»å‹
            patterns.append((
                rf'\btypedef\s+[^;]+\s+{re.escape(symbol_name)}\s*;',
                f"typedef ... {symbol_name};"
            ))
            # enum å®šä¹‰
            patterns.append((
                rf'\benum\s+{re.escape(symbol_name)}\s*\{{[^}}]*\}}',
                f"enum {symbol_name} {{ ... }}"
            ))
            # å‰å‘å£°æ˜
            patterns.append((
                rf'\bstruct\s+{re.escape(symbol_name)}\s*;',
                f"struct {symbol_name}; (forward declaration)"
            ))
            
        elif symbol_type == MissingSymbolType.CONSTANT:
            # #define å¸¸é‡
            patterns.append((
                rf'#\s*define\s+{re.escape(symbol_name)}\s+[^\n]+',
                f"#define {symbol_name} ..."
            ))
            # const å˜é‡
            patterns.append((
                rf'\bconst\s+\w+\s+{re.escape(symbol_name)}\s*=\s*[^;]+;',
                f"const ... {symbol_name} = ...;"
            ))
            # enum æˆå‘˜
            patterns.append((
                rf'\b{re.escape(symbol_name)}\s*=\s*\d+',
                f"{symbol_name} = ... (enum member)"
            ))
            patterns.append((
                rf'\b{re.escape(symbol_name)}\s*,',
                f"{symbol_name}, (enum member)"
            ))
            
        elif symbol_type == MissingSymbolType.MACRO:
            # å®å®šä¹‰
            patterns.append((
                rf'#\s*define\s+{re.escape(symbol_name)}(?:\([^)]*\))?\s*[^\n]+',
                f"#define {symbol_name}..."
            ))
        
        return patterns
    
    def _search_in_headers(
        self, 
        symbol_name: str, 
        symbol_type: MissingSymbolType
    ) -> Optional[Dict]:
        """åœ¨å¤´æ–‡ä»¶ç›®å½•ä¸­æœç´¢"""
        patterns = self._get_search_patterns(symbol_name, symbol_type)
        
        for include_dir in self.include_dirs:
            if not include_dir.exists():
                continue
                
            for file_path in include_dir.rglob('*.h'):
                content = self._get_file_content(str(file_path))
                if not content:
                    continue
                
                for pattern, pattern_desc in patterns:
                    match = re.search(pattern, content, re.MULTILINE | re.DOTALL)
                    if match:
                        line_number = content[:match.start()].count('\n') + 1
                        
                        lines = content.split('\n')
                        start_line = max(0, line_number - 3)
                        end_line = min(len(lines), line_number + 5)
                        code_snippet = '\n'.join(
                            f"{i+1:4d} | {lines[i]}" 
                            for i in range(start_line, end_line)
                        )
                        
                        return {
                            'evidence': SourceEvidence(
                                file_path=str(file_path),
                                line_number=line_number,
                                code_snippet=code_snippet
                            ),
                            'definition': match.group(0).strip()
                        }
        
        return None
    
    def _analyze_failure_reason(
        self,
        symbol_name: str,
        symbol_type: MissingSymbolType,
        c_definition: Dict
    ) -> Dict:
        """
        åˆ†æè½¬æ¢å¤±è´¥çš„åŸå› 
        
        è¿™æ˜¯è¯Šæ–­çš„æ ¸å¿ƒï¼šæˆ‘ä»¬æ‰¾åˆ°äº† C å®šä¹‰ï¼Œä½†ä¸ºä»€ä¹ˆ Rust è½¬æ¢å¤±è´¥äº†ï¼Ÿ
        """
        result = {
            'reason': FailureReason.UNKNOWN,
            'notes': [],
            'dependencies': [],
            'suggested_fix': ''
        }
        
        definition = c_definition['definition']
        evidence = c_definition['evidence']
        file_path = evidence.file_path
        
        # åˆ†æ 1: æ˜¯å¦æ˜¯æ¡ä»¶ç¼–è¯‘å¯¼è‡´çš„
        content = self._get_file_content(file_path)
        if content:
            # æ£€æŸ¥å®šä¹‰å‰æ˜¯å¦æœ‰ #ifdef / #if
            lines = content.split('\n')
            start_line = evidence.line_number - 1
            
            # å‘ä¸Šæœç´¢æ¡ä»¶ç¼–è¯‘æŒ‡ä»¤
            conditional_stack = []
            for i in range(start_line - 1, max(0, start_line - 50), -1):
                line = lines[i].strip()
                if line.startswith('#endif'):
                    conditional_stack.append('#endif')
                elif line.startswith(('#ifdef', '#ifndef', '#if ')):
                    if conditional_stack:
                        conditional_stack.pop()
                    else:
                        # æ‰¾åˆ°äº†åŒ…å›´å®šä¹‰çš„æ¡ä»¶ç¼–è¯‘
                        result['reason'] = FailureReason.CONDITIONAL_COMPILE
                        result['notes'].append(
                            f"ğŸ” å®šä¹‰è¢«æ¡ä»¶ç¼–è¯‘åŒ…å›´: {line}"
                        )
                        result['notes'].append(
                            f"   ä½ç½®: {file_path}:{i+1}"
                        )
                        result['suggested_fix'] = (
                            f"æ£€æŸ¥æ¡ä»¶ç¼–è¯‘: {line}\n"
                            f"ç¡®ä¿åœ¨ç¼–è¯‘æ—¶å®šä¹‰äº†æ­£ç¡®çš„å®"
                        )
                        return result
        
        # åˆ†æ 2: æ˜¯å¦æ˜¯å®å±•å¼€é—®é¢˜
        # æ£€æŸ¥å®šä¹‰ä¸­æ˜¯å¦åŒ…å«å…¶ä»–å®
        macro_pattern = r'\b([A-Z][A-Z0-9_]{2,})\b'
        macros_in_def = set(re.findall(macro_pattern, definition))
        macros_in_def.discard(symbol_name.upper())
        
        if macros_in_def:
            result['reason'] = FailureReason.MACRO_NOT_EXPANDED
            result['dependencies'] = list(macros_in_def)
            result['notes'].append(
                f"ğŸ” å®šä¹‰ä¸­ä½¿ç”¨äº†å…¶ä»–å®: {', '.join(macros_in_def)}"
            )
            result['suggested_fix'] = (
                f"éœ€è¦å…ˆå±•å¼€è¿™äº›å®: {', '.join(macros_in_def)}\n"
                f"å¯ä»¥åœ¨ macro_learner.py ä¸­æ·»åŠ è¿™äº›å®çš„å®šä¹‰"
            )
            return result
        
        # åˆ†æ 3: æ˜¯å¦æ˜¯ typedef é“¾
        if 'typedef' in definition:
            # æ£€æŸ¥ typedef æŒ‡å‘çš„ç±»å‹æ˜¯å¦æ˜¯å¦ä¸€ä¸ªè‡ªå®šä¹‰ç±»å‹
            typedef_match = re.search(r'typedef\s+(\w+)\s+' + re.escape(symbol_name), definition)
            if typedef_match:
                base_type = typedef_match.group(1)
                if not self._is_primitive_type(base_type):
                    result['reason'] = FailureReason.TYPEDEF_CHAIN
                    result['dependencies'] = [base_type]
                    result['notes'].append(
                        f"ğŸ” typedef æŒ‡å‘è‡ªå®šä¹‰ç±»å‹: {base_type}"
                    )
                    result['suggested_fix'] = (
                        f"éœ€è¦å…ˆå®šä¹‰ç±»å‹: {base_type}\n"
                        f"ç„¶åå†å®šä¹‰ {symbol_name}"
                    )
                    return result
        
        # åˆ†æ 4: æ˜¯å¦æ˜¯å‰å‘å£°æ˜ï¼ˆä¸é€æ˜ç±»å‹ï¼‰
        if re.match(rf'\bstruct\s+{re.escape(symbol_name)}\s*;$', definition.strip()):
            result['reason'] = FailureReason.OPAQUE_TYPE
            result['notes'].append(
                f"ğŸ” è¿™æ˜¯ä¸€ä¸ªå‰å‘å£°æ˜ï¼ˆä¸é€æ˜ç±»å‹ï¼‰"
            )
            result['notes'].append(
                f"   å®Œæ•´å®šä¹‰å¯èƒ½åœ¨å…¶ä»–æ–‡ä»¶ä¸­"
            )
            result['suggested_fix'] = (
                f"åœ¨ Rust ä¸­ä½¿ç”¨ä¸é€æ˜ç±»å‹:\n"
                f"#[repr(C)]\n"
                f"pub struct {symbol_name} {{ _opaque: [u8; 0] }}"
            )
            return result
        
        # åˆ†æ 5: bindgen å¯èƒ½å¤±è´¥çš„åŸå› 
        if symbol_type == MissingSymbolType.TYPE:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¤æ‚çš„è”åˆä½“æˆ–ä½åŸŸ
            if 'union' in definition:
                result['reason'] = FailureReason.BINDGEN_FAILURE
                result['notes'].append(
                    "ğŸ” å®šä¹‰åŒ…å« unionï¼Œbindgen å¯èƒ½æ— æ³•æ­£ç¡®å¤„ç†"
                )
            elif re.search(r':\s*\d+\s*[,;]', definition):  # ä½åŸŸ
                result['reason'] = FailureReason.BINDGEN_FAILURE
                result['notes'].append(
                    "ğŸ” å®šä¹‰åŒ…å«ä½åŸŸï¼Œbindgen å¯èƒ½æ— æ³•æ­£ç¡®å¤„ç†"
                )
        
        # å¦‚æœåˆ°è¿™é‡Œè¿˜æ˜¯ UNKNOWNï¼Œå°è¯•ç»™å‡ºæ›´å¤šä¿¡æ¯
        if result['reason'] == FailureReason.UNKNOWN:
            result['notes'].append(
                f"ğŸ” æ‰¾åˆ°äº†åŸå§‹å®šä¹‰ï¼Œä½†æ— æ³•ç¡®å®šå¤±è´¥åŸå› "
            )
            result['notes'].append(
                f"   æ–‡ä»¶: {file_path}:{evidence.line_number}"
            )
            result['notes'].append(
                f"   å®šä¹‰: {definition[:200]}..."
            )
            result['suggested_fix'] = (
                f"è¯·äººå·¥æ£€æŸ¥åŸå§‹å®šä¹‰:\n{definition[:500]}"
            )
        
        return result
    
    def _is_primitive_type(self, type_name: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯ C åŸå§‹ç±»å‹"""
        primitives = {
            'int', 'char', 'short', 'long', 'float', 'double', 'void',
            'unsigned', 'signed', 'size_t', 'ssize_t', 'ptrdiff_t',
            'int8_t', 'int16_t', 'int32_t', 'int64_t',
            'uint8_t', 'uint16_t', 'uint32_t', 'uint64_t',
            'intptr_t', 'uintptr_t', 'bool', '_Bool'
        }
        return type_name.lower() in primitives
    
    def _generate_recommendations(self, report: DiagnosticReport) -> List[str]:
        """ç”Ÿæˆæ±‡æ€»å»ºè®®"""
        recommendations = []
        
        # æŒ‰å¤±è´¥åŸå› ç»Ÿè®¡
        reason_counts = report.by_reason
        
        if reason_counts.get('macro_not_expanded', 0) > 0:
            recommendations.append(
                f"ğŸ“Œ æœ‰ {reason_counts['macro_not_expanded']} ä¸ªç¬¦å·å› å®æœªå±•å¼€è€Œå¤±è´¥ã€‚\n"
                f"   å»ºè®®: åœ¨ macro_learner.py ä¸­æ·»åŠ è¿™äº›å®çš„å®šä¹‰"
            )
        
        if reason_counts.get('header_not_included', 0) > 0:
            recommendations.append(
                f"ğŸ“Œ æœ‰ {reason_counts['header_not_included']} ä¸ªç¬¦å·å®šä¹‰åœ¨æœªåŒ…å«çš„å¤´æ–‡ä»¶ä¸­ã€‚\n"
                f"   å»ºè®®: æ£€æŸ¥å¤´æ–‡ä»¶æœç´¢è·¯å¾„ï¼Œæˆ–åœ¨ include_dirs ä¸­æ·»åŠ è·¯å¾„"
            )
        
        if reason_counts.get('conditional_compile', 0) > 0:
            recommendations.append(
                f"ğŸ“Œ æœ‰ {reason_counts['conditional_compile']} ä¸ªç¬¦å·è¢«æ¡ä»¶ç¼–è¯‘æ’é™¤ã€‚\n"
                f"   å»ºè®®: æ£€æŸ¥ç¼–è¯‘é€‰é¡¹ï¼Œç¡®ä¿å®šä¹‰äº†æ­£ç¡®çš„é¢„å¤„ç†å®"
            )
        
        if reason_counts.get('opaque_type', 0) > 0:
            recommendations.append(
                f"ğŸ“Œ æœ‰ {reason_counts['opaque_type']} ä¸ªä¸é€æ˜ç±»å‹ï¼ˆå‰å‘å£°æ˜ï¼‰ã€‚\n"
                f"   è¿™äº›ç±»å‹å¯ä»¥å®‰å…¨åœ°ä½¿ç”¨ [u8; 0] å ä½ç¬¦"
            )
        
        if len(report.manual_review_items) > 0:
            recommendations.append(
                f"âš ï¸ æœ‰ {len(report.manual_review_items)} ä¸ªç¬¦å·éœ€è¦äººå·¥å®¡æŸ¥"
            )
        
        return recommendations


def generate_diagnostic_report(
    error_output: str,
    rust_project_dir: Path,
    c_source_dirs: List[Path],
    include_dirs: List[Path] = None,
    output_path: Optional[Path] = None
) -> DiagnosticReport:
    """
    ç”Ÿæˆè¯Šæ–­æŠ¥å‘Šçš„ä¾¿æ·å‡½æ•°
    
    Args:
        error_output: cargo check çš„é”™è¯¯è¾“å‡º
        rust_project_dir: Rust é¡¹ç›®ç›®å½•
        c_source_dirs: C æºç ç›®å½•
        include_dirs: å¤´æ–‡ä»¶ç›®å½•
        output_path: æŠ¥å‘Šè¾“å‡ºè·¯å¾„
        
    Returns:
        è¯Šæ–­æŠ¥å‘Š
    """
    analyzer = DiagnosticAnalyzer(c_source_dirs, include_dirs)
    report = analyzer.analyze_compilation_errors(error_output, rust_project_dir)
    
    if output_path:
        save_report(report, output_path)
    
    return report


def save_report(report: DiagnosticReport, output_path: Path):
    """ä¿å­˜è¯Šæ–­æŠ¥å‘Š"""
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # JSON æ ¼å¼
    json_path = output_path.with_suffix('.json')
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(_report_to_dict(report), f, indent=2, ensure_ascii=False)
    
    # äººç±»å¯è¯»æ ¼å¼
    txt_path = output_path.with_suffix('.txt')
    with open(txt_path, 'w', encoding='utf-8') as f:
        f.write(format_report(report))
    
    logger.info(f"è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜: {json_path}, {txt_path}")


def _report_to_dict(report: DiagnosticReport) -> Dict:
    """å°†æŠ¥å‘Šè½¬æ¢ä¸ºå­—å…¸"""
    return {
        'project_name': report.project_name,
        'timestamp': report.timestamp,
        'total_missing_symbols': report.total_missing_symbols,
        'by_type': report.by_type,
        'by_reason': report.by_reason,
        'summary_recommendations': report.summary_recommendations,
        'diagnostics': [
            {
                'symbol_name': d.symbol_name,
                'symbol_type': d.symbol_type.value,
                'failure_reason': d.failure_reason.value,
                'confidence': d.confidence,
                'original_definition': d.original_definition[:500] if d.original_definition else '',
                'c_source_location': (
                    f"{d.c_source_evidence.file_path}:{d.c_source_evidence.line_number}"
                    if d.c_source_evidence else None
                ),
                'diagnostic_notes': d.diagnostic_notes,
                'suggested_fix': d.suggested_fix,
                'manual_review_required': d.manual_review_required
            }
            for d in report.diagnostics
        ]
    }


def format_report(report: DiagnosticReport) -> str:
    """æ ¼å¼åŒ–æŠ¥å‘Šä¸ºäººç±»å¯è¯»æ–‡æœ¬"""
    lines = [
        "=" * 70,
        f"è¯Šæ–­æŠ¥å‘Š: {report.project_name}",
        f"ç”Ÿæˆæ—¶é—´: {report.timestamp}",
        "=" * 70,
        "",
        f"ğŸ“Š ç»Ÿè®¡æ‘˜è¦",
        f"   ç¼ºå¤±ç¬¦å·æ€»æ•°: {report.total_missing_symbols}",
        "",
        f"   æŒ‰ç±»å‹åˆ†å¸ƒ:",
    ]
    
    for type_name, count in report.by_type.items():
        lines.append(f"     - {type_name}: {count}")
    
    lines.append("")
    lines.append(f"   æŒ‰åŸå› åˆ†å¸ƒ:")
    for reason, count in report.by_reason.items():
        lines.append(f"     - {reason}: {count}")
    
    lines.append("")
    lines.append("-" * 70)
    lines.append("ğŸ“‹ å»ºè®®")
    lines.append("-" * 70)
    for rec in report.summary_recommendations:
        lines.append(rec)
    
    lines.append("")
    lines.append("-" * 70)
    lines.append("ğŸ“ è¯¦ç»†è¯Šæ–­")
    lines.append("-" * 70)
    
    for i, d in enumerate(report.diagnostics, 1):
        lines.append("")
        lines.append(f"[{i}] {d.symbol_name} ({d.symbol_type.value})")
        lines.append(f"    å¤±è´¥åŸå› : {d.failure_reason.value}")
        lines.append(f"    ç½®ä¿¡åº¦: {d.confidence:.0%}")
        
        if d.c_source_evidence:
            lines.append(f"    C æºç ä½ç½®: {d.c_source_evidence.file_path}:{d.c_source_evidence.line_number}")
            if d.c_source_evidence.code_snippet:
                lines.append("    ä»£ç ç‰‡æ®µ:")
                for line in d.c_source_evidence.code_snippet.split('\n')[:10]:
                    lines.append(f"      {line}")
        
        if d.diagnostic_notes:
            lines.append("    è¯Šæ–­å¤‡æ³¨:")
            for note in d.diagnostic_notes:
                lines.append(f"      {note}")
        
        if d.suggested_fix:
            lines.append("    å»ºè®®ä¿®å¤:")
            for line in d.suggested_fix.split('\n'):
                lines.append(f"      {line}")
        
        if d.manual_review_required:
            lines.append("    âš ï¸ éœ€è¦äººå·¥å®¡æŸ¥")
    
    return '\n'.join(lines)


# =============================================================================
# æµ‹è¯•ä»£ç 
# =============================================================================

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # æ¨¡æ‹Ÿç¼–è¯‘é”™è¯¯
    fake_errors = """
error[E0412]: cannot find type `HdfDeviceInfo` in this scope
 --> src/lib.rs:42:15
  |
42 |     info: *mut HdfDeviceInfo,
  |               ^^^^^^^^^^^^^ not found in this scope

error[E0425]: cannot find value `HDF_ERR_INVALID_OBJECT` in this scope
  --> src/lib.rs:88:16
   |
88 |         return HDF_ERR_INVALID_OBJECT;
   |                ^^^^^^^^^^^^^^^^^^^^^^ not found in this scope

error[E0412]: cannot find type `AudioSubPortCapability` in this scope
  --> src/audio.rs:156:22
   |
156|     capability: *mut AudioSubPortCapability,
   |                      ^^^^^^^^^^^^^^^^^^^^^^ not found in this scope
"""
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = DiagnosticAnalyzer(
        c_source_dirs=[Path("./dlp_fuse")],
        include_dirs=[Path("/usr/include")]
    )
    
    # åˆ†æ
    report = analyzer.analyze_compilation_errors(
        fake_errors,
        Path("./output/test_project")
    )
    
    # è¾“å‡ºæŠ¥å‘Š
    print(format_report(report))



